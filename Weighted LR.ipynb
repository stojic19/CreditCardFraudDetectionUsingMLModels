{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72710333-acc9-4694-8904-3f40b391bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1dcbbe3-3ee4-4382-85c2-f564f3feefdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "transactions = pd.read_csv(\"Data/creditcard.csv\")\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566e7f0c-6e96-4161-b7ca-660a83467677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "X = transactions.drop(['Class'], axis=1) # Features\n",
    "y = transactions.Class # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ae2d03-d8ca-49ef-beb3-7a681961ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "276f6f5c-1788-4026-abe8-a86e2914a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C': 100, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "model = LogisticRegression(solver='liblinear', C=100, penalty='l1', random_state=0)\n",
    "\n",
    "# Train\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f130107-6783-4cee-b788-1983c245935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Confusion matrix  \n",
    "cm= confusion_matrix(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fdaac1-1f85-4f94-b5c2-0a0f95dc4264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b824259e-fd96-4366-85e5-fcbc676c055e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sns.heatmap(cm/np.sum(cm), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef391705-d83e-4652-bd30-60c61155f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.00\n",
      "\n",
      "Micro Precision: 1.00\n",
      "Micro Recall: 1.00\n",
      "Micro F1-score: 1.00\n",
      "\n",
      "Macro Precision: 0.87\n",
      "Macro Recall: 0.78\n",
      "Macro F1-score: 0.82\n",
      "\n",
      "Weighted Precision: 1.00\n",
      "Weighted Recall: 1.00\n",
      "Weighted F1-score: 1.00\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56861\n",
      "           1       0.74      0.56      0.64       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.78      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f99400-399f-4f90-88f6-db5838d902c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FN, FP, TN = 0, 0, 0, 0\n",
    "\n",
    "def confusion_matrix_for(cls, cm):\n",
    "    TP = cm[cls, cls]\n",
    "    FN = cm[cls].sum() - TP\n",
    "    FP = cm[:, cls].sum() - TP\n",
    "    TN = cm.sum() - TP - FN - FP\n",
    "    return np.array([[TP, FN], [FP, TN]])\n",
    "\n",
    "def getTotalAmountFalseNegative(df):\n",
    "    df = df[df.case == 'false negative'] \n",
    "    totalAmount = 0\n",
    "    for index, row in df.iterrows():\n",
    "        totalAmount += row.Amount\n",
    "    return totalAmount\n",
    "\n",
    "def total_cost(cm, X_test, y_test, y_pred):\n",
    "    for cls in range(cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, cm).ravel()\n",
    "        #print(f'TP: {TP}, FN: {FN}, FP: {FP}, TN: {TN}')\n",
    "    \n",
    "    print(f'TP: {TP}, FN: {FN}, FP: {FP}, TN: {TN}')\n",
    "\n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "\n",
    "    X_test['case'] = labels[y_test * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegative(X_test) + (FP + TP) * Ca\n",
    "    print('Total cost: ' + str(TotalCost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "412ed753-f4b4-49d6-a182-833fccf0492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 57, FN: 44, FP: 20, TN: 56841\n",
      "Total cost: 8950.170000000002\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm, X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7e552-6833-404c-aa0b-316900633273",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0ed6f6-eb0b-4eb0-a97c-d5dfb213e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce76f819-9627-4040-b838-599ba6beb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=1) # Numerical value\n",
    "# rus = RandomUnderSampler(sampling_strategy=\"not minority\") # String\n",
    "X_train_us, y_train_us = rus.fit_resample(X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183689fa-5da2-4976-945f-f9ec9ac94e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# Train\n",
    "model_us = model.fit(X_train_us,y_train_us)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_us = model.predict(X_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c22ad7-6a3a-4625-988f-36fabd6acabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm_us = confusion_matrix(y_test_us, y_pred_us) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870c54e9-db5c-4a57-804d-5823add6d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_us, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e684183-2d31-496a-9316-b4221b9966b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXXElEQVR4nO3deXhU1f3H8fc3GQMBAbHKUoP+kE0DWlFEEREEUVBWEQpuVaNRFFyoC/ysVrHWBatWBRUqVqsCakWjomhBxAUt9GmLgKCRWhZZ9MdeCMlkzu+PxDRBkpnI5Mzl5vPyuc+TuffMuef6TD6cnHvuGXPOISIifqSlugEiIrWJQldExCOFroiIRwpdERGPFLoiIh5FavoEmR1HaXqE/MD6jx9JdRMkgBplptm+1lGdzNn198f2+XzVVeOhKyLilQX7D3iFroiEi3nvvFaLQldEwkU9XRERj9TTFRHxKC091S2okkJXRMJFwwsiIh5peEFExCP1dEVEPFJPV0TEI/V0RUQ80uwFERGP1NMVEfFo39fMqVEKXREJF/V0RUQ80uwFERGPdCNNRMQjDS+IiHik4QUREY/U0xUR8Ug9XRERj9TTFRHxSLMXREQ8Uk9XRMQjjemKiHiknq6IiEfq6YqIeKSeroiIP5am0BUR8cY0vCAi4lGwM1ehKyLhop6uiIhHCl0REY/SAn4jLditExGpLqvGFq8qsz5mtsLM8s1s7F6OH25m75nZ381ssZmdHa9Oha6IhIqZJbzFqScdmAj0BbKBEWaWvUexXwEvOuc6AsOBSfHap9AVkVBJVugCnYF859xK51whMB0YuEcZBzQs/bkR8E28SjWmKyKhUp0baWaWC+SW2zXZOTe59OfDgNXljq0BTtqjijuAd8xsNFAfOCPeORW6IhIq1Qnd0oCdHLdg5UYAf3TO/c7MugB/MrMOzrlYZW9Q6IpIqFha0qaMrQValHudVbqvvBygD4BzboGZ1QUOATZWVqnGdEUkVJI4prsQaGNmLc0sg5IbZXl7lFkF9Co979FAXeDbqipVT1dEQiVZD0c456JmNgqYDaQDU51zS81sPLDIOZcH/BKYYmY3UHJT7RLnnKuqXoWuiIRLEh9Ic87NAmbtse/2cj8vA7pWp06FroiEih4DFhHxSKErIuJR0NdeUOiKSLgEu6Or0BWRcNHwgoiIRwpdERGPFLoiIh4l8THgGqHQTdA1I3pw6bmnYGY8/cpHPPbCPABGDu/OlcO6URxzvP3BEm79/WsV3pfV9CD+cNfFNPlJA5yDqX/+iInTSt57+9Xn0K/7scSc49tN28n99XOs+3Yrg3odx20jz2Hz1v8wbMwUNm39Dy2zDmH8qP5cNPZpz1cuidi9ezdXXnYRhUWFFEej9DrjLHKvHl2hzBuvzeSRhydw6KFNARg6/HwGnTsUgEcffoCPPngfgJzckfQ+q2Qt7NvG3cRX+V9warceXH3tDQA8NeVxWrVqQ4+ecRe0qpXU0w2B7FbNufTcU+h20QQKi4rJm3g1sz5YQlbTxvTrcQydf34vhUVRDm184A/eGy2OMfbBV/jH8jUcWK8OH79wC3M+Xc7ylet56Jk5jJ/0JgBXj+jOuNy+XHv3dEYO786pF97PwJ7H8fO+nXh8+vvccU0/7pj0hu9LlwRlZGQwacrT1KtXn2hREVdceiFdTu3GMcceV6Fc7zP7ctO42yrs+3D+PFZ8voznZsykqKiQq3J+QZeup7Hum7XUqVuHF156jVFXXsaO7dspKNjF0s8Wk3PFSI9Xt39R6IbAUS2bsXDJ1+wqKALgg7/lM6jncRyffTgPPP0uhUVRAL7dvOMH713/3TbWf7cNgB07d7P8X+v56aEHsXzlerb/p6CsXL3MOnz/yHYsFqPOARHq1c2gKFpM146t2PDdNr5aVeU6GpJCZka9evUBiEajRKNFCf/y/2vlV3Q8oRORSIRIJELrtm1Z8NEHtG7Tlt0Fu4nFYkSjUdLS03hy0qPkjhxVk5ey3wt66MadRWxmR5nZLWb2SOl2S+lqOrXG0q++oWvH1hzcqD6ZdQ+gz6ntyWrWmNZHNKFrx1bMf/ZG3vnDdZyQfXiV9Rze/GCOa5fFwiVfl+2745r+fPnWXQzv24m7Hi/p9U6Y+i5vPjGas0/rwItvL2LsFX24Z8rbNXmJkgTFxcVcMGwwZ/U8lc4nn0KHY372gzJz57zD+UMHMvbG69iwfh0AbdoexYKPPqRg1y62bN7M3xb+lY0b1tPyyFY0btyYi4YPoVv301mzahUxF+Ooo9v7vrT9SxK/I61GmlfVgjhmdgsli/ROp2TVdChZU3I4MN05d28l7ytbjT2S1eOEyCH7/4fkF4O6kDu0GzsLCln21ToKC6OcflI75i/6kjH3vUSn9kfwp/su5eh+d+z1/fUzM3jnD9dz/1OzeW3uP39w/MbLzqRuRoTfPFFhbQ3O79eZgxvW46+ffc31F/di87ad3Djh5bJe9/5q/cePpLoJNWb7tm3cPGY0N469lVat25bt37JlM/Xq1ScjI4NXXp7Bu7Pf4vEpfwRg6pQnmPPubBo3bkzjg39CdvsOjLjwFxXqHXPtSMb96k5ef+0VvvxiBSed3IVBQ4b5vLQa1yhz3++CHTlmVpWrfJW38sGzvUdvvJ5uDnCic+5e59xzpdu9lHx3UE5lb3LOTXbOdXLOdQpD4AI88+oCul5wP71zHmbLtp18+e+NrN2whVfn/AOARUv/TSzmOGQv47qRSBrTHriCGW8t2mvgAsyYtZBBvY6rsC+z7gFc1P8knnhxPr+66hwuv+1PfPyPlQzve2KyL0+SqEHDhpxwYmcWfPRhhf0HHdSYjIwMAAYOPo/lny8tO3bZFVfx/IszeezJqTjnOPyI/6nw3vffm8NRR7dn567/sHbNau6Z8BBz/vIOBbt21fj17G/S0izhLSXti3M8Bvx0L/ublx6rNb6/SdaiWWMG9vwZM95axOvzFtP9xJKeTOvDm5BxQITv9jKu+8SvL2DFv9bzyHNzK+xvdfihZT/363EsX3y9ocLxGy4+g0nT3icajZFZ9wAcjlgsRr26Gcm+PNlHmzdtYvu2krH7goICPv1kAUe0bFmhzHff/vfLBOa/P5eWLY8ESoYltmzZDMCXX6wg/8sVnNTlv6sFRouKmP78s1x8SQ67C3aX/VkcixVTVLR//8VTE5K4iHmNiHcj7Xpgjpl9yX+/oO1woDVQq0bzpz1wOQcfVJ+iaDHX3/siW3fs4plXF/DkHRew6KX/pbComMtv/xMAzQ9txKTbz2fw6Mc55bgjuaDfSXz2xVo+mT4WgF8/lsfsD5fxm2sH0uaIJsRijlXrNnHt3dPLztf80EZ06nAEv538FgCPT3ufD5+7ma3bdzJszBT//wOkSt999y133jaOWKyYWCzGGWf2odtpp/PkpEc4OrsDp/XoyYxpzzF/3lzSIxEaNWzE7ePvAUpuvF152UUA1K9fn/F3308k8t9fzZdmvMA5/QdRNzOTNm3bsbuggBHnDeCUU0+jQcOGe21PbRbw+2hVj+kCmFkaJcMJh5XuWgssdM4VJ3KCzI6jEh5fkdojzGO68uMlY0y33S2zE86cFfed5T2i404ZK/1Wy088tEVEZJ8FvaereboiEiqpukGWKIWuiISKQldExCMNL4iIeBT0x4AVuiISKgpdERGPAp65Cl0RCRfdSBMR8UjDCyIiHgU8cxW6IhIu6umKiHgU8MxV6IpIuKinKyLikWYviIh4FPCOrkJXRMJFwwsiIh4FPHMVuiISLurpioh4FPTQjfdtwCIi+5VkfgW7mfUxsxVmlm9mYyspM8zMlpnZUjN7IV6d6umKSKgkq6NrZunARKA3sAZYaGZ5zrll5cq0AcYBXZ1zm82sSbx61dMVkVAxs4S3ODoD+c65lc65QmA6MHCPMlcAE51zmwGccxvjVarQFZFQMavOZrlmtqjclluuqsOA1eVeryndV15boK2ZfWRmn5hZn3jt0/CCiIRKWjXGF5xzk4HJ+3C6CNAG6AFkAfPN7Bjn3Jaq3iAiEhpJfAx4LdCi3Ous0n3lrQE+dc4VAf8ysy8oCeGFlbYvWa0TEQmCNEt8i2Mh0MbMWppZBjAcyNujzKuU9HIxs0MoGW5YWVWl6umKSKgka56ucy5qZqOA2UA6MNU5t9TMxgOLnHN5pcfONLNlQDFwk3Pu/6qqV6ErIqGSzGcjnHOzgFl77Lu93M8OGFO6JUShKyKhYgT7iTSFroiESsCX01Xoiki4aBFzERGPqjNPNxUUuiISKgHPXIWuiIRL0Jd2VOiKSKgEPHMVuiISLukBT12FroiEioYXREQ8CviMMYWuiISLeroiIh4FPHMVuiISLurpioh4lB7wQV2FroiESrAjV6ErIiGjtRdERDwKeOYqdEUkXHQjTUTEo4BnrkJXRMJFsxdERDyq9cMLmxc+VtOnEBEpk5bqBsShnq6IhEqt7+mKiPgU8CFdha6IhItupImIeBTwzFXoiki4BHxIV6ErIuGitRdERDzSlDEREY8C3tFV6IpIuGj2goiIRwHPXIWuiISLbqSJiHgU8MxV6IpIuGh4QUTEIwv4V1MGfUqbiEi1RNIS3+Ixsz5mtsLM8s1sbBXlhpiZM7NOcdtXvcsREQm2ZC3taGbpwESgN7AGWGhmec65ZXuUawBcB3yaSL3q6YpIqKRZ4lscnYF859xK51whMB0YuJdydwH3AQUJta8a1yIiEnhm1dks18wWldtyy1V1GLC63Os1pfvKncuOB1o4595MtH0aXhCRUKnOPF3n3GRg8o85j5mlAQ8Cl1TnfQpdEQmV9OT9/b4WaFHudVbpvu81ADoA80rHkZsBeWY2wDm3qLJKFboiEippyZsythBoY2YtKQnb4cD53x90zm0FDvn+tZnNA26sKnBL2iciEiLVGdOtinMuCowCZgOfAy8655aa2XgzG/Bj26eeroiESjKfSHPOzQJm7bHv9krK9kikToWuiISKFrwREfEo4Jmr0BWRcNEi5iIiHgV9doBCV0RCJVlrL9QUha6IhEqwI1ehKyIho9kLIiIeBTtyFboiEjJpmr0gIuKPZi+IiHik2QsiIh4FO3IVuiISMurpioh4lK7QFRHxJ9iRq9AVkZAJeEdXoSsi4ZLEr+upEQpdEQkV9XRFRDwy9XRFRPzR7AUREY8CnrkKXREJF4WuiIhHGtMVEfEo4Cs7KnRFJFz0zREiIh4FfXgh6Ov9BtJHH8xnwDln0a9Pb56aMvkHxwsLC7npl9fTr09vLhg+lLVr1wCwZctmci65iJM7deS3vxlfofzI3BzOHdiPGdOeL9s//te38fmypTV/QZIU8T4Xf1u0kJ+fN5jjj83m3dlvVzi27ptvuPKKyxjUvy+D+59d9pkZd/MvOW9wfx55+MGyspOfmMTcOX+p2YvZj6VZ4ltK2pea0+6/iouL+e3d45n0xB+Ymfcmb896g6/y8yuUmfnnl2jYsCFvvP0uF158CQ8/+AAAGRl1uGb0dYy56eYK5T/+8AM6Hn8CL8/M443X8wBYsXw5xbFijs5u7+fCZJ8k8rlo1rw5d919D33P6feD9//qf2/hkktzePX1t3h++kscfPBP+GLFcurUrcvLM19n6ZLP2L59O99+u5HPFi+mZ68zfF3afseq8V8qKHSraclni2nR4giyWrTggIwM+px9DvPem1OhzHtz5zJg4GAAep95Fn/9ZAHOOerVq8fxJ3SiTkadCuUjB0QoKCggGo3inANg4qMPc83o6/xclOyzRD4Xhx2WRdt2R5FmFX/tvsrPJxqN0uWUrgDUq1+fzMxMIpED2F1QQCwWIxqNkp6WxqRHH+HqUaO9Xdf+yCzxLRUUutW0ccMGmjVvVva6SdOmbNiwoWKZjRto1qw5AJFIhAMbNGDLls2V1nlyl658s3YtF44YxvkXXMS8uXM4Ors9TZo0rZmLkKRL5HNRmX//+2saNGzIDdeNYtiQQTz4wH0UFxdzZKtWNG58MMPPG8xpPU5n1apVxFxMf/3EYdXYUuFH30gzs0udc09XciwXyAV4bNKT5FyR+2NPUytEIhHunfA7AIqKihiZm8PvH5vEhPvuYf26dfQfMJAePXuluJVSU4qjUf7+t0XMePlVmjVvzs2/vIHXXn2Fc4cM5eZxt5aVG331Vdx2x51MefJxvlixnJO7dGXI0GEpbHkwBf0x4H3p6d5Z2QHn3GTnXCfnXKewBW6Tpk1Zv2592euNGzbQtGnFHmmTJk1Zv34dANFolB3bt3PQQY0Tqv/F6S/Qf8AgFv/znzRo0ID7f/cQzz6z13/bJEAS+VxUpmmzZrQ76miyWrQgEolweq9eLF+2rEKZ9+b+hez27dm5cyerV69iwoO/5913ZrNr166kXkcoBLyrW2XomtniSrbPgFr5t2/7DsewatXXrFmzmqLCQt6e9SbdT+9ZoUyP03uS99pMAN59ZzadTzo5oe9t2rZ1K/Pfn0f/gYMoKNiFmWFmFBQU1Mi1SPIk8rmo6r3bt21j06ZNAPz10085slXrsuNFRUU89+wzXHLZ5ewu2F32WYrFiikqKkr+xezngn4jLd7wQlPgLGDPAUkDPq6RFgVcJBJh3K23MzL3cmKxYgYNHkLr1m2Y+Ojvad++Az169mLwkPO4dexN9OvTm4aNGnH/Aw+Vvb9v757s2LGDoqIi3pv7F56YPJVWrUt+wZ58fCKX515FWloap3TtxvRpLzBkUH+G/nx4qi5XEpTI52LJZ4u54bpRbNu2jffnvcekiY8yM+9N0tPTGXPTLeTm/ALnIDu7PUPOG1pW94xpzzNg4GAyMzNp264dBbsKGDKoP6d2O42GDRum8KqDKeCjC9j3d8v3etDsKeBp59yHezn2gnPu/HgnKIhS+QlERMqpG9n37ufClVsTzpwTj2zkPaKr7Ok653KqOBY3cEVEvAt4T1dTxkQkVNLMEt7iMbM+ZrbCzPLNbOxejo8xs2Wl97rmmNkRcdv3I69LRCSQkjV5wczSgYlAXyAbGGFm2XsU+zvQyTl3LPAycH+89il0RSRckjdlrDOQ75xb6ZwrBKYDA8sXcM6955zbWfryEyArXqUKXREJlSROGTsMWF3u9ZrSfZXJAd6KV6mWdhSRUKnOlLHyT8+Wmuyc++EScfHruRDoBHSPV1ahKyKhUp3QLQ3YykJ2LdCi3Ous0n17nM/OAG4Fujvndsc7p4YXRCRUkji8sBBoY2YtzSwDGA7kVTiXWUfgSWCAc25jIu1TT1dEQiVZT6Q556JmNgqYDaQDU51zS81sPLDIOZcHTAAOBF4qfTx7lXNuQJXtq+qJtGTQE2kikqhkPJG2ZM2OhDOnQ9aBwXoiTURkvxPwJ9IUuiISKkH/YkqFroiESqq+cDJRCl0RCReFroiIPxpeEBHxKOiLmCt0RSRUAp65Cl0RCZmAp65CV0RCJZHFyVNJoSsioRLsyFXoikjYBDx1FboiEiqaMiYi4lHAh3QVuiISLgpdERGPNLwgIuKReroiIh4FPHMVuiISLurpioh4FezUVeiKSKhoEXMREY80vCAi4pGmjImI+BTszFXoiki4BDxzFboiEi4a0xUR8cgCnroKXREJlWBHrkJXREIm4B1dha6IhIumjImIeKSeroiIRwpdERGPNLwgIuKReroiIh4FPHMVuiISMgFPXYWuiISKxnRFRDzSIuYiIj4pdEVE/NHwgoiIR0GfMmbOuVS3odYws1zn3ORUt0OCRZ+L2iUt1Q2oZXJT3QAJJH0uahGFroiIRwpdERGPFLp+adxO9kafi1pEN9JERDxST1dExCOFroiIRwpdT8ysj5mtMLN8Mxub6vZI6pnZVDPbaGZLUt0W8Ueh64GZpQMTgb5ANjDCzLJT2yoJgD8CfVLdCPFLoetHZyDfObfSOVcITAcGprhNkmLOufnAplS3Q/xS6PpxGLC63Os1pftEpJZR6IqIeKTQ9WMt0KLc66zSfSJSyyh0/VgItDGzlmaWAQwH8lLcJhFJAYWuB865KDAKmA18DrzonFua2lZJqpnZNGAB0M7M1phZTqrbJDVPjwGLiHiknq6IiEcKXRERjxS6IiIeKXRFRDxS6IqIeKTQFRHxSKErIuLR/wMMe1VPFtSFYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_us/np.sum(cm_us), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c64f1c-2e29-423b-bc44-f7aa5066af48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 90, FN: 8, FP: 2047, TN: 54817\n",
      "Total cost: 11343.61\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm_us, X_test_us, y_test_us, y_pred_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa10484-fc6c-4fe5-90be-647f550113fe",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581a7c00-37fc-4755-9ca4-ec649f75693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) # 80% training and 20% test\n",
    "\n",
    "smote_technique = SMOTE(sampling_strategy='minority')\n",
    "X_smt, y_smt = smote_technique.fit_resample(X_train_smt, y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d168c954-3f11-4d3b-817e-1a48d3953e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 'logisticregression__C': 1e-05, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'\n",
    "model_smt = LogisticRegression(C=1e-05, penalty='l2',solver='newton-cg')\n",
    "\n",
    "# Train\n",
    "model_smt = model_smt.fit(X_smt,y_smt)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_smt = model_smt.predict(X_test_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40005461-92c0-4c6d-be33-a402ccfaf5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm_smt = confusion_matrix(y_test_smt, y_pred_smt) \n",
    "\n",
    "sns.heatmap(cm_smt/np.sum(cm_smt), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1533d3b2-2f26-4a03-8f59-1f25c24aa1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 87, FN: 11, FP: 345, TN: 56519\n",
      "Total cost: 3986.5\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm_smt, X_test_smt, y_test_smt, y_pred_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da76817-f7ed-486b-96fb-057af668a08a",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c934ba22-0c69-44da-b000-76107423921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def get_x_elements_by_indices(x_train, indices):\n",
    "    new_df = pd.DataFrame()\n",
    "    for index in indices:\n",
    "        try:\n",
    "            new_df = new_df.append(x_train.iloc[index])\n",
    "        except:\n",
    "            print(str(index) + \" not found\")\n",
    "    return new_df\n",
    "\n",
    "def getTotalAmountFalseNegativeMyScorer(df, y_test, y_pred):\n",
    "    fn_indices = []\n",
    "    for ((index, row), i) in zip(y_test.items(), range(len(y_pred))):\n",
    "        if y_pred[i]==0 and row!=y_pred[i]:\n",
    "            fn_indices.append(index)\n",
    "    print(\"No of FN: \" + str(len(fn_indices)))\n",
    "    df = df.iloc[fn_indices]\n",
    "    totalAmount = 0\n",
    "    for index, row in df.iterrows():\n",
    "        totalAmount += row.Amount\n",
    "    return totalAmount\n",
    "\n",
    "def my_scorer(y_true, y_pred):\n",
    "    model_cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    for cls in range(model_cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, model_cm).ravel() \n",
    "        \n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "    X_test_score = X\n",
    "    # X_test_score = get_x_elements_by_indices(X_test_score, y_true.index)\n",
    "    #print(labels[y_true * 2 + y_pred])\n",
    "    #X_test_score['case'] = labels[y_true * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegativeMyScorer(X_test_score, y_true, y_pred) + (FP + TP) * Ca\n",
    "    print(TotalCost)\n",
    "    return TotalCost\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "my_func = make_scorer(my_scorer, greater_is_better=False)\n",
    "\n",
    "#my_scorer(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40af14e9-49b0-44eb-8693-7eef8b5ecc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# weights = {0:1.0, 1:25.0}\n",
    "space['weights'] = [{0:1.0, 1:25.0}, {0:1.0, 1:50.0}, {0:1.0, 1:75.0}, {0:1.0, 1:100.0}, {0:1.0, 1:150.0}]\n",
    "# define search\n",
    "#search = GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504222c8-912c-47fd-9e7a-d5eef87aa32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search\n",
    "# search = GridSearchCV(model, space, cv=cv, scoring='f1', n_jobs=-1)\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring=my_func, cv=cv, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42fb557d-f9e5-403f-aa0a-795c63ac2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute search\n",
    "#result = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa0dddf3-d47a-4f36-9f40-3703b56ede21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9989554302261862\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09719699-678e-4706-8032-97b95aa6db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty  = ['none', 'l1', 'l2', 'elasticnet']\n",
    "C = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# weights =  [{0:1.0, 1:25.0}, {0:1.0, 1:50.0}, {0:1.0, 1:75.0}, {0:1.0, 1:100.0}, {0:1.0, 1:150.0}]\n",
    "weights =  [{0:1.0, 1:10.0}, {0:1.0, 1:25.0}]\n",
    "# Define parameters\n",
    "param_grid = dict(solver=solver, penalty=penalty, C=C, class_weight=weights)\n",
    "\n",
    "# Build the gridsearch\n",
    "lr = LogisticRegression()\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, scoring=my_func, cv = 5, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f547976-75a1-4009-bb9b-5b4d4f66c9e4",
   "metadata": {},
   "source": [
    "# Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5487de7a-da66-44a0-9212-ab6a35bb9948",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5; 1/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 1/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  10.1s\n",
      "[CV 2/5; 1/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 1/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  10.2s\n",
      "[CV 3/5; 1/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 1/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  10.0s\n",
      "[CV 4/5; 1/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 1/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  10.3s\n",
      "[CV 5/5; 1/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 1/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=   9.6s\n",
      "[CV 1/5; 2/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 2/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.2s\n",
      "[CV 2/5; 2/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 2/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.2s\n",
      "[CV 3/5; 2/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 2/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   1.2s\n",
      "[CV 4/5; 2/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 2/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   1.2s\n",
      "[CV 5/5; 2/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 2/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.2s\n",
      "[CV 1/5; 3/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 3/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 3/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 3/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 3/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 3/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 4/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 4/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 4/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 4/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 4/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 4/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 4/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 5/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 5/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 5/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 5/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 5/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 5/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "7300.529999999998\n",
      "[CV 1/5; 6/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-7300.530 total time=   0.3s\n",
      "[CV 2/5; 6/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "10858.949999999997\n",
      "[CV 2/5; 6/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-10858.950 total time=   0.2s\n",
      "[CV 3/5; 6/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "6768.910000000001\n",
      "[CV 3/5; 6/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-6768.910 total time=   0.2s\n",
      "[CV 4/5; 6/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "7686.04\n",
      "[CV 4/5; 6/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-7686.040 total time=   0.2s\n",
      "[CV 5/5; 6/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 79\n",
      "16510.07\n",
      "[CV 5/5; 6/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-16510.070 total time=   0.2s\n",
      "[CV 1/5; 7/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 56\n",
      "6672.549999999998\n",
      "[CV 1/5; 7/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-6672.550 total time=  10.8s\n",
      "[CV 2/5; 7/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 50\n",
      "8835.949999999999\n",
      "[CV 2/5; 7/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-8835.950 total time=  10.5s\n",
      "[CV 3/5; 7/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 53\n",
      "4824.650000000001\n",
      "[CV 3/5; 7/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4824.650 total time=  10.5s\n",
      "[CV 4/5; 7/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 52\n",
      "4931.899999999999\n",
      "[CV 4/5; 7/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4931.900 total time=  10.6s\n",
      "[CV 5/5; 7/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 57\n",
      "12747.660000000002\n",
      "[CV 5/5; 7/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-12747.660 total time=  13.2s\n",
      "[CV 1/5; 8/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 44\n",
      "6476.509999999999\n",
      "[CV 1/5; 8/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-6476.510 total time=   0.8s\n",
      "[CV 2/5; 8/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 48\n",
      "9096.649999999998\n",
      "[CV 2/5; 8/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-9096.650 total time=   0.8s\n",
      "[CV 3/5; 8/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 48\n",
      "5357.040000000002\n",
      "[CV 3/5; 8/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-5357.040 total time=   1.0s\n",
      "[CV 4/5; 8/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 48\n",
      "5772.329999999999\n",
      "[CV 4/5; 8/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-5772.330 total time=   0.9s\n",
      "[CV 5/5; 8/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 54\n",
      "13278.95\n",
      "[CV 5/5; 8/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-13278.950 total time=   1.5s\n",
      "[CV 1/5; 9/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 44\n",
      "6446.509999999999\n",
      "[CV 1/5; 9/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-6446.510 total time=   1.5s\n",
      "[CV 2/5; 9/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 48\n",
      "9026.649999999998\n",
      "[CV 2/5; 9/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-9026.650 total time=   1.7s\n",
      "[CV 3/5; 9/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 48\n",
      "5327.040000000002\n",
      "[CV 3/5; 9/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-5327.040 total time=   1.7s\n",
      "[CV 4/5; 9/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 47\n",
      "5736.329999999999\n",
      "[CV 4/5; 9/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-5736.330 total time=   1.5s\n",
      "[CV 5/5; 9/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 54\n",
      "13283.95\n",
      "[CV 5/5; 9/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-13283.950 total time=   1.5s\n",
      "[CV 1/5; 10/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 10/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 10/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 10/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 10/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 10/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 10/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 10/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 10/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 10/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 11/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 11/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 11/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 11/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 11/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 11/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 11/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 11/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 11/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 11/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 12/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 12/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 12/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 12/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 12/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 12/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 12/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 12/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 12/192] START C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 12/192] END C=1e-05, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 13/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 13/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  13.7s\n",
      "[CV 2/5; 13/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 13/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  13.7s\n",
      "[CV 3/5; 13/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 13/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  13.9s\n",
      "[CV 4/5; 13/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 13/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  13.7s\n",
      "[CV 5/5; 13/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 13/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  13.3s\n",
      "[CV 1/5; 14/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 14/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   1.5s\n",
      "[CV 2/5; 14/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 14/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   1.3s\n",
      "[CV 3/5; 14/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 14/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.3s\n",
      "[CV 4/5; 14/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 14/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.3s\n",
      "[CV 5/5; 14/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 14/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.2s\n",
      "[CV 1/5; 15/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 15/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 15/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 15/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 15/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 15/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 15/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 15/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 15/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 15/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 16/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 16/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 16/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 16/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 16/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 16/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 16/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 16/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 16/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 16/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 17/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 17/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 17/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 17/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 17/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 17/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 17/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 17/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 17/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 17/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 18/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "7300.529999999998\n",
      "[CV 1/5; 18/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-7300.530 total time=   0.2s\n",
      "[CV 2/5; 18/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "10858.949999999997\n",
      "[CV 2/5; 18/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-10858.950 total time=   0.3s\n",
      "[CV 3/5; 18/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "6768.910000000001\n",
      "[CV 3/5; 18/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-6768.910 total time=   0.3s\n",
      "[CV 4/5; 18/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 78\n",
      "7686.04\n",
      "[CV 4/5; 18/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-7686.040 total time=   0.2s\n",
      "[CV 5/5; 18/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 79\n",
      "16510.07\n",
      "[CV 5/5; 18/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-16510.070 total time=   0.2s\n",
      "[CV 1/5; 19/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "5283.95\n",
      "[CV 1/5; 19/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-5283.950 total time=  13.4s\n",
      "[CV 2/5; 19/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "7587.500000000001\n",
      "[CV 2/5; 19/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-7587.500 total time=  13.7s\n",
      "[CV 3/5; 19/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "3377.66\n",
      "[CV 3/5; 19/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-3377.660 total time=  13.2s\n",
      "[CV 4/5; 19/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 32\n",
      "4125.24\n",
      "[CV 4/5; 19/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-4125.240 total time=  14.8s\n",
      "[CV 5/5; 19/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 44\n",
      "10757.950000000003\n",
      "[CV 5/5; 19/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-10757.950 total time=  14.2s\n",
      "[CV 1/5; 20/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "5214.21\n",
      "[CV 1/5; 20/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-5214.210 total time=   1.5s\n",
      "[CV 2/5; 20/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 37\n",
      "8389.869999999999\n",
      "[CV 2/5; 20/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-8389.870 total time=   1.0s\n",
      "[CV 3/5; 20/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 37\n",
      "4506.879999999999\n",
      "[CV 3/5; 20/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4506.880 total time=   0.7s\n",
      "[CV 4/5; 20/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 37\n",
      "4473.879999999999\n",
      "[CV 4/5; 20/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4473.880 total time=   1.0s\n",
      "[CV 5/5; 20/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 42\n",
      "10548.660000000002\n",
      "[CV 5/5; 20/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-10548.660 total time=   1.5s\n",
      "[CV 1/5; 21/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 32\n",
      "4073.8799999999997\n",
      "[CV 1/5; 21/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4073.880 total time=   1.6s\n",
      "[CV 2/5; 21/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 37\n",
      "8389.869999999999\n",
      "[CV 2/5; 21/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-8389.870 total time=   1.4s\n",
      "[CV 3/5; 21/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 35\n",
      "4335.199999999999\n",
      "[CV 3/5; 21/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4335.200 total time=   1.5s\n",
      "[CV 4/5; 21/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 38\n",
      "4494.879999999999\n",
      "[CV 4/5; 21/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4494.880 total time=   1.3s\n",
      "[CV 5/5; 21/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 43\n",
      "11269.520000000002\n",
      "[CV 5/5; 21/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-11269.520 total time=   1.6s\n",
      "[CV 1/5; 22/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 22/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 22/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 22/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 22/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 22/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 22/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 22/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 22/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 22/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 23/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 23/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 23/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 23/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 23/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 23/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 23/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 23/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 23/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 23/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 24/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 24/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 24/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 24/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 24/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 24/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 24/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 24/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 24/192] START C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 24/192] END C=1e-05, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 25/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 25/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  13.1s\n",
      "[CV 2/5; 25/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 25/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  13.1s\n",
      "[CV 3/5; 25/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 25/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  12.9s\n",
      "[CV 4/5; 25/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 25/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  13.2s\n",
      "[CV 5/5; 25/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 25/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  12.3s\n",
      "[CV 1/5; 26/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 26/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.5s\n",
      "[CV 2/5; 26/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 26/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.6s\n",
      "[CV 3/5; 26/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 26/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   1.6s\n",
      "[CV 4/5; 26/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 26/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   1.5s\n",
      "[CV 5/5; 26/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 26/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.5s\n",
      "[CV 1/5; 27/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 27/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 27/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 27/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 27/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 27/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 27/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 27/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 27/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 27/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 28/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 28/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 28/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 28/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 28/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 28/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 28/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 28/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 28/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 28/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 29/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 29/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 29/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 29/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 29/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 29/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 29/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 29/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 29/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 29/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 30/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 43\n",
      "6774.199999999999\n",
      "[CV 1/5; 30/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-6774.200 total time=   0.4s\n",
      "[CV 2/5; 30/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 49\n",
      "9590.919999999998\n",
      "[CV 2/5; 30/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-9590.920 total time=   0.3s\n",
      "[CV 3/5; 30/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 45\n",
      "5235.52\n",
      "[CV 3/5; 30/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-5235.520 total time=   0.4s\n",
      "[CV 4/5; 30/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 48\n",
      "6120.159999999999\n",
      "[CV 4/5; 30/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-6120.160 total time=   0.3s\n",
      "[CV 5/5; 30/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 54\n",
      "13593.95\n",
      "[CV 5/5; 30/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-13593.950 total time=   0.3s\n",
      "[CV 1/5; 31/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "3369.319999999999\n",
      "[CV 1/5; 31/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-3369.320 total time=  14.2s\n",
      "[CV 2/5; 31/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 32\n",
      "7095.2300000000005\n",
      "[CV 2/5; 31/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-7095.230 total time=  13.5s\n",
      "[CV 3/5; 31/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "2657.9700000000003\n",
      "[CV 3/5; 31/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2657.970 total time=  13.2s\n",
      "[CV 4/5; 31/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 20\n",
      "2485.2400000000002\n",
      "[CV 4/5; 31/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2485.240 total time=  13.0s\n",
      "[CV 5/5; 31/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 32\n",
      "7048.58\n",
      "[CV 5/5; 31/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-7048.580 total time=  13.7s\n",
      "[CV 1/5; 32/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 26\n",
      "3692.79\n",
      "[CV 1/5; 32/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3692.790 total time=   1.1s\n",
      "[CV 2/5; 32/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7546.17\n",
      "[CV 2/5; 32/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-7546.170 total time=   1.6s\n",
      "[CV 3/5; 32/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 22\n",
      "4122.01\n",
      "[CV 3/5; 32/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4122.010 total time=   1.6s\n",
      "[CV 4/5; 32/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 28\n",
      "4088.5799999999995\n",
      "[CV 4/5; 32/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4088.580 total time=   1.7s\n",
      "[CV 5/5; 32/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 38\n",
      "10519.230000000001\n",
      "[CV 5/5; 32/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-10519.230 total time=   1.6s\n",
      "[CV 1/5; 33/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 24\n",
      "3138.56\n",
      "[CV 1/5; 33/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-3138.560 total time=   1.6s\n",
      "[CV 2/5; 33/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 25\n",
      "5350.300000000001\n",
      "[CV 2/5; 33/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-5350.300 total time=   1.8s\n",
      "[CV 3/5; 33/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 22\n",
      "4172.01\n",
      "[CV 3/5; 33/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4172.010 total time=   1.7s\n",
      "[CV 4/5; 33/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 27\n",
      "3853.04\n",
      "[CV 4/5; 33/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-3853.040 total time=   2.0s\n",
      "[CV 5/5; 33/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 38\n",
      "10524.230000000001\n",
      "[CV 5/5; 33/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-10524.230 total time=   1.6s\n",
      "[CV 1/5; 34/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 34/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 34/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 34/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 34/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 34/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 34/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 34/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 34/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 34/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 35/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 35/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 35/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 35/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 35/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 35/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 35/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 35/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 35/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 35/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 36/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 36/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 36/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 36/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 36/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 36/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 36/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 36/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 36/192] START C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 36/192] END C=0.0001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 37/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 37/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  14.1s\n",
      "[CV 2/5; 37/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 37/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  14.2s\n",
      "[CV 3/5; 37/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 37/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  14.7s\n",
      "[CV 4/5; 37/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 37/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  15.1s\n",
      "[CV 5/5; 37/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 37/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  13.9s\n",
      "[CV 1/5; 38/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 38/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   1.6s\n",
      "[CV 2/5; 38/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 38/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   1.5s\n",
      "[CV 3/5; 38/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 38/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.7s\n",
      "[CV 4/5; 38/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 38/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.7s\n",
      "[CV 5/5; 38/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 38/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.6s\n",
      "[CV 1/5; 39/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 39/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 39/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 39/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 39/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 39/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 40/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 40/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 40/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 40/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 40/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 40/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 40/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 40/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 40/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 41/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 41/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 41/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 41/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 41/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 41/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 41/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 41/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 41/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 41/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 42/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 28\n",
      "4564.459999999999\n",
      "[CV 1/5; 42/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-4564.460 total time=   0.5s\n",
      "[CV 2/5; 42/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 33\n",
      "8150.92\n",
      "[CV 2/5; 42/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-8150.920 total time=   0.5s\n",
      "[CV 3/5; 42/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 23\n",
      "5116.88\n",
      "[CV 3/5; 42/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-5116.880 total time=   0.4s\n",
      "[CV 4/5; 42/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 32\n",
      "5291.73\n",
      "[CV 4/5; 42/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-5291.730 total time=   0.4s\n",
      "[CV 5/5; 42/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 42\n",
      "12232.750000000002\n",
      "[CV 5/5; 42/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-12232.750 total time=   0.6s\n",
      "[CV 1/5; 43/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "3040.249999999999\n",
      "[CV 1/5; 43/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-3040.250 total time=  14.2s\n",
      "[CV 2/5; 43/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 23\n",
      "4754.750000000001\n",
      "[CV 2/5; 43/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-4754.750 total time=  14.4s\n",
      "[CV 3/5; 43/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1948.15\n",
      "[CV 3/5; 43/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1948.150 total time=  14.5s\n",
      "[CV 4/5; 43/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "2211.34\n",
      "[CV 4/5; 43/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2211.340 total time=  15.1s\n",
      "[CV 5/5; 43/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "1772.9299999999998\n",
      "[CV 5/5; 43/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1772.930 total time=  14.8s\n",
      "[CV 1/5; 44/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 17\n",
      "3271.2999999999993\n",
      "[CV 1/5; 44/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3271.300 total time=   1.2s\n",
      "[CV 2/5; 44/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4523.800000000001\n",
      "[CV 2/5; 44/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4523.800 total time=   1.5s\n",
      "[CV 3/5; 44/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2913.66\n",
      "[CV 3/5; 44/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2913.660 total time=   1.6s\n",
      "[CV 4/5; 44/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 19\n",
      "3024.71\n",
      "[CV 4/5; 44/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3024.710 total time=   0.8s\n",
      "[CV 5/5; 44/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "6449.5\n",
      "[CV 5/5; 44/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-6449.500 total time=   1.7s\n",
      "[CV 1/5; 45/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 16\n",
      "3220.2999999999993\n",
      "[CV 1/5; 45/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-3220.300 total time=   2.0s\n",
      "[CV 2/5; 45/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "4483.800000000001\n",
      "[CV 2/5; 45/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4483.800 total time=   2.0s\n",
      "[CV 3/5; 45/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "3129.66\n",
      "[CV 3/5; 45/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-3129.660 total time=   2.0s\n",
      "[CV 4/5; 45/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 16\n",
      "2662.95\n",
      "[CV 4/5; 45/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2662.950 total time=   2.1s\n",
      "[CV 5/5; 45/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 24\n",
      "6084.799999999999\n",
      "[CV 5/5; 45/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-6084.800 total time=   2.1s\n",
      "[CV 1/5; 46/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 46/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 46/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 46/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 46/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 46/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 46/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 46/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 46/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 46/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 47/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 47/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 47/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 47/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 47/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 47/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 47/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 47/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 47/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 47/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 48/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 48/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 48/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 48/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 48/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 48/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 48/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 48/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 48/192] START C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 48/192] END C=0.0001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 49/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 49/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  14.0s\n",
      "[CV 2/5; 49/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 49/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  13.5s\n",
      "[CV 3/5; 49/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 49/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  13.4s\n",
      "[CV 4/5; 49/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 49/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  13.5s\n",
      "[CV 5/5; 49/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 49/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  12.0s\n",
      "[CV 1/5; 50/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 50/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.6s\n",
      "[CV 2/5; 50/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 50/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.5s\n",
      "[CV 3/5; 50/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 50/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   1.6s\n",
      "[CV 4/5; 50/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 50/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   1.6s\n",
      "[CV 5/5; 50/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 50/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.6s\n",
      "[CV 1/5; 51/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 51/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 51/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 51/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 51/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 51/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 51/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 51/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 51/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 51/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 52/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 52/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 52/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 52/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 52/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 52/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 52/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 52/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 52/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 52/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 53/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 53/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 53/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 53/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 53/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 53/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 53/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 53/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 53/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 53/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 54/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 20\n",
      "2723.0699999999997\n",
      "[CV 1/5; 54/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2723.070 total time=   0.8s\n",
      "[CV 2/5; 54/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 21\n",
      "4388.980000000001\n",
      "[CV 2/5; 54/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-4388.980 total time=   1.0s\n",
      "[CV 3/5; 54/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 17\n",
      "2287.7\n",
      "[CV 3/5; 54/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2287.700 total time=   0.6s\n",
      "[CV 4/5; 54/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 20\n",
      "2852.61\n",
      "[CV 4/5; 54/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2852.610 total time=   0.8s\n",
      "[CV 5/5; 54/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 27\n",
      "6012.6\n",
      "[CV 5/5; 54/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-6012.600 total time=   1.1s\n",
      "[CV 1/5; 55/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "3040.249999999999\n",
      "[CV 1/5; 55/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-3040.250 total time=  13.9s\n",
      "[CV 2/5; 55/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 20\n",
      "4607.270000000001\n",
      "[CV 2/5; 55/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4607.270 total time=  13.3s\n",
      "[CV 3/5; 55/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1948.15\n",
      "[CV 3/5; 55/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1948.150 total time=  13.6s\n",
      "[CV 4/5; 55/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "2201.34\n",
      "[CV 4/5; 55/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2201.340 total time=  13.9s\n",
      "[CV 5/5; 55/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "1777.9299999999998\n",
      "[CV 5/5; 55/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1777.930 total time=  12.6s\n",
      "[CV 1/5; 56/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 15\n",
      "2949.539999999999\n",
      "[CV 1/5; 56/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2949.540 total time=   1.2s\n",
      "[CV 2/5; 56/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 20\n",
      "4485.02\n",
      "[CV 2/5; 56/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4485.020 total time=   1.5s\n",
      "[CV 3/5; 56/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2194.66\n",
      "[CV 3/5; 56/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2194.660 total time=   1.6s\n",
      "[CV 4/5; 56/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 19\n",
      "2979.71\n",
      "[CV 4/5; 56/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2979.710 total time=   0.9s\n",
      "[CV 5/5; 56/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 22\n",
      "5820.76\n",
      "[CV 5/5; 56/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-5820.760 total time=   1.5s\n",
      "[CV 1/5; 57/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 16\n",
      "2805.2999999999993\n",
      "[CV 1/5; 57/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2805.300 total time=   2.4s\n",
      "[CV 2/5; 57/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "4208.800000000001\n",
      "[CV 2/5; 57/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4208.800 total time=   2.3s\n",
      "[CV 3/5; 57/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2078.66\n",
      "[CV 3/5; 57/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2078.660 total time=   2.4s\n",
      "[CV 4/5; 57/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 16\n",
      "2291.34\n",
      "[CV 4/5; 57/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2291.340 total time=   2.6s\n",
      "[CV 5/5; 57/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 22\n",
      "4429.029999999999\n",
      "[CV 5/5; 57/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4429.030 total time=   2.2s\n",
      "[CV 1/5; 58/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 58/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 58/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 58/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 58/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 58/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 58/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 58/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 58/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 58/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 59/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 59/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 59/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 59/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 59/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 59/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 59/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 59/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 59/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 59/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 60/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 60/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 60/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 60/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 60/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 60/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 60/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 60/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 60/192] START C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 60/192] END C=0.001, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 61/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 61/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  13.6s\n",
      "[CV 2/5; 61/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 61/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  13.5s\n",
      "[CV 3/5; 61/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 61/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  14.1s\n",
      "[CV 4/5; 61/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 61/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  13.6s\n",
      "[CV 5/5; 61/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 61/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  13.1s\n",
      "[CV 1/5; 62/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 62/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   1.5s\n",
      "[CV 2/5; 62/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 62/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   1.5s\n",
      "[CV 3/5; 62/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 62/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.5s\n",
      "[CV 4/5; 62/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 62/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.6s\n",
      "[CV 5/5; 62/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 62/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.5s\n",
      "[CV 1/5; 63/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 63/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 63/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 63/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 63/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 63/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 63/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 63/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 63/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 63/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 64/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 64/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 64/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 64/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 64/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 64/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 64/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 64/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 64/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 64/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 65/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 65/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 65/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 65/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 65/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 65/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 65/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 65/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 65/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 65/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 66/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "2811.249999999999\n",
      "[CV 1/5; 66/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2811.250 total time=   0.7s\n",
      "[CV 2/5; 66/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 18\n",
      "4228.800000000001\n",
      "[CV 2/5; 66/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-4228.800 total time=   0.6s\n",
      "[CV 3/5; 66/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 13\n",
      "2053.15\n",
      "[CV 3/5; 66/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2053.150 total time=   0.8s\n",
      "[CV 4/5; 66/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2324.34\n",
      "[CV 4/5; 66/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2324.340 total time=   0.8s\n",
      "[CV 5/5; 66/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 19\n",
      "2914.2\n",
      "[CV 5/5; 66/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2914.200 total time=   0.9s\n",
      "[CV 1/5; 67/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2740.249999999999\n",
      "[CV 1/5; 67/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2740.250 total time=  13.7s\n",
      "[CV 2/5; 67/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4442.24\n",
      "[CV 2/5; 67/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-4442.240 total time=  13.7s\n",
      "[CV 3/5; 67/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2027.15\n",
      "[CV 3/5; 67/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2027.150 total time=  13.7s\n",
      "[CV 4/5; 67/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2258.1200000000003\n",
      "[CV 4/5; 67/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2258.120 total time=  13.6s\n",
      "[CV 5/5; 67/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1710.1\n",
      "[CV 5/5; 67/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1710.100 total time=  13.2s\n",
      "[CV 1/5; 68/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3240.539999999999\n",
      "[CV 1/5; 68/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3240.540 total time=   1.6s\n",
      "[CV 2/5; 68/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 18\n",
      "4718.800000000001\n",
      "[CV 2/5; 68/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4718.800 total time=   1.2s\n",
      "[CV 3/5; 68/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2757.15\n",
      "[CV 3/5; 68/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2757.150 total time=   1.4s\n",
      "[CV 4/5; 68/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2849.58\n",
      "[CV 4/5; 68/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2849.580 total time=   1.5s\n",
      "[CV 5/5; 68/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "8349.17\n",
      "[CV 5/5; 68/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-8349.170 total time=   1.6s\n",
      "[CV 1/5; 69/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 15\n",
      "3064.539999999999\n",
      "[CV 1/5; 69/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-3064.540 total time=   2.9s\n",
      "[CV 2/5; 69/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "4343.800000000001\n",
      "[CV 2/5; 69/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4343.800 total time=   2.2s\n",
      "[CV 3/5; 69/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "2278.15\n",
      "[CV 3/5; 69/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2278.150 total time=   2.5s\n",
      "[CV 4/5; 69/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2504.34\n",
      "[CV 4/5; 69/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2504.340 total time=   2.4s\n",
      "[CV 5/5; 69/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "3175.0600000000004\n",
      "[CV 5/5; 69/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-3175.060 total time=   2.1s\n",
      "[CV 1/5; 70/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 70/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 70/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 70/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 70/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 70/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 70/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 70/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 70/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 70/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 71/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 71/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 71/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 71/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 71/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 71/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 71/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 71/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 71/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 71/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 72/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 72/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 72/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 72/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 72/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 72/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 72/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 72/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 72/192] START C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 72/192] END C=0.001, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 73/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 73/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  12.5s\n",
      "[CV 2/5; 73/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 73/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  12.6s\n",
      "[CV 3/5; 73/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 73/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  12.6s\n",
      "[CV 4/5; 73/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 73/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  12.8s\n",
      "[CV 5/5; 73/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 73/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  10.3s\n",
      "[CV 1/5; 74/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 74/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.3s\n",
      "[CV 2/5; 74/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 74/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.3s\n",
      "[CV 3/5; 74/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 74/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   1.3s\n",
      "[CV 4/5; 74/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 74/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   1.3s\n",
      "[CV 5/5; 74/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 74/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.3s\n",
      "[CV 1/5; 75/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 75/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 75/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 75/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 75/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 75/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 75/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 75/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 75/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 75/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 76/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 76/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 76/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 76/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 76/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 76/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 76/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 76/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 76/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 76/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 77/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 77/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 77/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 77/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 77/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 77/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 77/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 77/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 77/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 77/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 78/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 78/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2695.250 total time=   1.2s\n",
      "[CV 2/5; 78/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 19\n",
      "4423.0\n",
      "[CV 2/5; 78/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-4423.000 total time=   1.3s\n",
      "[CV 3/5; 78/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 13\n",
      "1963.15\n",
      "[CV 3/5; 78/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1963.150 total time=   1.5s\n",
      "[CV 4/5; 78/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "2210.34\n",
      "[CV 4/5; 78/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2210.340 total time=   0.9s\n",
      "[CV 5/5; 78/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 17\n",
      "1777.9299999999998\n",
      "[CV 5/5; 78/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1777.930 total time=   0.9s\n",
      "[CV 1/5; 79/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2690.249999999999\n",
      "[CV 1/5; 79/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2690.250 total time=  10.0s\n",
      "[CV 2/5; 79/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4418.0\n",
      "[CV 2/5; 79/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4418.000 total time=  12.7s\n",
      "[CV 3/5; 79/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1952.15\n",
      "[CV 3/5; 79/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1952.150 total time=  16.2s\n",
      "[CV 4/5; 79/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2223.1200000000003\n",
      "[CV 4/5; 79/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2223.120 total time=  15.6s\n",
      "[CV 5/5; 79/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 79/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1772.890 total time=  15.5s\n",
      "[CV 1/5; 80/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "3059.539999999999\n",
      "[CV 1/5; 80/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3059.540 total time=   1.9s\n",
      "[CV 2/5; 80/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4398.800000000001\n",
      "[CV 2/5; 80/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4398.800 total time=   1.9s\n",
      "[CV 3/5; 80/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 13\n",
      "2293.15\n",
      "[CV 3/5; 80/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2293.150 total time=   1.6s\n",
      "[CV 4/5; 80/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "2508.6000000000004\n",
      "[CV 4/5; 80/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2508.600 total time=   2.1s\n",
      "[CV 5/5; 80/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 20\n",
      "3145.83\n",
      "[CV 5/5; 80/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3145.830 total time=   1.8s\n",
      "[CV 1/5; 81/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 15\n",
      "2679.539999999999\n",
      "[CV 1/5; 81/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2679.540 total time=   4.0s\n",
      "[CV 2/5; 81/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "4128.800000000001\n",
      "[CV 2/5; 81/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4128.800 total time=   4.4s\n",
      "[CV 3/5; 81/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "2083.15\n",
      "[CV 3/5; 81/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2083.150 total time=   3.3s\n",
      "[CV 4/5; 81/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "2341.3300000000004\n",
      "[CV 4/5; 81/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2341.330 total time=   3.9s\n",
      "[CV 5/5; 81/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "2835.0600000000004\n",
      "[CV 5/5; 81/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2835.060 total time=   4.1s\n",
      "[CV 1/5; 82/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 82/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 82/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 82/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 82/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 82/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 82/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 82/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 82/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 82/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 83/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 83/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 83/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 83/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 83/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 83/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 83/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 83/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 83/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 83/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 84/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 84/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 84/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 84/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 84/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 84/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 84/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 84/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 84/192] START C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 84/192] END C=0.01, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 85/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 85/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  19.0s\n",
      "[CV 2/5; 85/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 85/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  18.0s\n",
      "[CV 3/5; 85/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 85/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  18.5s\n",
      "[CV 4/5; 85/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 85/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  17.0s\n",
      "[CV 5/5; 85/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 85/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  17.1s\n",
      "[CV 1/5; 86/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 86/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   2.0s\n",
      "[CV 2/5; 86/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 86/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   2.1s\n",
      "[CV 3/5; 86/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 86/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   2.0s\n",
      "[CV 4/5; 86/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 86/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   2.1s\n",
      "[CV 5/5; 86/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 86/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   2.0s\n",
      "[CV 1/5; 87/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 87/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 87/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 87/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 87/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 87/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 87/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 87/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 87/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 87/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 88/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 88/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 88/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 88/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 88/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 88/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 88/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 88/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 88/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 88/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 89/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 89/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 89/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 89/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 89/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 89/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 89/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 89/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 89/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 89/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 90/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2765.249999999999\n",
      "[CV 1/5; 90/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2765.250 total time=   3.7s\n",
      "[CV 2/5; 90/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 17\n",
      "4168.040000000001\n",
      "[CV 2/5; 90/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-4168.040 total time=   3.7s\n",
      "[CV 3/5; 90/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "2067.15\n",
      "[CV 3/5; 90/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2067.150 total time=   3.8s\n",
      "[CV 4/5; 90/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2278.1200000000003\n",
      "[CV 4/5; 90/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2278.120 total time=   2.8s\n",
      "[CV 5/5; 90/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 13\n",
      "1745.1\n",
      "[CV 5/5; 90/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-1745.100 total time=   2.9s\n",
      "[CV 1/5; 91/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2775.249999999999\n",
      "[CV 1/5; 91/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2775.250 total time=  17.9s\n",
      "[CV 2/5; 91/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3925.1800000000003\n",
      "[CV 2/5; 91/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-3925.180 total time=  20.1s\n",
      "[CV 3/5; 91/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2072.15\n",
      "[CV 3/5; 91/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2072.150 total time=  18.7s\n",
      "[CV 4/5; 91/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2308.1200000000003\n",
      "[CV 4/5; 91/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2308.120 total time=  17.9s\n",
      "[CV 5/5; 91/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1760.1\n",
      "[CV 5/5; 91/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1760.100 total time=  16.6s\n",
      "[CV 1/5; 92/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 14\n",
      "3625.249999999999\n",
      "[CV 1/5; 92/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3625.250 total time=   1.7s\n",
      "[CV 2/5; 92/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 17\n",
      "4832.800000000001\n",
      "[CV 2/5; 92/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4832.800 total time=   1.6s\n",
      "[CV 3/5; 92/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2882.15\n",
      "[CV 3/5; 92/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2882.150 total time=   1.8s\n",
      "[CV 4/5; 92/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 11\n",
      "3132.36\n",
      "[CV 4/5; 92/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3132.360 total time=   1.7s\n",
      "[CV 5/5; 92/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 15\n",
      "2712.89\n",
      "[CV 5/5; 92/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2712.890 total time=   1.7s\n",
      "[CV 1/5; 93/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2885.249999999999\n",
      "[CV 1/5; 93/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2885.250 total time=   5.2s\n",
      "[CV 2/5; 93/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "4293.800000000001\n",
      "[CV 2/5; 93/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4293.800 total time=   4.4s\n",
      "[CV 3/5; 93/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 11\n",
      "2175.16\n",
      "[CV 3/5; 93/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2175.160 total time=   4.2s\n",
      "[CV 4/5; 93/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2298.1200000000003\n",
      "[CV 4/5; 93/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2298.120 total time=   5.3s\n",
      "[CV 5/5; 93/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "1846.1\n",
      "[CV 5/5; 93/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-1846.100 total time=   4.4s\n",
      "[CV 1/5; 94/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 94/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 94/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 94/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 94/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 94/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 94/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 94/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 94/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 94/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 95/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 95/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 95/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 95/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 95/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 95/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 95/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 95/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 95/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 95/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 96/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 96/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 96/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 96/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 96/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 96/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 96/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 96/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 96/192] START C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 96/192] END C=0.01, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 97/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 97/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  16.9s\n",
      "[CV 2/5; 97/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 97/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  16.7s\n",
      "[CV 3/5; 97/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 97/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  16.3s\n",
      "[CV 4/5; 97/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 97/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  17.6s\n",
      "[CV 5/5; 97/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 97/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  16.6s\n",
      "[CV 1/5; 98/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 98/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   2.1s\n",
      "[CV 2/5; 98/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 98/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.8s\n",
      "[CV 3/5; 98/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 98/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   2.0s\n",
      "[CV 4/5; 98/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 98/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   2.0s\n",
      "[CV 5/5; 98/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 98/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.9s\n",
      "[CV 1/5; 99/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 99/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 99/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 99/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 99/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 99/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 99/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 99/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 99/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 99/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 100/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 100/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 100/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 100/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 100/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 100/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 100/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 100/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 100/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 100/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 101/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 101/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 101/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 101/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 101/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 101/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 101/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 101/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 101/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 101/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 102/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 102/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2695.250 total time=   3.8s\n",
      "[CV 2/5; 102/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 102/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-4422.240 total time=   2.2s\n",
      "[CV 3/5; 102/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1957.15\n",
      "[CV 3/5; 102/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1957.150 total time=   4.1s\n",
      "[CV 4/5; 102/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 102/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2328.110 total time=   4.4s\n",
      "[CV 5/5; 102/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 102/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1772.890 total time=   4.3s\n",
      "[CV 1/5; 103/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 103/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2695.250 total time=  16.7s\n",
      "[CV 2/5; 103/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 103/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4422.240 total time=  16.5s\n",
      "[CV 3/5; 103/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1957.15\n",
      "[CV 3/5; 103/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1957.150 total time=  16.1s\n",
      "[CV 4/5; 103/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 103/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2328.110 total time=  15.4s\n",
      "[CV 5/5; 103/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 103/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1772.890 total time=  15.0s\n",
      "[CV 1/5; 104/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "3179.539999999999\n",
      "[CV 1/5; 104/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3179.540 total time=   1.9s\n",
      "[CV 2/5; 104/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4328.800000000001\n",
      "[CV 2/5; 104/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4328.800 total time=   1.8s\n",
      "[CV 3/5; 104/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2198.66\n",
      "[CV 3/5; 104/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2198.660 total time=   1.8s\n",
      "[CV 4/5; 104/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2491.58\n",
      "[CV 4/5; 104/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2491.580 total time=   2.0s\n",
      "[CV 5/5; 104/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 104/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3145.930 total time=   2.0s\n",
      "[CV 1/5; 105/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 15\n",
      "2709.539999999999\n",
      "[CV 1/5; 105/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2709.540 total time=   4.0s\n",
      "[CV 2/5; 105/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "4113.800000000001\n",
      "[CV 2/5; 105/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4113.800 total time=   5.6s\n",
      "[CV 3/5; 105/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "2038.15\n",
      "[CV 3/5; 105/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2038.150 total time=   3.7s\n",
      "[CV 4/5; 105/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "2263.6100000000006\n",
      "[CV 4/5; 105/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2263.610 total time=   3.5s\n",
      "[CV 5/5; 105/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "2935.0600000000004\n",
      "[CV 5/5; 105/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2935.060 total time=   3.9s\n",
      "[CV 1/5; 106/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 106/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 106/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 106/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 106/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 106/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 106/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 106/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 106/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 106/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 107/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 107/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 107/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 107/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 107/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 107/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 107/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 107/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 107/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 107/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 108/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 108/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 108/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 108/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 108/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 108/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 108/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 108/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 108/192] START C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 108/192] END C=0.1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 109/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 109/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  15.9s\n",
      "[CV 2/5; 109/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 109/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  16.3s\n",
      "[CV 3/5; 109/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 109/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  15.7s\n",
      "[CV 4/5; 109/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 109/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  15.5s\n",
      "[CV 5/5; 109/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 109/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  14.8s\n",
      "[CV 1/5; 110/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 110/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   1.9s\n",
      "[CV 2/5; 110/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 110/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   1.8s\n",
      "[CV 3/5; 110/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 110/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.8s\n",
      "[CV 4/5; 110/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 110/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.7s\n",
      "[CV 5/5; 110/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 110/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.6s\n",
      "[CV 1/5; 111/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 111/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 111/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 111/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 111/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 111/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 111/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 111/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 111/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 111/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 112/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 112/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 112/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 112/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 112/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 112/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 112/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 112/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 112/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 112/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 113/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 113/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 113/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 113/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 113/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 113/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 113/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 113/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 113/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 113/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 114/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 114/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2780.250 total time=   2.3s\n",
      "[CV 2/5; 114/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 16\n",
      "3940.1800000000003\n",
      "[CV 2/5; 114/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-3940.180 total time=   5.4s\n",
      "[CV 3/5; 114/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 114/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2070.160 total time=   3.9s\n",
      "[CV 4/5; 114/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2318.1200000000003\n",
      "[CV 4/5; 114/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2318.120 total time=   4.1s\n",
      "[CV 5/5; 114/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1784.1\n",
      "[CV 5/5; 114/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-1784.100 total time=   4.0s\n",
      "[CV 1/5; 115/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 115/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2780.250 total time=  15.9s\n",
      "[CV 2/5; 115/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3950.1800000000003\n",
      "[CV 2/5; 115/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-3950.180 total time=  14.8s\n",
      "[CV 3/5; 115/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2075.16\n",
      "[CV 3/5; 115/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2075.160 total time=  15.4s\n",
      "[CV 4/5; 115/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2323.1200000000003\n",
      "[CV 4/5; 115/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2323.120 total time=  14.6s\n",
      "[CV 5/5; 115/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1765.1\n",
      "[CV 5/5; 115/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1765.100 total time=  14.6s\n",
      "[CV 1/5; 116/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 14\n",
      "3660.249999999999\n",
      "[CV 1/5; 116/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3660.250 total time=   1.4s\n",
      "[CV 2/5; 116/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "4852.800000000001\n",
      "[CV 2/5; 116/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4852.800 total time=   1.5s\n",
      "[CV 3/5; 116/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 12\n",
      "2897.15\n",
      "[CV 3/5; 116/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2897.150 total time=   1.6s\n",
      "[CV 4/5; 116/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2998.15\n",
      "[CV 4/5; 116/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2998.150 total time=   1.6s\n",
      "[CV 5/5; 116/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2727.89\n",
      "[CV 5/5; 116/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2727.890 total time=   1.8s\n",
      "[CV 1/5; 117/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2960.249999999999\n",
      "[CV 1/5; 117/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2960.250 total time=   4.0s\n",
      "[CV 2/5; 117/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "4313.040000000001\n",
      "[CV 2/5; 117/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4313.040 total time=   3.9s\n",
      "[CV 3/5; 117/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 11\n",
      "2145.16\n",
      "[CV 3/5; 117/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2145.160 total time=   3.7s\n",
      "[CV 4/5; 117/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 12\n",
      "2421.1200000000003\n",
      "[CV 4/5; 117/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2421.120 total time=   3.8s\n",
      "[CV 5/5; 117/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "1745.1\n",
      "[CV 5/5; 117/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-1745.100 total time=   4.4s\n",
      "[CV 1/5; 118/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 118/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 118/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 118/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 118/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 118/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 118/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 118/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 118/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 118/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 119/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 119/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 119/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 119/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 119/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 119/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 119/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 119/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 119/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 119/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 120/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 120/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 120/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 120/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 120/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 120/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 120/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 120/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 120/192] START C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 120/192] END C=0.1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 121/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 121/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  14.0s\n",
      "[CV 2/5; 121/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 121/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  13.9s\n",
      "[CV 3/5; 121/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 121/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  14.3s\n",
      "[CV 4/5; 121/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 121/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  13.9s\n",
      "[CV 5/5; 121/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 121/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  13.3s\n",
      "[CV 1/5; 122/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 122/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.7s\n",
      "[CV 2/5; 122/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 122/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.7s\n",
      "[CV 3/5; 122/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 122/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   1.5s\n",
      "[CV 4/5; 122/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 122/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   1.7s\n",
      "[CV 5/5; 122/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 122/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.7s\n",
      "[CV 1/5; 123/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 123/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 123/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 123/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 123/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 123/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 123/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 123/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 123/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 123/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 124/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 124/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 124/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 124/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 124/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 124/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 124/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 124/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 124/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 124/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 125/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 125/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 125/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 125/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 125/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 125/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 125/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 125/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 125/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 125/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 126/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2700.249999999999\n",
      "[CV 1/5; 126/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2700.250 total time=   3.9s\n",
      "[CV 2/5; 126/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 126/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-4422.240 total time=   3.0s\n",
      "[CV 3/5; 126/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1957.15\n",
      "[CV 3/5; 126/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1957.150 total time=   5.1s\n",
      "[CV 4/5; 126/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "2323.1100000000006\n",
      "[CV 4/5; 126/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2323.110 total time=   3.9s\n",
      "[CV 5/5; 126/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 16\n",
      "1807.8899999999999\n",
      "[CV 5/5; 126/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1807.890 total time=   3.1s\n",
      "[CV 1/5; 127/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 127/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2695.250 total time=  12.6s\n",
      "[CV 2/5; 127/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 127/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4422.240 total time=  14.2s\n",
      "[CV 3/5; 127/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 127/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1947.150 total time=  14.4s\n",
      "[CV 4/5; 127/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 127/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2328.110 total time=  15.2s\n",
      "[CV 5/5; 127/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 127/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1772.890 total time=  14.1s\n",
      "[CV 1/5; 128/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2939.539999999999\n",
      "[CV 1/5; 128/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2939.540 total time=   1.9s\n",
      "[CV 2/5; 128/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4348.800000000001\n",
      "[CV 2/5; 128/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4348.800 total time=   2.0s\n",
      "[CV 3/5; 128/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2363.15\n",
      "[CV 3/5; 128/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2363.150 total time=   1.6s\n",
      "[CV 4/5; 128/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2616.58\n",
      "[CV 4/5; 128/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2616.580 total time=   1.8s\n",
      "[CV 5/5; 128/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 128/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3145.930 total time=   1.9s\n",
      "[CV 1/5; 129/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "3125.539999999999\n",
      "[CV 1/5; 129/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-3125.540 total time=   3.7s\n",
      "[CV 2/5; 129/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "4108.800000000001\n",
      "[CV 2/5; 129/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4108.800 total time=   4.5s\n",
      "[CV 3/5; 129/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "2043.15\n",
      "[CV 3/5; 129/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2043.150 total time=   3.7s\n",
      "[CV 4/5; 129/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "2268.6100000000006\n",
      "[CV 4/5; 129/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2268.610 total time=   3.1s\n",
      "[CV 5/5; 129/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "2840.0600000000004\n",
      "[CV 5/5; 129/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2840.060 total time=   3.1s\n",
      "[CV 1/5; 130/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 130/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 130/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 130/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 130/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 130/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 130/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 130/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 130/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 130/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 131/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 131/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 131/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 131/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 131/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 131/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 131/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 131/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 131/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 131/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 132/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 132/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 132/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 132/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 132/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 132/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 132/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 132/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 132/192] START C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 132/192] END C=1, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 133/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 133/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  16.5s\n",
      "[CV 2/5; 133/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 133/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  15.8s\n",
      "[CV 3/5; 133/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 133/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  17.0s\n",
      "[CV 4/5; 133/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 133/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  17.0s\n",
      "[CV 5/5; 133/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 133/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  15.4s\n",
      "[CV 1/5; 134/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 134/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   2.2s\n",
      "[CV 2/5; 134/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 134/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   1.8s\n",
      "[CV 3/5; 134/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 134/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.8s\n",
      "[CV 4/5; 134/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 134/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.8s\n",
      "[CV 5/5; 134/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 134/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.9s\n",
      "[CV 1/5; 135/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 135/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 135/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 135/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 135/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 135/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 135/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 135/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 135/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 135/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 136/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 136/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 136/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 136/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 136/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 136/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 136/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 136/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 136/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 136/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 137/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 137/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 137/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 137/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 137/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 137/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 137/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 137/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 137/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 137/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 138/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 138/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2780.250 total time=   3.9s\n",
      "[CV 2/5; 138/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 17\n",
      "4264.38\n",
      "[CV 2/5; 138/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-4264.380 total time=   6.4s\n",
      "[CV 3/5; 138/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 11\n",
      "2085.16\n",
      "[CV 3/5; 138/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2085.160 total time=   4.5s\n",
      "[CV 4/5; 138/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2333.1200000000003\n",
      "[CV 4/5; 138/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2333.120 total time=   2.0s\n",
      "[CV 5/5; 138/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1784.1\n",
      "[CV 5/5; 138/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-1784.100 total time=   4.8s\n",
      "[CV 1/5; 139/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 139/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2780.250 total time=  15.4s\n",
      "[CV 2/5; 139/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 139/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-3955.180 total time=  17.3s\n",
      "[CV 3/5; 139/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2075.16\n",
      "[CV 3/5; 139/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2075.160 total time=  17.2s\n",
      "[CV 4/5; 139/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2338.1200000000003\n",
      "[CV 4/5; 139/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2338.120 total time=  16.6s\n",
      "[CV 5/5; 139/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1784.1\n",
      "[CV 5/5; 139/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1784.100 total time=  16.5s\n",
      "[CV 1/5; 140/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3520.249999999999\n",
      "[CV 1/5; 140/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3520.250 total time=   1.7s\n",
      "[CV 2/5; 140/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "4842.800000000001\n",
      "[CV 2/5; 140/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4842.800 total time=   1.9s\n",
      "[CV 3/5; 140/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2832.15\n",
      "[CV 3/5; 140/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2832.150 total time=   2.0s\n",
      "[CV 4/5; 140/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2874.15\n",
      "[CV 4/5; 140/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2874.150 total time=   2.3s\n",
      "[CV 5/5; 140/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2707.89\n",
      "[CV 5/5; 140/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2707.890 total time=   1.7s\n",
      "[CV 1/5; 141/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2960.249999999999\n",
      "[CV 1/5; 141/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2960.250 total time=   3.8s\n",
      "[CV 2/5; 141/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "4313.040000000001\n",
      "[CV 2/5; 141/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4313.040 total time=   4.1s\n",
      "[CV 3/5; 141/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 11\n",
      "2145.16\n",
      "[CV 3/5; 141/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2145.160 total time=   2.8s\n",
      "[CV 4/5; 141/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 12\n",
      "2397.9100000000003\n",
      "[CV 4/5; 141/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2397.910 total time=   2.9s\n",
      "[CV 5/5; 141/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "1781.1\n",
      "[CV 5/5; 141/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-1781.100 total time=   5.4s\n",
      "[CV 1/5; 142/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 142/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 142/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 142/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 142/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 142/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 142/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 142/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 142/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 142/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 143/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 143/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 143/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 143/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 143/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 143/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 143/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 143/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 143/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 143/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 144/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 144/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 144/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 144/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 144/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 144/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 144/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 144/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 144/192] START C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 144/192] END C=1, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 145/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 145/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  16.6s\n",
      "[CV 2/5; 145/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 145/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  16.7s\n",
      "[CV 3/5; 145/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 145/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  17.3s\n",
      "[CV 4/5; 145/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 145/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  16.3s\n",
      "[CV 5/5; 145/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 145/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  15.1s\n",
      "[CV 1/5; 146/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 146/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.9s\n",
      "[CV 2/5; 146/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 146/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   2.1s\n",
      "[CV 3/5; 146/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 146/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   2.0s\n",
      "[CV 4/5; 146/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 146/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   2.0s\n",
      "[CV 5/5; 146/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 146/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   1.7s\n",
      "[CV 1/5; 147/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 147/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 147/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 147/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 147/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 147/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 147/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 147/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 147/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 147/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 148/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 148/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 148/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 148/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 148/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 148/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 148/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 148/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 148/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 148/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 149/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 149/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 149/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 149/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 149/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 149/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 149/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 149/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 149/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 149/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 150/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2700.249999999999\n",
      "[CV 1/5; 150/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2700.250 total time=   3.6s\n",
      "[CV 2/5; 150/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 18\n",
      "4427.24\n",
      "[CV 2/5; 150/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-4427.240 total time=   5.9s\n",
      "[CV 3/5; 150/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1952.15\n",
      "[CV 3/5; 150/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1952.150 total time=   6.0s\n",
      "[CV 4/5; 150/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "2323.1100000000006\n",
      "[CV 4/5; 150/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2323.110 total time=   5.0s\n",
      "[CV 5/5; 150/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 16\n",
      "1807.8899999999999\n",
      "[CV 5/5; 150/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1807.890 total time=   3.3s\n",
      "[CV 1/5; 151/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 151/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2695.250 total time=  14.8s\n",
      "[CV 2/5; 151/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 151/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4422.240 total time=  15.5s\n",
      "[CV 3/5; 151/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 151/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1947.150 total time=  15.2s\n",
      "[CV 4/5; 151/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 151/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2328.110 total time=  15.8s\n",
      "[CV 5/5; 151/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "1768.8899999999999\n",
      "[CV 5/5; 151/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1768.890 total time=  13.6s\n",
      "[CV 1/5; 152/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2939.539999999999\n",
      "[CV 1/5; 152/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2939.540 total time=   1.7s\n",
      "[CV 2/5; 152/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4418.800000000001\n",
      "[CV 2/5; 152/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4418.800 total time=   2.1s\n",
      "[CV 3/5; 152/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2338.15\n",
      "[CV 3/5; 152/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2338.150 total time=   1.9s\n",
      "[CV 4/5; 152/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "2723.8300000000004\n",
      "[CV 4/5; 152/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2723.830 total time=   1.8s\n",
      "[CV 5/5; 152/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 152/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3145.930 total time=   1.6s\n",
      "[CV 1/5; 153/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "3125.539999999999\n",
      "[CV 1/5; 153/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-3125.540 total time=   3.7s\n",
      "[CV 2/5; 153/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 18\n",
      "4108.800000000001\n",
      "[CV 2/5; 153/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4108.800 total time=   6.5s\n",
      "[CV 3/5; 153/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "2043.15\n",
      "[CV 3/5; 153/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2043.150 total time=   3.8s\n",
      "[CV 4/5; 153/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "2268.6100000000006\n",
      "[CV 4/5; 153/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2268.610 total time=   3.8s\n",
      "[CV 5/5; 153/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "2840.0600000000004\n",
      "[CV 5/5; 153/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2840.060 total time=   3.4s\n",
      "[CV 1/5; 154/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 154/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 154/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 154/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 154/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 154/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 154/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 154/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 154/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 154/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 155/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 155/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 155/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 155/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 155/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 155/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 155/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 155/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 155/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 155/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 156/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 156/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 156/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 156/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 156/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 156/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 156/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 156/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 156/192] START C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 156/192] END C=10, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 157/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 157/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  16.9s\n",
      "[CV 2/5; 157/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 157/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  17.0s\n",
      "[CV 3/5; 157/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 157/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  16.3s\n",
      "[CV 4/5; 157/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 157/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  16.4s\n",
      "[CV 5/5; 157/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 157/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  15.4s\n",
      "[CV 1/5; 158/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 158/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   1.9s\n",
      "[CV 2/5; 158/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 158/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   2.0s\n",
      "[CV 3/5; 158/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 158/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.6s\n",
      "[CV 4/5; 158/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 158/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.9s\n",
      "[CV 5/5; 158/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 158/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.8s\n",
      "[CV 1/5; 159/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 159/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 159/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 159/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 159/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 159/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 159/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 159/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 159/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 159/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 160/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 160/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 160/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 160/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 160/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 160/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 160/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 160/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 160/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 160/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 161/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 161/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 161/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 161/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 161/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 161/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 161/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 161/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 161/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 161/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 162/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 162/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2780.250 total time=   5.1s\n",
      "[CV 2/5; 162/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 17\n",
      "4264.38\n",
      "[CV 2/5; 162/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-4264.380 total time=   8.4s\n",
      "[CV 3/5; 162/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 11\n",
      "2085.16\n",
      "[CV 3/5; 162/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2085.160 total time=   3.9s\n",
      "[CV 4/5; 162/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 162/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2328.120 total time=   4.0s\n",
      "[CV 5/5; 162/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1784.1\n",
      "[CV 5/5; 162/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-1784.100 total time=   3.9s\n",
      "[CV 1/5; 163/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 163/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2780.250 total time=  15.1s\n",
      "[CV 2/5; 163/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "4264.38\n",
      "[CV 2/5; 163/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-4264.380 total time=  14.0s\n",
      "[CV 3/5; 163/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2080.16\n",
      "[CV 3/5; 163/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2080.160 total time=  15.3s\n",
      "[CV 4/5; 163/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2333.1200000000003\n",
      "[CV 4/5; 163/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2333.120 total time=  16.3s\n",
      "[CV 5/5; 163/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1765.1\n",
      "[CV 5/5; 163/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1765.100 total time=  15.9s\n",
      "[CV 1/5; 164/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 14\n",
      "3660.249999999999\n",
      "[CV 1/5; 164/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3660.250 total time=   1.5s\n",
      "[CV 2/5; 164/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 17\n",
      "4847.800000000001\n",
      "[CV 2/5; 164/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4847.800 total time=   1.3s\n",
      "[CV 3/5; 164/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2897.15\n",
      "[CV 3/5; 164/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2897.150 total time=   1.5s\n",
      "[CV 4/5; 164/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2879.15\n",
      "[CV 4/5; 164/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2879.150 total time=   1.8s\n",
      "[CV 5/5; 164/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 164/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2737.890 total time=   1.7s\n",
      "[CV 1/5; 165/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2935.249999999999\n",
      "[CV 1/5; 165/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2935.250 total time=   3.1s\n",
      "[CV 2/5; 165/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "4303.040000000001\n",
      "[CV 2/5; 165/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4303.040 total time=   3.5s\n",
      "[CV 3/5; 165/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 11\n",
      "2145.16\n",
      "[CV 3/5; 165/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2145.160 total time=   2.9s\n",
      "[CV 4/5; 165/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2408.1200000000003\n",
      "[CV 4/5; 165/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2408.120 total time=   4.5s\n",
      "[CV 5/5; 165/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "1750.1\n",
      "[CV 5/5; 165/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-1750.100 total time=   3.8s\n",
      "[CV 1/5; 166/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 166/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 166/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 166/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 166/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 166/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 166/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 166/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 166/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 166/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 167/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 167/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 167/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 167/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 167/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 167/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 167/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 167/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 167/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 167/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 168/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 168/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 168/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 168/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 168/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 168/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 168/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 168/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 168/192] START C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 168/192] END C=10, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 169/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 169/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2695.250 total time=  15.1s\n",
      "[CV 2/5; 169/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 169/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-4422.240 total time=  14.7s\n",
      "[CV 3/5; 169/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 169/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1947.150 total time=  15.7s\n",
      "[CV 4/5; 169/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 169/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-2328.110 total time=  15.0s\n",
      "[CV 5/5; 169/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 169/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=newton-cg;, score=-1772.890 total time=  14.4s\n",
      "[CV 1/5; 170/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3205.249999999999\n",
      "[CV 1/5; 170/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3205.250 total time=   1.6s\n",
      "[CV 2/5; 170/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4423.800000000001\n",
      "[CV 2/5; 170/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-4423.800 total time=   1.6s\n",
      "[CV 3/5; 170/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2368.15\n",
      "[CV 3/5; 170/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2368.150 total time=   1.8s\n",
      "[CV 4/5; 170/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2771.36\n",
      "[CV 4/5; 170/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-2771.360 total time=   1.9s\n",
      "[CV 5/5; 170/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 170/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=lbfgs;, score=-3145.930 total time=   2.0s\n",
      "[CV 1/5; 171/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 171/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 171/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 171/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 171/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 171/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 171/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 171/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 171/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 171/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 172/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 172/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 172/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 172/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 172/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 172/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 172/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 172/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 172/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 172/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 173/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 173/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 173/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 173/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 173/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 173/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 173/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 173/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 173/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 173/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 174/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2700.249999999999\n",
      "[CV 1/5; 174/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2700.250 total time=   3.3s\n",
      "[CV 2/5; 174/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 18\n",
      "4427.24\n",
      "[CV 2/5; 174/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-4427.240 total time=   3.0s\n",
      "[CV 3/5; 174/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1952.15\n",
      "[CV 3/5; 174/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1952.150 total time=   2.7s\n",
      "[CV 4/5; 174/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 15\n",
      "2323.1100000000006\n",
      "[CV 4/5; 174/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-2323.110 total time=   3.7s\n",
      "[CV 5/5; 174/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 16\n",
      "1807.8899999999999\n",
      "[CV 5/5; 174/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l1, solver=liblinear;, score=-1807.890 total time=   4.2s\n",
      "[CV 1/5; 175/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2695.249999999999\n",
      "[CV 1/5; 175/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2695.250 total time=  15.5s\n",
      "[CV 2/5; 175/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4422.24\n",
      "[CV 2/5; 175/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-4422.240 total time=  16.1s\n",
      "[CV 3/5; 175/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "1947.15\n",
      "[CV 3/5; 175/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1947.150 total time=  14.8s\n",
      "[CV 4/5; 175/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2328.1100000000006\n",
      "[CV 4/5; 175/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-2328.110 total time=  15.7s\n",
      "[CV 5/5; 175/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "1772.8899999999999\n",
      "[CV 5/5; 175/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=newton-cg;, score=-1772.890 total time=  15.3s\n",
      "[CV 1/5; 176/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2939.539999999999\n",
      "[CV 1/5; 176/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2939.540 total time=   2.2s\n",
      "[CV 2/5; 176/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4513.800000000001\n",
      "[CV 2/5; 176/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-4513.800 total time=   2.0s\n",
      "[CV 3/5; 176/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2253.15\n",
      "[CV 3/5; 176/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2253.150 total time=   2.0s\n",
      "[CV 4/5; 176/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2566.58\n",
      "[CV 4/5; 176/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-2566.580 total time=   1.7s\n",
      "[CV 5/5; 176/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3145.9300000000003\n",
      "[CV 5/5; 176/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=lbfgs;, score=-3145.930 total time=   1.7s\n",
      "[CV 1/5; 177/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "3125.539999999999\n",
      "[CV 1/5; 177/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-3125.540 total time=   3.4s\n",
      "[CV 2/5; 177/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "4163.800000000001\n",
      "[CV 2/5; 177/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-4163.800 total time=   3.4s\n",
      "[CV 3/5; 177/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 13\n",
      "2043.15\n",
      "[CV 3/5; 177/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2043.150 total time=   3.2s\n",
      "[CV 4/5; 177/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "2268.6100000000006\n",
      "[CV 4/5; 177/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2268.610 total time=   3.1s\n",
      "[CV 5/5; 177/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 19\n",
      "2840.0600000000004\n",
      "[CV 5/5; 177/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=l2, solver=liblinear;, score=-2840.060 total time=   3.7s\n",
      "[CV 1/5; 178/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 178/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 178/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 178/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 178/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 178/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 178/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 178/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 178/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 178/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 179/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 179/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 179/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 179/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 179/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 179/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 179/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 179/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 179/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 179/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 180/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 180/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 180/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 180/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 180/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 180/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 180/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 180/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 180/192] START C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 180/192] END C=100, class_weight={0: 1.0, 1: 10.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 181/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 181/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2780.250 total time=  17.1s\n",
      "[CV 2/5; 181/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 181/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-3955.180 total time=  16.6s\n",
      "[CV 3/5; 181/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 181/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2070.160 total time=  17.6s\n",
      "[CV 4/5; 181/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2328.1200000000003\n",
      "[CV 4/5; 181/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-2328.120 total time=  17.5s\n",
      "[CV 5/5; 181/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 181/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=newton-cg;, score=-1775.100 total time=  16.1s\n",
      "[CV 1/5; 182/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "3185.249999999999\n",
      "[CV 1/5; 182/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-3185.250 total time=   2.0s\n",
      "[CV 2/5; 182/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "4698.800000000001\n",
      "[CV 2/5; 182/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-4698.800 total time=   1.7s\n",
      "[CV 3/5; 182/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 182/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2912.150 total time=   1.7s\n",
      "[CV 4/5; 182/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2979.1400000000003\n",
      "[CV 4/5; 182/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2979.140 total time=   1.8s\n",
      "[CV 5/5; 182/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2737.89\n",
      "[CV 5/5; 182/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=lbfgs;, score=-2737.890 total time=   1.9s\n",
      "[CV 1/5; 183/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 1/5; 183/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 183/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 2/5; 183/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 183/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 3/5; 183/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 183/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 4/5; 183/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 183/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear\n",
      "[CV 5/5; 183/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 184/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 1/5; 184/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 184/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 2/5; 184/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 184/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 3/5; 184/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 184/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 4/5; 184/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 184/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg\n",
      "[CV 5/5; 184/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 185/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 1/5; 185/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 185/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 2/5; 185/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 185/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 3/5; 185/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 185/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 4/5; 185/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 185/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs\n",
      "[CV 5/5; 185/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 186/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 186/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2780.250 total time=   3.2s\n",
      "[CV 2/5; 186/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 16\n",
      "3955.1800000000003\n",
      "[CV 2/5; 186/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-3955.180 total time=   2.3s\n",
      "[CV 3/5; 186/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 11\n",
      "2085.16\n",
      "[CV 3/5; 186/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2085.160 total time=   4.1s\n",
      "[CV 4/5; 186/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 14\n",
      "2338.1200000000003\n",
      "[CV 4/5; 186/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-2338.120 total time=   3.2s\n",
      "[CV 5/5; 186/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear\n",
      "No of FN: 12\n",
      "1784.1\n",
      "[CV 5/5; 186/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l1, solver=liblinear;, score=-1784.100 total time=   3.9s\n",
      "[CV 1/5; 187/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2780.249999999999\n",
      "[CV 1/5; 187/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2780.250 total time=  17.2s\n",
      "[CV 2/5; 187/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 17\n",
      "4264.38\n",
      "[CV 2/5; 187/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-4264.380 total time=  16.6s\n",
      "[CV 3/5; 187/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2070.16\n",
      "[CV 3/5; 187/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2070.160 total time=  16.3s\n",
      "[CV 4/5; 187/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2333.1200000000003\n",
      "[CV 4/5; 187/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-2333.120 total time=  16.8s\n",
      "[CV 5/5; 187/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "1775.1\n",
      "[CV 5/5; 187/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=newton-cg;, score=-1775.100 total time=  16.0s\n",
      "[CV 1/5; 188/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "3224.539999999999\n",
      "[CV 1/5; 188/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3224.540 total time=   1.8s\n",
      "[CV 2/5; 188/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4478.800000000001\n",
      "[CV 2/5; 188/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-4478.800 total time=   1.8s\n",
      "[CV 3/5; 188/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 12\n",
      "2912.15\n",
      "[CV 3/5; 188/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2912.150 total time=   1.7s\n",
      "[CV 4/5; 188/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n",
      "No of FN: 10\n",
      "3138.15\n",
      "[CV 4/5; 188/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-3138.150 total time=   1.2s\n",
      "[CV 5/5; 188/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 15\n",
      "2747.89\n",
      "[CV 5/5; 188/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=lbfgs;, score=-2747.890 total time=   1.9s\n",
      "[CV 1/5; 189/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2795.249999999999\n",
      "[CV 1/5; 189/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2795.250 total time=   5.2s\n",
      "[CV 2/5; 189/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 17\n",
      "4313.040000000001\n",
      "[CV 2/5; 189/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-4313.040 total time=   4.7s\n",
      "[CV 3/5; 189/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 11\n",
      "2145.16\n",
      "[CV 3/5; 189/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2145.160 total time=   4.0s\n",
      "[CV 4/5; 189/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "2403.1200000000003\n",
      "[CV 4/5; 189/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-2403.120 total time=   4.6s\n",
      "[CV 5/5; 189/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear\n",
      "No of FN: 14\n",
      "1791.1\n",
      "[CV 5/5; 189/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=l2, solver=liblinear;, score=-1791.100 total time=   5.6s\n",
      "[CV 1/5; 190/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/5; 190/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 190/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/5; 190/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 190/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/5; 190/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 190/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 4/5; 190/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 190/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg\n",
      "[CV 5/5; 190/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 191/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 1/5; 191/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 191/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 2/5; 191/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 191/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 3/5; 191/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 191/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 4/5; 191/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 191/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs\n",
      "[CV 5/5; 191/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 192/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/5; 192/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 192/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/5; 192/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 192/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/5; 192/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 192/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 4/5; 192/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 192/192] START C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear\n",
      "[CV 5/5; 192/192] END C=100, class_weight={0: 1.0, 1: 25.0}, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "480 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-2633.128 -3182.898       nan       nan       nan -9824.9   -7602.542\n",
      " -7996.296 -7964.096       nan       nan       nan -2581.762 -3302.646\n",
      "       nan       nan       nan -9824.9   -6226.46  -6626.7   -6512.67\n",
      "       nan       nan       nan -2633.128 -3182.898       nan       nan\n",
      "       nan -8262.95  -4531.268 -5993.756 -5407.628       nan       nan\n",
      "       nan -2581.762 -3302.646       nan       nan       nan -7071.348\n",
      " -2745.484 -4036.594 -3916.302       nan       nan       nan -2633.128\n",
      " -3182.898       nan       nan       nan -3652.992 -2714.988 -3685.938\n",
      " -3162.626       nan       nan       nan -2581.762 -3302.646       nan\n",
      "       nan       nan -2866.348 -2635.572 -4383.048 -3073.178       nan\n",
      "       nan       nan -2633.128 -3182.898       nan       nan       nan\n",
      " -2613.934 -2611.282 -3081.184 -2813.576       nan       nan       nan\n",
      " -2581.762 -3302.646       nan       nan       nan -2604.732 -2568.16\n",
      " -3437.09  -2699.686       nan       nan       nan -2633.128 -3182.898\n",
      "       nan       nan       nan -2635.128 -2635.128 -3068.902 -2812.032\n",
      "       nan       nan       nan -2581.762 -3302.646       nan       nan\n",
      "       nan -2578.562 -2578.762 -3427.248 -2716.934       nan       nan\n",
      "       nan -2633.128 -3182.898       nan       nan       nan -2642.128\n",
      " -2633.128 -3082.8   -2877.232       nan       nan       nan -2581.762\n",
      " -3302.646       nan       nan       nan -2649.402 -2586.562 -3355.448\n",
      " -2719.492       nan       nan       nan -2633.128 -3182.898       nan\n",
      "       nan       nan -2642.128 -2632.328 -3113.25  -2877.232       nan\n",
      "       nan       nan -2581.762 -3302.646       nan       nan       nan\n",
      " -2648.402 -2644.602 -3404.448 -2708.334       nan       nan       nan\n",
      " -2633.128 -3182.898       nan       nan       nan -2642.128 -2633.128\n",
      " -3083.8   -2888.232       nan       nan       nan -2581.762 -3302.646\n",
      "       nan       nan       nan -2588.562 -2644.602 -3300.306 -2689.534\n",
      "       nan       nan       nan]\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [-2633.128 -3182.898       nan       nan       nan -9824.9   -7602.542\n",
      " -7996.296 -7964.096       nan       nan       nan -2581.762 -3302.646\n",
      "       nan       nan       nan -9824.9   -6226.46  -6626.7   -6512.67\n",
      "       nan       nan       nan -2633.128 -3182.898       nan       nan\n",
      "       nan -8262.95  -4531.268 -5993.756 -5407.628       nan       nan\n",
      "       nan -2581.762 -3302.646       nan       nan       nan -7071.348\n",
      " -2745.484 -4036.594 -3916.302       nan       nan       nan -2633.128\n",
      " -3182.898       nan       nan       nan -3652.992 -2714.988 -3685.938\n",
      " -3162.626       nan       nan       nan -2581.762 -3302.646       nan\n",
      "       nan       nan -2866.348 -2635.572 -4383.048 -3073.178       nan\n",
      "       nan       nan -2633.128 -3182.898       nan       nan       nan\n",
      " -2613.934 -2611.282 -3081.184 -2813.576       nan       nan       nan\n",
      " -2581.762 -3302.646       nan       nan       nan -2604.732 -2568.16\n",
      " -3437.09  -2699.686       nan       nan       nan -2633.128 -3182.898\n",
      "       nan       nan       nan -2635.128 -2635.128 -3068.902 -2812.032\n",
      "       nan       nan       nan -2581.762 -3302.646       nan       nan\n",
      "       nan -2578.562 -2578.762 -3427.248 -2716.934       nan       nan\n",
      "       nan -2633.128 -3182.898       nan       nan       nan -2642.128\n",
      " -2633.128 -3082.8   -2877.232       nan       nan       nan -2581.762\n",
      " -3302.646       nan       nan       nan -2649.402 -2586.562 -3355.448\n",
      " -2719.492       nan       nan       nan -2633.128 -3182.898       nan\n",
      "       nan       nan -2642.128 -2632.328 -3113.25  -2877.232       nan\n",
      "       nan       nan -2581.762 -3302.646       nan       nan       nan\n",
      " -2648.402 -2644.602 -3404.448 -2708.334       nan       nan       nan\n",
      " -2633.128 -3182.898       nan       nan       nan -2642.128 -2633.128\n",
      " -3083.8   -2888.232       nan       nan       nan -2581.762 -3302.646\n",
      "       nan       nan       nan -2588.562 -2644.602 -3300.306 -2689.534\n",
      "       nan       nan       nan], using {'C': 0.01, 'class_weight': {0: 1.0, 1: 25.0}, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.112594</td>\n",
       "      <td>0.260395</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...</td>\n",
       "      <td>-2695.25</td>\n",
       "      <td>-4422.24</td>\n",
       "      <td>-1947.15</td>\n",
       "      <td>-2328.11</td>\n",
       "      <td>-1772.89</td>\n",
       "      <td>-2633.128</td>\n",
       "      <td>949.567492</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.285382</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...</td>\n",
       "      <td>-3205.25</td>\n",
       "      <td>-4423.80</td>\n",
       "      <td>-2368.15</td>\n",
       "      <td>-2771.36</td>\n",
       "      <td>-3145.93</td>\n",
       "      <td>-3182.898</td>\n",
       "      <td>689.185294</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018002</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019611</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.753214</td>\n",
       "      <td>0.240806</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...</td>\n",
       "      <td>-3224.54</td>\n",
       "      <td>-4478.80</td>\n",
       "      <td>-2912.15</td>\n",
       "      <td>-3138.15</td>\n",
       "      <td>-2747.89</td>\n",
       "      <td>-3300.306</td>\n",
       "      <td>612.651888</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4.910773</td>\n",
       "      <td>0.539586</td>\n",
       "      <td>0.024602</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...</td>\n",
       "      <td>-2795.25</td>\n",
       "      <td>-4313.04</td>\n",
       "      <td>-2145.16</td>\n",
       "      <td>-2403.12</td>\n",
       "      <td>-1791.10</td>\n",
       "      <td>-2689.534</td>\n",
       "      <td>875.500690</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.028799</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.031017</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0        10.112594      0.260395         0.023012        0.000015  0.00001   \n",
       "1         1.285382      0.029357         0.022010        0.000655  0.00001   \n",
       "2         0.018002      0.000027         0.000000        0.000000  0.00001   \n",
       "3         0.019406      0.001850         0.000000        0.000000  0.00001   \n",
       "4         0.019611      0.001351         0.000000        0.000000  0.00001   \n",
       "..             ...           ...              ...             ...      ...   \n",
       "187       1.753214      0.240806         0.024593        0.000796      100   \n",
       "188       4.910773      0.539586         0.024602        0.001007      100   \n",
       "189       0.028799      0.002643         0.000000        0.000000      100   \n",
       "190       0.031017      0.001257         0.000000        0.000000      100   \n",
       "191       0.029784      0.002647         0.000000        0.000000      100   \n",
       "\n",
       "    param_class_weight param_penalty param_solver  \\\n",
       "0    {0: 1.0, 1: 10.0}          none    newton-cg   \n",
       "1    {0: 1.0, 1: 10.0}          none        lbfgs   \n",
       "2    {0: 1.0, 1: 10.0}          none    liblinear   \n",
       "3    {0: 1.0, 1: 10.0}            l1    newton-cg   \n",
       "4    {0: 1.0, 1: 10.0}            l1        lbfgs   \n",
       "..                 ...           ...          ...   \n",
       "187  {0: 1.0, 1: 25.0}            l2        lbfgs   \n",
       "188  {0: 1.0, 1: 25.0}            l2    liblinear   \n",
       "189  {0: 1.0, 1: 25.0}    elasticnet    newton-cg   \n",
       "190  {0: 1.0, 1: 25.0}    elasticnet        lbfgs   \n",
       "191  {0: 1.0, 1: 25.0}    elasticnet    liblinear   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...           -2695.25   \n",
       "1    {'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...           -3205.25   \n",
       "2    {'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...                NaN   \n",
       "3    {'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...                NaN   \n",
       "4    {'C': 1e-05, 'class_weight': {0: 1.0, 1: 10.0}...                NaN   \n",
       "..                                                 ...                ...   \n",
       "187  {'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...           -3224.54   \n",
       "188  {'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...           -2795.25   \n",
       "189  {'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...                NaN   \n",
       "190  {'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...                NaN   \n",
       "191  {'C': 100, 'class_weight': {0: 1.0, 1: 25.0}, ...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             -4422.24           -1947.15           -2328.11   \n",
       "1             -4423.80           -2368.15           -2771.36   \n",
       "2                  NaN                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                  NaN                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "187           -4478.80           -2912.15           -3138.15   \n",
       "188           -4313.04           -2145.16           -2403.12   \n",
       "189                NaN                NaN                NaN   \n",
       "190                NaN                NaN                NaN   \n",
       "191                NaN                NaN                NaN   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             -1772.89        -2633.128      949.567492               18  \n",
       "1             -3145.93        -3182.898      689.185294               58  \n",
       "2                  NaN              NaN             NaN              157  \n",
       "3                  NaN              NaN             NaN              156  \n",
       "4                  NaN              NaN             NaN              155  \n",
       "..                 ...              ...             ...              ...  \n",
       "187           -2747.89        -3300.306      612.651888               66  \n",
       "188           -1791.10        -2689.534      875.500690               38  \n",
       "189                NaN              NaN             NaN               97  \n",
       "190                NaN              NaN             NaN              175  \n",
       "191                NaN              NaN             NaN              192  \n",
       "\n",
       "[192 rows x 17 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ddc76-6a1b-42d1-b3e6-bca697d518ca",
   "metadata": {},
   "source": [
    "# SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ebc8ebb-2531-410d-9396-3e43ce7ca049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def my_scorer_smt(y_true, y_pred):\n",
    "    model_cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    for cls in range(model_cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, model_cm).ravel() \n",
    "        \n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "    X_test_score = X_smt\n",
    "    # X_test_score = get_x_elements_by_indices(X_test_score, y_true.index)\n",
    "    #print(labels[y_true * 2 + y_pred])\n",
    "    #X_test_score['case'] = labels[y_true * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegativeMyScorer(X_test_score, y_true, y_pred) + (FP + TP) * Ca\n",
    "    print(TotalCost)\n",
    "    return TotalCost\n",
    "\n",
    "my_func_smt = make_scorer(my_scorer_smt, greater_is_better=False)\n",
    "\n",
    "#my_scorer(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be83f0-64eb-444c-bbeb-11f0ff2c59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "# DecisionTreeClassifier\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state=42), \n",
    "                              LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0edb9d07-cdc3-4b38-b226-c19dc4eee01c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  18.4s\n",
      "[CV 2/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  18.5s\n",
      "[CV 3/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  18.5s\n",
      "[CV 4/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  17.6s\n",
      "[CV 5/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  18.0s\n",
      "[CV 1/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   2.5s\n",
      "[CV 2/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   2.5s\n",
      "[CV 3/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   1.8s\n",
      "[CV 4/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   1.7s\n",
      "[CV 5/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   2.2s\n",
      "[CV 1/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "47637.21399285662\n",
      "[CV 1/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-47637.214 total time=   1.0s\n",
      "[CV 2/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "51713.88771162684\n",
      "[CV 2/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-51713.888 total time=   0.8s\n",
      "[CV 3/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "60835.84\n",
      "[CV 3/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-60835.840 total time=   0.8s\n",
      "[CV 4/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "59155.95\n",
      "[CV 4/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-59155.950 total time=   0.8s\n",
      "[CV 5/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "62605\n",
      "[CV 5/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-62605.000 total time=   0.9s\n",
      "[CV 1/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16574.483992856618\n",
      "[CV 1/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16574.484 total time=  19.5s\n",
      "[CV 2/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "19463.302822325128\n",
      "[CV 2/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-19463.303 total time=  20.2s\n",
      "[CV 3/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21780.7\n",
      "[CV 3/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21780.700 total time=  19.1s\n",
      "[CV 4/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "19737.833682760935\n",
      "[CV 4/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-19737.834 total time=  18.8s\n",
      "[CV 5/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "22671.95\n",
      "[CV 5/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-22671.950 total time=  19.4s\n",
      "[CV 1/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "21714.023745790666\n",
      "[CV 1/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-21714.024 total time=   2.1s\n",
      "[CV 2/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "25273.302822325128\n",
      "[CV 2/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-25273.303 total time=   2.1s\n",
      "[CV 3/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "27969.26\n",
      "[CV 3/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-27969.260 total time=   2.5s\n",
      "[CV 4/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "31229.833682760935\n",
      "[CV 4/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-31229.834 total time=   1.6s\n",
      "[CV 5/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "33345.54\n",
      "[CV 5/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-33345.540 total time=   1.5s\n",
      "[CV 1/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 2/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226515\n",
      "[CV 2/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226515.000 total time=   1.8s\n",
      "[CV 3/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 4/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   1.6s\n",
      "[CV 5/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.0s\n",
      "[CV 1/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  17.3s\n",
      "[CV 2/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  17.4s\n",
      "[CV 3/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  17.6s\n",
      "[CV 4/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  17.7s\n",
      "[CV 5/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  17.4s\n",
      "[CV 1/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   1.7s\n",
      "[CV 2/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   1.7s\n",
      "[CV 3/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   1.7s\n",
      "[CV 4/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   2.4s\n",
      "[CV 5/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.1s\n",
      "[CV 1/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 1\n",
      "92978.55\n",
      "[CV 1/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-92978.550 total time=   1.0s\n",
      "[CV 2/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 1\n",
      "100740.78\n",
      "[CV 2/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-100740.780 total time=   0.9s\n",
      "[CV 3/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "99855.84\n",
      "[CV 3/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-99855.840 total time=   0.9s\n",
      "[CV 4/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 1\n",
      "99242.25\n",
      "[CV 4/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-99242.250 total time=   0.8s\n",
      "[CV 5/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "114160\n",
      "[CV 5/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-114160.000 total time=   0.9s\n",
      "[CV 1/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "47505.94399285662\n",
      "[CV 1/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-47505.944 total time=  19.7s\n",
      "[CV 2/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "49698.88771162684\n",
      "[CV 2/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-49698.888 total time=  17.2s\n",
      "[CV 3/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "57370.84\n",
      "[CV 3/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-57370.840 total time=  17.0s\n",
      "[CV 4/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 1\n",
      "54593.7\n",
      "[CV 4/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-54593.700 total time=  19.1s\n",
      "[CV 5/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "66500\n",
      "[CV 5/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-66500.000 total time=  20.2s\n",
      "[CV 1/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "51966.553992856614\n",
      "[CV 1/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-51966.554 total time=   2.1s\n",
      "[CV 2/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "51933.88771162684\n",
      "[CV 2/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-51933.888 total time=   2.0s\n",
      "[CV 3/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "59430.84\n",
      "[CV 3/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-59430.840 total time=   2.1s\n",
      "[CV 4/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "57390\n",
      "[CV 4/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-57390.000 total time=   2.3s\n",
      "[CV 5/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "68435\n",
      "[CV 5/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-68435.000 total time=   2.3s\n",
      "[CV 1/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   1.9s\n",
      "[CV 2/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   2.1s\n",
      "[CV 3/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.0s\n",
      "[CV 4/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.1s\n",
      "[CV 5/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   1.5s\n",
      "[CV 1/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  17.7s\n",
      "[CV 2/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  18.2s\n",
      "[CV 3/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  18.5s\n",
      "[CV 4/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  17.5s\n",
      "[CV 5/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  17.9s\n",
      "[CV 1/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   2.5s\n",
      "[CV 2/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   2.4s\n",
      "[CV 3/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   1.8s\n",
      "[CV 4/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   1.7s\n",
      "[CV 5/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   2.2s\n",
      "[CV 1/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "20749.483992856618\n",
      "[CV 1/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-20749.484 total time=   1.1s\n",
      "[CV 2/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "23210.43771162684\n",
      "[CV 2/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-23210.438 total time=   1.1s\n",
      "[CV 3/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "26430.7\n",
      "[CV 3/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26430.700 total time=   1.3s\n",
      "[CV 4/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "24967.213682760932\n",
      "[CV 4/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24967.214 total time=   1.2s\n",
      "[CV 5/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "27495\n",
      "[CV 5/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27495.000 total time=   1.4s\n",
      "[CV 1/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "14359.483992856618\n",
      "[CV 1/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14359.484 total time=  20.1s\n",
      "[CV 2/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "16612.852822325127\n",
      "[CV 2/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16612.853 total time=  20.4s\n",
      "[CV 3/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "18780.7\n",
      "[CV 3/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-18780.700 total time=  20.4s\n",
      "[CV 4/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "17552.833682760935\n",
      "[CV 4/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17552.834 total time=  20.0s\n",
      "[CV 5/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "20161.95\n",
      "[CV 5/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-20161.950 total time=  20.2s\n",
      "[CV 1/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "25279.023745790666\n",
      "[CV 1/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-25279.024 total time=   1.6s\n",
      "[CV 2/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "26493.47521302187\n",
      "[CV 2/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26493.475 total time=   1.6s\n",
      "[CV 3/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "31105.75\n",
      "[CV 3/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-31105.750 total time=   1.7s\n",
      "[CV 4/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "28074.833682760935\n",
      "[CV 4/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-28074.834 total time=   1.7s\n",
      "[CV 5/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "33158.78\n",
      "[CV 5/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-33158.780 total time=   1.6s\n",
      "[CV 1/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 2/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   1.8s\n",
      "[CV 3/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 4/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   1.7s\n",
      "[CV 5/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.0s\n",
      "[CV 1/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  17.3s\n",
      "[CV 2/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  17.8s\n",
      "[CV 3/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  17.4s\n",
      "[CV 4/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  17.4s\n",
      "[CV 5/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  17.1s\n",
      "[CV 1/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   1.7s\n",
      "[CV 2/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   1.7s\n",
      "[CV 3/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   1.7s\n",
      "[CV 4/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   2.4s\n",
      "[CV 5/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.0s\n",
      "[CV 1/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "37619.483992856614\n",
      "[CV 1/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-37619.484 total time=   1.3s\n",
      "[CV 2/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "37958.88771162684\n",
      "[CV 2/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-37958.888 total time=   1.2s\n",
      "[CV 3/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "45930.79\n",
      "[CV 3/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-45930.790 total time=   1.2s\n",
      "[CV 4/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "42475.95\n",
      "[CV 4/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-42475.950 total time=   0.9s\n",
      "[CV 5/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "49205\n",
      "[CV 5/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-49205.000 total time=   1.3s\n",
      "[CV 1/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "28404.483992856618\n",
      "[CV 1/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-28404.484 total time=  19.4s\n",
      "[CV 2/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "31583.88771162684\n",
      "[CV 2/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-31583.888 total time=  19.2s\n",
      "[CV 3/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "34849.26\n",
      "[CV 3/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-34849.260 total time=  19.7s\n",
      "[CV 4/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "33590.43368276094\n",
      "[CV 4/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33590.434 total time=  19.7s\n",
      "[CV 5/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "40415\n",
      "[CV 5/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-40415.000 total time=  18.7s\n",
      "[CV 1/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "45341.803992856614\n",
      "[CV 1/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-45341.804 total time=   1.6s\n",
      "[CV 2/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "49106.03\n",
      "[CV 2/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-49106.030 total time=   1.6s\n",
      "[CV 3/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "44999.26\n",
      "[CV 3/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-44999.260 total time=   2.1s\n",
      "[CV 4/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "53503.26368276093\n",
      "[CV 4/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53503.264 total time=   1.6s\n",
      "[CV 5/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "49480\n",
      "[CV 5/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-49480.000 total time=   2.3s\n",
      "[CV 1/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   1.9s\n",
      "[CV 2/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   2.1s\n",
      "[CV 3/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.0s\n",
      "[CV 4/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.1s\n",
      "[CV 5/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   1.5s\n",
      "[CV 1/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  17.7s\n",
      "[CV 2/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  18.2s\n",
      "[CV 3/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  18.5s\n",
      "[CV 4/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  17.6s\n",
      "[CV 5/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  18.0s\n",
      "[CV 1/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   2.5s\n",
      "[CV 2/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   2.4s\n",
      "[CV 3/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   1.8s\n",
      "[CV 4/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   1.7s\n",
      "[CV 5/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   2.2s\n",
      "[CV 1/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "13601.793992856617\n",
      "[CV 1/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13601.794 total time=   1.7s\n",
      "[CV 2/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "15237.852822325127\n",
      "[CV 2/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15237.853 total time=   1.7s\n",
      "[CV 3/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "17935.75\n",
      "[CV 3/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17935.750 total time=   1.7s\n",
      "[CV 4/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "16885.083682760935\n",
      "[CV 4/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16885.084 total time=   2.6s\n",
      "[CV 5/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "19501.95\n",
      "[CV 5/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-19501.950 total time=   1.5s\n",
      "[CV 1/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "13071.793992856617\n",
      "[CV 1/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13071.794 total time=  18.3s\n",
      "[CV 2/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "14448.852822325127\n",
      "[CV 2/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14448.853 total time=  18.8s\n",
      "[CV 3/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "17215.75\n",
      "[CV 3/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17215.750 total time=  18.8s\n",
      "[CV 4/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "16232.833682760935\n",
      "[CV 4/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16232.834 total time=  18.5s\n",
      "[CV 5/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "18746.95\n",
      "[CV 5/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-18746.950 total time=  18.5s\n",
      "[CV 1/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "26424.023745790666\n",
      "[CV 1/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26424.024 total time=   1.6s\n",
      "[CV 2/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "17028.852822325127\n",
      "[CV 2/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-17028.853 total time=   2.6s\n",
      "[CV 3/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "32115.75\n",
      "[CV 3/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32115.750 total time=   1.8s\n",
      "[CV 4/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "17125.083682760935\n",
      "[CV 4/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-17125.084 total time=   2.5s\n",
      "[CV 5/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "32135.54\n",
      "[CV 5/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32135.540 total time=   1.7s\n",
      "[CV 1/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 2/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   1.8s\n",
      "[CV 3/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 4/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   1.7s\n",
      "[CV 5/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.0s\n",
      "[CV 1/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  17.4s\n",
      "[CV 2/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  17.4s\n",
      "[CV 3/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  17.3s\n",
      "[CV 4/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  17.4s\n",
      "[CV 5/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  17.1s\n",
      "[CV 1/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   1.7s\n",
      "[CV 2/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   1.7s\n",
      "[CV 3/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   1.7s\n",
      "[CV 4/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   2.4s\n",
      "[CV 5/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.0s\n",
      "[CV 1/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "23876.79399285662\n",
      "[CV 1/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-23876.794 total time=   1.8s\n",
      "[CV 2/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "26829.43771162684\n",
      "[CV 2/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26829.438 total time=   1.8s\n",
      "[CV 3/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "31390.84\n",
      "[CV 3/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-31390.840 total time=   1.5s\n",
      "[CV 4/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "29230.553682760932\n",
      "[CV 4/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-29230.554 total time=   2.4s\n",
      "[CV 5/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "35480\n",
      "[CV 5/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-35480.000 total time=   1.7s\n",
      "[CV 1/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "23436.79399285662\n",
      "[CV 1/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-23436.794 total time=  17.3s\n",
      "[CV 2/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "27024.43771162684\n",
      "[CV 2/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27024.438 total time=  17.7s\n",
      "[CV 3/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "30974.26\n",
      "[CV 3/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-30974.260 total time=  17.4s\n",
      "[CV 4/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "29413.303682760932\n",
      "[CV 4/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-29413.304 total time=  17.6s\n",
      "[CV 5/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "35275\n",
      "[CV 5/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-35275.000 total time=  17.9s\n",
      "[CV 1/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "35741.073745790665\n",
      "[CV 1/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-35741.074 total time=   2.2s\n",
      "[CV 2/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46559.88771162684\n",
      "[CV 2/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46559.888 total time=   1.7s\n",
      "[CV 3/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53719.26\n",
      "[CV 3/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53719.260 total time=   1.6s\n",
      "[CV 4/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "35662.43368276094\n",
      "[CV 4/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-35662.434 total time=   2.3s\n",
      "[CV 5/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 1\n",
      "59161.0\n",
      "[CV 5/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-59161.000 total time=   1.7s\n",
      "[CV 1/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.0s\n",
      "[CV 2/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   2.1s\n",
      "[CV 3/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.0s\n",
      "[CV 4/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.1s\n",
      "[CV 5/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   1.5s\n",
      "[CV 1/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  17.6s\n",
      "[CV 2/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  18.3s\n",
      "[CV 3/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  18.4s\n",
      "[CV 4/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  17.6s\n",
      "[CV 5/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  18.3s\n",
      "[CV 1/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   2.7s\n",
      "[CV 2/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   2.6s\n",
      "[CV 3/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   1.8s\n",
      "[CV 4/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   1.7s\n",
      "[CV 5/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   2.2s\n",
      "[CV 1/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "20731.79399285662\n",
      "[CV 1/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-20731.794 total time=   1.0s\n",
      "[CV 2/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "16887.852822325127\n",
      "[CV 2/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16887.853 total time=   1.4s\n",
      "[CV 3/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "17085.75\n",
      "[CV 3/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17085.750 total time=   1.9s\n",
      "[CV 4/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "15001.843682760933\n",
      "[CV 4/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15001.844 total time=   2.9s\n",
      "[CV 5/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "17596.95\n",
      "[CV 5/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17596.950 total time=   3.6s\n",
      "[CV 1/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12746.793992856617\n",
      "[CV 1/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12746.794 total time=  20.8s\n",
      "[CV 2/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13338.852822325127\n",
      "[CV 2/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13338.853 total time=  21.6s\n",
      "[CV 3/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16520.75\n",
      "[CV 3/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16520.750 total time=  20.5s\n",
      "[CV 4/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15361.843682760933\n",
      "[CV 4/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-15361.844 total time=  22.1s\n",
      "[CV 5/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "18266.95\n",
      "[CV 5/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-18266.950 total time=  23.9s\n",
      "[CV 1/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "16791.79399285662\n",
      "[CV 1/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16791.794 total time=   3.1s\n",
      "[CV 2/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "22313.302822325128\n",
      "[CV 2/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-22313.303 total time=   2.6s\n",
      "[CV 3/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32385.75\n",
      "[CV 3/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32385.750 total time=   2.2s\n",
      "[CV 4/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29934.833682760935\n",
      "[CV 4/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29934.834 total time=   2.2s\n",
      "[CV 5/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "20830\n",
      "[CV 5/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-20830.000 total time=   3.3s\n",
      "[CV 1/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.4s\n",
      "[CV 2/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.3s\n",
      "[CV 3/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.4s\n",
      "[CV 4/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.1s\n",
      "[CV 5/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.6s\n",
      "[CV 1/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  23.0s\n",
      "[CV 2/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  23.3s\n",
      "[CV 3/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  23.9s\n",
      "[CV 4/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  24.8s\n",
      "[CV 5/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  24.0s\n",
      "[CV 1/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.4s\n",
      "[CV 2/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.2s\n",
      "[CV 3/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.3s\n",
      "[CV 4/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.4s\n",
      "[CV 5/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.8s\n",
      "[CV 1/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "22266.79399285662\n",
      "[CV 1/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-22266.794 total time=   2.3s\n",
      "[CV 2/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "25977.852822325127\n",
      "[CV 2/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-25977.853 total time=   2.4s\n",
      "[CV 3/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "27860.84\n",
      "[CV 3/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27860.840 total time=   4.2s\n",
      "[CV 4/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "27056.843682760933\n",
      "[CV 4/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27056.844 total time=   2.8s\n",
      "[CV 5/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "33720\n",
      "[CV 5/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-33720.000 total time=   2.7s\n",
      "[CV 1/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21281.79399285662\n",
      "[CV 1/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21281.794 total time=  24.2s\n",
      "[CV 2/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25192.852822325127\n",
      "[CV 2/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-25192.853 total time=  23.9s\n",
      "[CV 3/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "29475.84\n",
      "[CV 3/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-29475.840 total time=  24.4s\n",
      "[CV 4/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27903.303682760932\n",
      "[CV 4/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27903.304 total time=  24.3s\n",
      "[CV 5/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33560\n",
      "[CV 5/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33560.000 total time=  24.5s\n",
      "[CV 1/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42266.803992856614\n",
      "[CV 1/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42266.804 total time=   2.4s\n",
      "[CV 2/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46324.88771162684\n",
      "[CV 2/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46324.888 total time=   2.4s\n",
      "[CV 3/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53134.26\n",
      "[CV 3/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53134.260 total time=   2.5s\n",
      "[CV 4/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34836.963682760936\n",
      "[CV 4/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34836.964 total time=   3.2s\n",
      "[CV 5/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "51010\n",
      "[CV 5/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-51010.000 total time=   3.1s\n",
      "[CV 1/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.8s\n",
      "[CV 2/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.0s\n",
      "[CV 3/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.0s\n",
      "[CV 4/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.4s\n",
      "[CV 5/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.7s\n",
      "[CV 1/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 1/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 2/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 3/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 4/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 5/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  26.1s\n",
      "[CV 2/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  26.7s\n",
      "[CV 3/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  27.8s\n",
      "[CV 4/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  24.8s\n",
      "[CV 5/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  26.4s\n",
      "[CV 1/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   3.5s\n",
      "[CV 2/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   3.5s\n",
      "[CV 3/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   2.6s\n",
      "[CV 4/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.5s\n",
      "[CV 5/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   3.2s\n",
      "[CV 1/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 1/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "12131.793992856617\n",
      "[CV 1/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12131.794 total time=   4.3s\n",
      "[CV 2/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "13423.852822325127\n",
      "[CV 2/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13423.853 total time=   4.2s\n",
      "[CV 3/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16065.75\n",
      "[CV 3/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16065.750 total time=   5.5s\n",
      "[CV 4/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "15744.093682760933\n",
      "[CV 4/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15744.094 total time=   2.7s\n",
      "[CV 5/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "21195.54\n",
      "[CV 5/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21195.540 total time=   1.5s\n",
      "[CV 1/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12251.793992856617\n",
      "[CV 1/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12251.794 total time=  26.0s\n",
      "[CV 2/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13428.852822325127\n",
      "[CV 2/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13428.853 total time=  26.3s\n",
      "[CV 3/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16285.75\n",
      "[CV 3/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16285.750 total time=  26.1s\n",
      "[CV 4/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "14946.843682760933\n",
      "[CV 4/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14946.844 total time=  26.1s\n",
      "[CV 5/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17746.95\n",
      "[CV 5/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17746.950 total time=  25.8s\n",
      "[CV 1/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "17141.79399285662\n",
      "[CV 1/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-17141.794 total time=   4.6s\n",
      "[CV 2/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16878.853 total time=   3.7s\n",
      "[CV 3/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32430.75\n",
      "[CV 3/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32430.750 total time=   2.5s\n",
      "[CV 4/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.3s\n",
      "[CV 5/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "28894.19\n",
      "[CV 5/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-28894.190 total time=   2.7s\n",
      "[CV 1/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   3.0s\n",
      "[CV 2/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.9s\n",
      "[CV 3/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 4/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.4s\n",
      "[CV 5/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.9s\n",
      "[CV 1/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 2/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  24.4s\n",
      "[CV 2/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  23.5s\n",
      "[CV 3/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  24.8s\n",
      "[CV 4/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  24.7s\n",
      "[CV 5/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.3s\n",
      "[CV 1/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.3s\n",
      "[CV 2/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.3s\n",
      "[CV 3/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.3s\n",
      "[CV 4/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.3s\n",
      "[CV 5/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.8s\n",
      "[CV 1/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "21341.79399285662\n",
      "[CV 1/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21341.794 total time=   3.8s\n",
      "[CV 2/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "27213.88771162684\n",
      "[CV 2/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27213.888 total time=   2.3s\n",
      "[CV 3/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "27765.84\n",
      "[CV 3/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27765.840 total time=   4.2s\n",
      "[CV 4/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "27401.843682760933\n",
      "[CV 4/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27401.844 total time=   2.6s\n",
      "[CV 5/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "34815\n",
      "[CV 5/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-34815.000 total time=   2.4s\n",
      "[CV 1/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21086.79399285662\n",
      "[CV 1/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21086.794 total time=  21.8s\n",
      "[CV 2/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "26919.43771162684\n",
      "[CV 2/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26919.438 total time=  22.4s\n",
      "[CV 3/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "27585.84\n",
      "[CV 3/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27585.840 total time=  22.1s\n",
      "[CV 4/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "26916.843682760933\n",
      "[CV 4/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26916.844 total time=  23.0s\n",
      "[CV 5/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "32925\n",
      "[CV 5/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-32925.000 total time=  23.2s\n",
      "[CV 1/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42256.803992856614\n",
      "[CV 1/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42256.804 total time=   2.2s\n",
      "[CV 2/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46309.88771162684\n",
      "[CV 2/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46309.888 total time=   2.2s\n",
      "[CV 3/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53094.26\n",
      "[CV 3/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53094.260 total time=   2.2s\n",
      "[CV 4/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34741.963682760936\n",
      "[CV 4/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34741.964 total time=   2.9s\n",
      "[CV 5/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "50600\n",
      "[CV 5/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-50600.000 total time=   3.1s\n",
      "[CV 1/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.5s\n",
      "[CV 2/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   2.7s\n",
      "[CV 3/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.7s\n",
      "[CV 4/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.9s\n",
      "[CV 5/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.0s\n",
      "[CV 1/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  24.2s\n",
      "[CV 2/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  25.0s\n",
      "[CV 3/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  26.5s\n",
      "[CV 4/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  24.7s\n",
      "[CV 5/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  25.5s\n",
      "[CV 1/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   3.4s\n",
      "[CV 2/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   3.4s\n",
      "[CV 3/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   2.5s\n",
      "[CV 4/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.4s\n",
      "[CV 5/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   3.1s\n",
      "[CV 1/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "11741.793992856617\n",
      "[CV 1/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-11741.794 total time=   9.4s\n",
      "[CV 2/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "13713.852822325127\n",
      "[CV 2/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13713.853 total time=   2.6s\n",
      "[CV 3/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16285.75\n",
      "[CV 3/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16285.750 total time=   3.2s\n",
      "[CV 4/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "15619.093682760933\n",
      "[CV 4/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15619.094 total time=   2.5s\n",
      "[CV 5/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "18246.95\n",
      "[CV 5/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-18246.950 total time=   2.3s\n",
      "[CV 1/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12191.793992856617\n",
      "[CV 1/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12191.794 total time=  25.2s\n",
      "[CV 2/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13378.852822325127\n",
      "[CV 2/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13378.853 total time=  25.3s\n",
      "[CV 3/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16710.75\n",
      "[CV 3/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16710.750 total time=  26.0s\n",
      "[CV 4/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "14906.843682760933\n",
      "[CV 4/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14906.844 total time=  25.4s\n",
      "[CV 5/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17816.95\n",
      "[CV 5/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17816.950 total time=  24.8s\n",
      "[CV 1/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "18755.493745790667\n",
      "[CV 1/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-18755.494 total time=   2.8s\n",
      "[CV 2/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16718.852822325127\n",
      "[CV 2/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16718.853 total time=   3.6s\n",
      "[CV 3/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32435.75\n",
      "[CV 3/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32435.750 total time=   2.5s\n",
      "[CV 4/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.3s\n",
      "[CV 5/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-28904.190 total time=   3.0s\n",
      "[CV 1/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.6s\n",
      "[CV 2/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.5s\n",
      "[CV 3/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.6s\n",
      "[CV 4/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.3s\n",
      "[CV 5/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.8s\n",
      "[CV 1/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.4s\n",
      "[CV 2/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  25.2s\n",
      "[CV 2/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  24.9s\n",
      "[CV 3/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  24.8s\n",
      "[CV 4/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  25.4s\n",
      "[CV 5/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  24.6s\n",
      "[CV 1/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.4s\n",
      "[CV 2/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.3s\n",
      "[CV 3/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.4s\n",
      "[CV 4/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.4s\n",
      "[CV 5/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   3.0s\n",
      "[CV 1/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "23106.79399285662\n",
      "[CV 1/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-23106.794 total time=   2.2s\n",
      "[CV 2/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "24922.852822325127\n",
      "[CV 2/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24922.853 total time=   3.2s\n",
      "[CV 3/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "27825.84\n",
      "[CV 3/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27825.840 total time=   3.8s\n",
      "[CV 4/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "25941.843682760933\n",
      "[CV 4/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-25941.844 total time=   5.5s\n",
      "[CV 5/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "33700\n",
      "[CV 5/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-33700.000 total time=   2.8s\n",
      "[CV 1/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21206.79399285662\n",
      "[CV 1/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21206.794 total time=  24.8s\n",
      "[CV 2/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25212.852822325127\n",
      "[CV 2/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-25212.853 total time=  25.5s\n",
      "[CV 3/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28075.84\n",
      "[CV 3/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-28075.840 total time=  25.1s\n",
      "[CV 4/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "26616.843682760933\n",
      "[CV 4/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26616.844 total time=  24.7s\n",
      "[CV 5/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33910\n",
      "[CV 5/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33910.000 total time=  25.3s\n",
      "[CV 1/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.4s\n",
      "[CV 2/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.3s\n",
      "[CV 3/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53094.26\n",
      "[CV 3/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53094.260 total time=   2.4s\n",
      "[CV 4/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.1s\n",
      "[CV 5/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "37390\n",
      "[CV 5/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-37390.000 total time=   3.5s\n",
      "[CV 1/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.7s\n",
      "[CV 2/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.0s\n",
      "[CV 3/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.9s\n",
      "[CV 4/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.3s\n",
      "[CV 5/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.3s\n",
      "[CV 1/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  23.3s\n",
      "[CV 2/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  24.6s\n",
      "[CV 3/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  24.6s\n",
      "[CV 4/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  24.1s\n",
      "[CV 5/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  24.3s\n",
      "[CV 1/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   3.3s\n",
      "[CV 2/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   3.2s\n",
      "[CV 3/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   2.3s\n",
      "[CV 4/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.2s\n",
      "[CV 5/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   2.9s\n",
      "[CV 1/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "11936.793992856617\n",
      "[CV 1/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-11936.794 total time=   4.8s\n",
      "[CV 2/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "13563.852822325127\n",
      "[CV 2/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13563.853 total time=   3.4s\n",
      "[CV 3/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16685.75\n",
      "[CV 3/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16685.750 total time=   3.3s\n",
      "[CV 4/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "14689.093682760933\n",
      "[CV 4/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-14689.094 total time=   5.6s\n",
      "[CV 5/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "17436.95\n",
      "[CV 5/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17436.950 total time=   5.3s\n",
      "[CV 1/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "11971.793992856617\n",
      "[CV 1/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-11971.794 total time=  25.5s\n",
      "[CV 2/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12993.852822325127\n",
      "[CV 2/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12993.853 total time=  26.6s\n",
      "[CV 3/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16090.75\n",
      "[CV 3/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16090.750 total time=  27.0s\n",
      "[CV 4/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15396.843682760933\n",
      "[CV 4/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-15396.844 total time=  25.4s\n",
      "[CV 5/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17641.95\n",
      "[CV 5/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17641.950 total time=  26.8s\n",
      "[CV 1/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "18755.493745790667\n",
      "[CV 1/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-18755.494 total time=   3.0s\n",
      "[CV 2/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16878.853 total time=   3.5s\n",
      "[CV 3/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32440.750 total time=   2.5s\n",
      "[CV 4/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.4s\n",
      "[CV 5/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-28904.190 total time=   2.9s\n",
      "[CV 1/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 2/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.4s\n",
      "[CV 3/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.4s\n",
      "[CV 4/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.5s\n",
      "[CV 5/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.9s\n",
      "[CV 1/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  24.7s\n",
      "[CV 2/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  25.5s\n",
      "[CV 3/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  24.9s\n",
      "[CV 4/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  24.5s\n",
      "[CV 5/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  24.0s\n",
      "[CV 1/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.3s\n",
      "[CV 2/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.3s\n",
      "[CV 3/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.4s\n",
      "[CV 4/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.4s\n",
      "[CV 5/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.8s\n",
      "[CV 1/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 5/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 1/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "30749.483992856618\n",
      "[CV 1/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-30749.484 total time=   2.2s\n",
      "[CV 2/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "24407.852822325127\n",
      "[CV 2/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24407.853 total time=   5.3s\n",
      "[CV 3/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "27130.84\n",
      "[CV 3/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27130.840 total time=   7.6s\n",
      "[CV 4/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "27186.843682760933\n",
      "[CV 4/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27186.844 total time=   3.2s\n",
      "[CV 5/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "32840\n",
      "[CV 5/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-32840.000 total time=   3.7s\n",
      "[CV 1/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21621.79399285662\n",
      "[CV 1/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21621.794 total time=  24.9s\n",
      "[CV 2/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24012.852822325127\n",
      "[CV 2/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-24012.853 total time=  25.3s\n",
      "[CV 3/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "27755.84\n",
      "[CV 3/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27755.840 total time=  24.9s\n",
      "[CV 4/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27318.303682760932\n",
      "[CV 4/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27318.304 total time=  24.6s\n",
      "[CV 5/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33235\n",
      "[CV 5/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33235.000 total time=  25.1s\n",
      "[CV 1/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.3s\n",
      "[CV 2/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.3s\n",
      "[CV 3/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.4s\n",
      "[CV 4/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.4s\n",
      "[CV 5/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "50870\n",
      "[CV 5/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-50870.000 total time=   3.0s\n",
      "[CV 1/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   3.6s\n",
      "[CV 2/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.4s\n",
      "[CV 3/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.2s\n",
      "[CV 4/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.4s\n",
      "[CV 5/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.5s\n",
      "[CV 1/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12111.793992856617\n",
      "[CV 1/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12111.794 total time=  25.6s\n",
      "[CV 2/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13293.852822325127\n",
      "[CV 2/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-13293.853 total time=  26.5s\n",
      "[CV 3/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15845.75\n",
      "[CV 3/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15845.750 total time=  27.2s\n",
      "[CV 4/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15416.843682760933\n",
      "[CV 4/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15416.844 total time=  25.4s\n",
      "[CV 5/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17886.95\n",
      "[CV 5/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17886.950 total time=  25.5s\n",
      "[CV 1/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19211.79399285662\n",
      "[CV 1/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19211.794 total time=   3.8s\n",
      "[CV 2/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16878.852822325127\n",
      "[CV 2/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16878.853 total time=   3.5s\n",
      "[CV 3/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32440.750 total time=   2.5s\n",
      "[CV 4/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.4s\n",
      "[CV 5/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-28904.190 total time=   3.1s\n",
      "[CV 1/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 4/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.4s\n",
      "[CV 1/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "11876.793992856617\n",
      "[CV 1/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-11876.794 total time=   9.1s\n",
      "[CV 2/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "13773.852822325127\n",
      "[CV 2/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13773.853 total time=   3.1s\n",
      "[CV 3/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "15955.75\n",
      "[CV 3/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15955.750 total time=   7.1s\n",
      "[CV 4/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "15474.093682760933\n",
      "[CV 4/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15474.094 total time=   3.4s\n",
      "[CV 5/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "17411.95\n",
      "[CV 5/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17411.950 total time=   5.5s\n",
      "[CV 1/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12416.793992856617\n",
      "[CV 1/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12416.794 total time=  26.1s\n",
      "[CV 2/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13213.852822325127\n",
      "[CV 2/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13213.853 total time=  26.1s\n",
      "[CV 3/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "15945.75\n",
      "[CV 3/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-15945.750 total time=  25.6s\n",
      "[CV 4/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "14716.843682760933\n",
      "[CV 4/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14716.844 total time=  25.3s\n",
      "[CV 5/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17831.95\n",
      "[CV 5/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17831.950 total time=  25.2s\n",
      "[CV 1/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16394.483992856618\n",
      "[CV 1/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16394.484 total time=   3.3s\n",
      "[CV 2/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "17088.852822325127\n",
      "[CV 2/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-17088.853 total time=   3.6s\n",
      "[CV 3/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32440.75\n",
      "[CV 3/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32440.750 total time=   2.3s\n",
      "[CV 4/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29979.833682760935\n",
      "[CV 4/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29979.834 total time=   2.3s\n",
      "[CV 5/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "28904.19\n",
      "[CV 5/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-28904.190 total time=   3.1s\n",
      "[CV 1/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 2/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.9s\n",
      "[CV 3/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   3.1s\n",
      "[CV 4/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.6s\n",
      "[CV 5/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   3.2s\n",
      "[CV 1/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 3/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 5/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21861.79399285662\n",
      "[CV 1/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-21861.794 total time=  24.5s\n",
      "[CV 2/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "25237.852822325127\n",
      "[CV 2/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-25237.853 total time=  24.4s\n",
      "[CV 3/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28685.84\n",
      "[CV 3/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28685.840 total time=  24.1s\n",
      "[CV 4/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27948.303682760932\n",
      "[CV 4/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27948.304 total time=  24.7s\n",
      "[CV 5/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  25.4s\n",
      "[CV 1/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.3s\n",
      "[CV 2/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.3s\n",
      "[CV 3/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.3s\n",
      "[CV 4/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.3s\n",
      "[CV 5/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.8s\n",
      "[CV 1/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "21241.79399285662\n",
      "[CV 1/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21241.794 total time=   4.4s\n",
      "[CV 2/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "25132.852822325127\n",
      "[CV 2/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-25132.853 total time=   3.0s\n",
      "[CV 3/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "27615.84\n",
      "[CV 3/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27615.840 total time=   4.5s\n",
      "[CV 4/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "26506.843682760933\n",
      "[CV 4/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26506.844 total time=   3.5s\n",
      "[CV 5/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "35045\n",
      "[CV 5/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-35045.000 total time=   2.6s\n",
      "[CV 1/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22311.79399285662\n",
      "[CV 1/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-22311.794 total time=  23.6s\n",
      "[CV 2/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "23967.852822325127\n",
      "[CV 2/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-23967.853 total time=  23.5s\n",
      "[CV 3/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29714.26\n",
      "[CV 3/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-29714.260 total time=  24.1s\n",
      "[CV 4/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "28318.303682760932\n",
      "[CV 4/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-28318.304 total time=  24.5s\n",
      "[CV 5/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33095\n",
      "[CV 5/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33095.000 total time=  23.2s\n",
      "[CV 1/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42251.803992856614\n",
      "[CV 1/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42251.804 total time=   2.2s\n",
      "[CV 2/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46304.88771162684\n",
      "[CV 2/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46304.888 total time=   2.4s\n",
      "[CV 3/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53089.26\n",
      "[CV 3/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53089.260 total time=   2.4s\n",
      "[CV 4/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34731.963682760936\n",
      "[CV 4/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34731.964 total time=   3.1s\n",
      "[CV 5/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "44760\n",
      "[CV 5/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-44760.000 total time=   2.7s\n",
      "[CV 1/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.9s\n",
      "[CV 2/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.1s\n",
      "[CV 3/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.9s\n",
      "[CV 4/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.2s\n",
      "[CV 5/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.1s\n",
      "[CV 1/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "480 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [ -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -56389.5783409   -20045.65409959  -27906.39205018\n",
      " -226832.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan -101395.484       -55133.8743409   -57831.2563409\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -24570.56707745  -17493.56409959  -28822.37252831\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -42638.0223409   -33768.61307745  -48486.07153512\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -16632.48609959  -15943.23609959  -24965.85005018\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -29361.52507745  -29224.75907745  -46168.73102804\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -17460.83809959  -15247.03809959  -24451.13609959\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27376.46609959  -27482.75809959  -45514.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -15712.20609959  -14932.03809959  -25065.08409959\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27707.67307745  -27086.78307745  -45400.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -15121.48809959  -15001.03809959  -25358.82405018\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27099.46609959  -27004.46609959  -42754.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -14862.48809959  -14819.03809959  -25391.82405018\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -28463.00409959  -26788.75809959  -45449.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -14898.48809959  -14825.03809959  -24961.62209959\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27108.46609959  -27481.44209959  -44227.58307745\n",
      " -227237.                      nan              nan              nan]\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# grid_smt = GridSearchCV(estimator=dtc, param_grid=param_grid, scoring=my_func_smt, cv = 5, verbose=10)\n",
    "new_params = {'logisticregression__' + key: param_grid[key] for key in param_grid}\n",
    "# grid_c = GridSearchCV(estimator=dfrst_c, param_grid=param_grid_criterion, scoring=my_func, cv = 5, verbose=10)return_train_score=True,\n",
    "grid_imba = GridSearchCV(imba_pipeline, param_grid=new_params, cv=5, scoring=my_func_smt,  verbose=10)\n",
    "grid_search_imba = grid_imba.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dafea1c-b41f-4918-b949-780d0bd3b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [ -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -56389.5783409   -20045.65409959  -27906.39205018\n",
      " -226832.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan -101395.484       -55133.8743409   -57831.2563409\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -24570.56707745  -17493.56409959  -28822.37252831\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -42638.0223409   -33768.61307745  -48486.07153512\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -16632.48609959  -15943.23609959  -24965.85005018\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -29361.52507745  -29224.75907745  -46168.73102804\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -17460.83809959  -15247.03809959  -24451.13609959\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27376.46609959  -27482.75809959  -45514.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -15712.20609959  -14932.03809959  -25065.08409959\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27707.67307745  -27086.78307745  -45400.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -15121.48809959  -15001.03809959  -25358.82405018\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27099.46609959  -27004.46609959  -42754.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -14862.48809959  -14819.03809959  -25391.82405018\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -28463.00409959  -26788.75809959  -45449.58307745\n",
      " -227237.                      nan              nan              nan\n",
      "  -14911.03809959  -25483.08409959              nan              nan\n",
      "              nan  -14898.48809959  -14825.03809959  -24961.62209959\n",
      " -226831.                      nan              nan              nan\n",
      "  -27437.75809959  -45255.58307745              nan              nan\n",
      "              nan  -27108.46609959  -27481.44209959  -44227.58307745\n",
      " -227237.                      nan              nan              nan], using {'logisticregression__C': 10, 'logisticregression__class_weight': {0: 1.0, 1: 10.0}, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.255399</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-12111.793993</td>\n",
       "      <td>-13293.852822</td>\n",
       "      <td>-15845.75</td>\n",
       "      <td>-15416.843683</td>\n",
       "      <td>-17886.95</td>\n",
       "      <td>-14911.038100</td>\n",
       "      <td>2021.713781</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.215000</td>\n",
       "      <td>0.338555</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-19211.793993</td>\n",
       "      <td>-16878.852822</td>\n",
       "      <td>-32440.75</td>\n",
       "      <td>-29979.833683</td>\n",
       "      <td>-28904.19</td>\n",
       "      <td>-25483.084100</td>\n",
       "      <td>6224.077645</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280399</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.277198</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277206</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2.638993</td>\n",
       "      <td>0.300981</td>\n",
       "      <td>0.022404</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-42251.803993</td>\n",
       "      <td>-46304.887712</td>\n",
       "      <td>-53089.26</td>\n",
       "      <td>-34731.963683</td>\n",
       "      <td>-44760.00</td>\n",
       "      <td>-44227.583077</td>\n",
       "      <td>5953.124741</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2.926190</td>\n",
       "      <td>0.396628</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-227435.000000</td>\n",
       "      <td>-227080.000000</td>\n",
       "      <td>-226920.00</td>\n",
       "      <td>-226920.000000</td>\n",
       "      <td>-227830.00</td>\n",
       "      <td>-227237.000000</td>\n",
       "      <td>351.135302</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.370808</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.381753</td>\n",
       "      <td>0.024629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.396985</td>\n",
       "      <td>0.021708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        18.255399      0.343514         0.021202        0.000749   \n",
       "1         2.215000      0.338555         0.020600        0.000490   \n",
       "2         0.280399      0.012305         0.000000        0.000000   \n",
       "3         0.277198      0.014127         0.000000        0.000000   \n",
       "4         0.277206      0.012872         0.000000        0.000000   \n",
       "..             ...           ...              ...             ...   \n",
       "187       2.638993      0.300981         0.022404        0.000494   \n",
       "188       2.926190      0.396628         0.018414        0.000997   \n",
       "189       0.370808      0.020268         0.000000        0.000000   \n",
       "190       0.381753      0.024629         0.000000        0.000000   \n",
       "191       0.396985      0.021708         0.000000        0.000000   \n",
       "\n",
       "    param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "0                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "1                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "2                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "3                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "4                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "..                          ...                                    ...   \n",
       "187                         100                      {0: 1.0, 1: 25.0}   \n",
       "188                         100                      {0: 1.0, 1: 25.0}   \n",
       "189                         100                      {0: 1.0, 1: 25.0}   \n",
       "190                         100                      {0: 1.0, 1: 25.0}   \n",
       "191                         100                      {0: 1.0, 1: 25.0}   \n",
       "\n",
       "    param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "0                                none                        newton-cg   \n",
       "1                                none                            lbfgs   \n",
       "2                                none                        liblinear   \n",
       "3                                  l1                        newton-cg   \n",
       "4                                  l1                            lbfgs   \n",
       "..                                ...                              ...   \n",
       "187                                l2                            lbfgs   \n",
       "188                                l2                        liblinear   \n",
       "189                        elasticnet                        newton-cg   \n",
       "190                        elasticnet                            lbfgs   \n",
       "191                        elasticnet                        liblinear   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'logisticregression__C': 1e-05, 'logisticregr...      -12111.793993   \n",
       "1    {'logisticregression__C': 1e-05, 'logisticregr...      -19211.793993   \n",
       "2    {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "3    {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "4    {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "..                                                 ...                ...   \n",
       "187  {'logisticregression__C': 100, 'logisticregres...      -42251.803993   \n",
       "188  {'logisticregression__C': 100, 'logisticregres...     -227435.000000   \n",
       "189  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "190  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "191  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0        -13293.852822          -15845.75      -15416.843683   \n",
       "1        -16878.852822          -32440.75      -29979.833683   \n",
       "2                  NaN                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                  NaN                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "187      -46304.887712          -53089.26      -34731.963683   \n",
       "188     -227080.000000         -226920.00     -226920.000000   \n",
       "189                NaN                NaN                NaN   \n",
       "190                NaN                NaN                NaN   \n",
       "191                NaN                NaN                NaN   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            -17886.95    -14911.038100     2021.713781                5  \n",
       "1            -28904.19    -25483.084100     6224.077645               30  \n",
       "2                  NaN              NaN             NaN              157  \n",
       "3                  NaN              NaN             NaN              156  \n",
       "4                  NaN              NaN             NaN              155  \n",
       "..                 ...              ...             ...              ...  \n",
       "187          -44760.00    -44227.583077     5953.124741               63  \n",
       "188         -227830.00   -227237.000000      351.135302               89  \n",
       "189                NaN              NaN             NaN              115  \n",
       "190                NaN              NaN             NaN              175  \n",
       "191                NaN              NaN             NaN              192  \n",
       "\n",
       "[192 rows x 17 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_search_imba.cv_results_['mean_test_score'], grid_search_imba.best_params_))\n",
    "results_df_smt = pd.DataFrame(grid_search_imba.cv_results_)\n",
    "results_df_smt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59df01e-5af4-4e92-b9da-f1f69ecbce20",
   "metadata": {},
   "source": [
    "# Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d074b3d-abbd-4421-8303-caba4bd908be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.1, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "anomaly_inputs = []\n",
    "for name in transactions.columns[1:29]:\n",
    "    anomaly_inputs.append(name)\n",
    "anomaly_inputs.append('Class')\n",
    "\n",
    "model_IF = IsolationForest(contamination=float(0.1),random_state=42)\n",
    "\n",
    "anomaly_df = transactions\n",
    "model_IF.fit(anomaly_df[anomaly_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc406d3c-3c71-4f2e-ac56-43e36d1484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df['anomaly_scores'] = model_IF.decision_function(anomaly_df[anomaly_inputs])\n",
    "anomaly_df['anomaly'] = model_IF.predict(anomaly_df[anomaly_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52a82db8-7697-4335-a090-c210aab824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_o = anomaly_df[(anomaly_df[\"anomaly\"]==1) | ((anomaly_df[\"Class\"]==1) & (anomaly_df[\"anomaly\"]==-1))]\n",
    "df_wo_o = df_wo_o.drop(\"anomaly\", axis='columns')\n",
    "df_wo_o = df_wo_o.drop(\"anomaly_scores\", axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77c8d47b-a061-4f32-aaa3-bbb59344b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#split dataset in features and target variable\n",
    "X_wo_outliers = df_wo_o.drop(['Class'], axis=1) # Features\n",
    "y_wo_outliers = df_wo_o.Class # Target variable\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train_smt_wo_outliers, X_test_smt_wo_outliers, y_train_smt_wo_outliers, y_test_smt_wo_outliers = train_test_split(X_wo_outliers, y_wo_outliers, test_size=0.2, stratify=y_wo_outliers, random_state=42) # 80% training and 20% test\n",
    "\n",
    "smote_technique = SMOTE(sampling_strategy='minority')\n",
    "X_smt_wo_outliers, y_smt_wo_outliers = smote_technique.fit_resample(X_train_smt_wo_outliers, y_train_smt_wo_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16adfce0-2efb-4942-b3ca-f49632a01613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_smt_wo_outliers = LogisticRegression(C=1e-05, penalty='l2',solver='newton-cg')\n",
    "\n",
    "# Train\n",
    "model_smt_wo_outliers = model_smt_wo_outliers.fit(X_smt_wo_outliers,y_smt_wo_outliers)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_smt_wo_outliers = model_smt_wo_outliers.predict(X_test_smt_wo_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea4846ce-d92e-427d-b611-e3ef6c817aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_smt_wo_outliers = confusion_matrix(y_test_smt_wo_outliers, y_pred_smt_wo_outliers) \n",
    "\n",
    "sns.heatmap(cm_smt_wo_outliers/np.sum(cm_smt_wo_outliers), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91c13d6f-7bad-4809-903e-4e493db0c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 87, FN: 11, FP: 78, TN: 51179\n",
      "Total cost: 2038.6899999999998\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm_smt_wo_outliers, X_test_smt_wo_outliers, y_test_smt_wo_outliers, y_pred_smt_wo_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8719f70-a84c-4310-b591-626b3d92ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def my_scorer_smt_wo_outliers(y_true, y_pred):\n",
    "    model_cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    for cls in range(model_cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, model_cm).ravel() \n",
    "        \n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "    X_test_score = X_smt_wo_outliers\n",
    "    # X_test_score = get_x_elements_by_indices(X_test_score, y_true.index)\n",
    "    #print(labels[y_true * 2 + y_pred])\n",
    "    #X_test_score['case'] = labels[y_true * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegativeMyScorer(X_test_score, y_true, y_pred) + (FP + TP) * Ca\n",
    "    print(TotalCost)\n",
    "    return TotalCost\n",
    "\n",
    "my_func_smt_wo_outliers = make_scorer(my_scorer_smt_wo_outliers, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b6cb9f6-c1b0-4b76-a9ed-641d64aae734",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  19.1s\n",
      "[CV 2/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  19.7s\n",
      "[CV 3/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  19.7s\n",
      "[CV 4/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  18.7s\n",
      "[CV 5/5; 1/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 1/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  18.7s\n",
      "[CV 1/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   2.9s\n",
      "[CV 2/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   2.6s\n",
      "[CV 3/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   1.9s\n",
      "[CV 4/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   1.8s\n",
      "[CV 5/5; 2/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 2/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   2.4s\n",
      "[CV 1/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 3/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 3/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 4/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 4/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 5/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 5/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "47962.04398330185\n",
      "[CV 1/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-47962.044 total time=   1.0s\n",
      "[CV 2/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "51582.315354843326\n",
      "[CV 2/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-51582.315 total time=   0.9s\n",
      "[CV 3/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "59897.46659034838\n",
      "[CV 3/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-59897.467 total time=   0.9s\n",
      "[CV 4/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "58762.708331230206\n",
      "[CV 4/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-58762.708 total time=   1.1s\n",
      "[CV 5/5; 6/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "62405\n",
      "[CV 5/5; 6/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-62405.000 total time=   0.9s\n",
      "[CV 1/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16914.213789929734\n",
      "[CV 1/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16914.214 total time=  20.8s\n",
      "[CV 2/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "18919.40171941066\n",
      "[CV 2/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-18919.402 total time=  21.6s\n",
      "[CV 3/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22217.64659034838\n",
      "[CV 3/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-22217.647 total time=  19.3s\n",
      "[CV 4/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "19374.304589955143\n",
      "[CV 4/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-19374.305 total time=  18.6s\n",
      "[CV 5/5; 7/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "22757.7\n",
      "[CV 5/5; 7/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-22757.700 total time=  20.4s\n",
      "[CV 1/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "21708.33149042004\n",
      "[CV 1/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-21708.331 total time=   2.2s\n",
      "[CV 2/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "24729.40171941066\n",
      "[CV 2/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-24729.402 total time=   2.2s\n",
      "[CV 3/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "28248.616590348378\n",
      "[CV 3/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-28248.617 total time=   2.5s\n",
      "[CV 4/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "30721.614589955145\n",
      "[CV 4/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-30721.615 total time=   1.7s\n",
      "[CV 5/5; 8/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "33507.7\n",
      "[CV 5/5; 8/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-33507.700 total time=   1.6s\n",
      "[CV 1/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 2/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226515\n",
      "[CV 2/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226515.000 total time=   1.8s\n",
      "[CV 3/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 4/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   1.6s\n",
      "[CV 5/5; 9/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 9/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.0s\n",
      "[CV 1/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 10/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 10/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 11/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 11/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 12/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 12/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  19.4s\n",
      "[CV 2/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  23.0s\n",
      "[CV 3/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  23.2s\n",
      "[CV 4/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  23.8s\n",
      "[CV 5/5; 13/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 13/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  24.0s\n",
      "[CV 1/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.2s\n",
      "[CV 2/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.6s\n",
      "[CV 3/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.3s\n",
      "[CV 4/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.2s\n",
      "[CV 5/5; 14/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 14/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.7s\n",
      "[CV 1/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 15/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 15/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 16/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 16/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 17/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 17/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 1\n",
      "93127.69\n",
      "[CV 1/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-93127.690 total time=   1.5s\n",
      "[CV 2/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 1\n",
      "101488.0\n",
      "[CV 2/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-101488.000 total time=   1.4s\n",
      "[CV 3/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "99412.46659034838\n",
      "[CV 3/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-99412.467 total time=   1.4s\n",
      "[CV 4/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 1\n",
      "100682.34\n",
      "[CV 4/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-100682.340 total time=   1.3s\n",
      "[CV 5/5; 18/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "113980\n",
      "[CV 5/5; 18/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-113980.000 total time=   1.5s\n",
      "[CV 1/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "47906.553789929734\n",
      "[CV 1/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-47906.554 total time=  26.4s\n",
      "[CV 2/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "49387.315354843326\n",
      "[CV 2/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-49387.315 total time=  25.3s\n",
      "[CV 3/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "57322.51659034838\n",
      "[CV 3/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-57322.517 total time=  23.1s\n",
      "[CV 4/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 1\n",
      "54761.378331230204\n",
      "[CV 4/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-54761.378 total time=  26.1s\n",
      "[CV 5/5; 19/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "66500\n",
      "[CV 5/5; 19/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-66500.000 total time=  27.8s\n",
      "[CV 1/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "52167.64378992973\n",
      "[CV 1/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-52167.644 total time=   2.7s\n",
      "[CV 2/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "51622.315354843326\n",
      "[CV 2/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-51622.315 total time=   2.7s\n",
      "[CV 3/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "59382.51659034838\n",
      "[CV 3/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-59382.517 total time=   2.8s\n",
      "[CV 4/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "57390\n",
      "[CV 4/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-57390.000 total time=   3.1s\n",
      "[CV 5/5; 20/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "68435\n",
      "[CV 5/5; 20/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-68435.000 total time=   3.0s\n",
      "[CV 1/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.8s\n",
      "[CV 2/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.6s\n",
      "[CV 3/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.1s\n",
      "[CV 4/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.3s\n",
      "[CV 5/5; 21/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 21/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.3s\n",
      "[CV 1/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 22/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 22/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 23/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 23/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 24/192] START logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 24/192] END logisticregression__C=1e-05, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  23.6s\n",
      "[CV 2/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  24.4s\n",
      "[CV 3/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  25.0s\n",
      "[CV 4/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  23.2s\n",
      "[CV 5/5; 25/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 25/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  24.0s\n",
      "[CV 1/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.3s\n",
      "[CV 2/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.1s\n",
      "[CV 3/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.3s\n",
      "[CV 4/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.3s\n",
      "[CV 5/5; 26/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 26/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   3.0s\n",
      "[CV 1/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 27/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 27/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 28/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 28/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 29/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 29/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "21134.213789929734\n",
      "[CV 1/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21134.214 total time=   2.1s\n",
      "[CV 2/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "22924.39171941066\n",
      "[CV 2/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-22924.392 total time=   1.9s\n",
      "[CV 3/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "26549.85659034838\n",
      "[CV 3/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26549.857 total time=   2.0s\n",
      "[CV 4/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "24722.654589955146\n",
      "[CV 4/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24722.655 total time=   2.3s\n",
      "[CV 5/5; 30/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "27490\n",
      "[CV 5/5; 30/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27490.000 total time=   2.1s\n",
      "[CV 1/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "14699.213789929732\n",
      "[CV 1/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14699.214 total time=  26.7s\n",
      "[CV 2/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "16092.285354843327\n",
      "[CV 2/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16092.285 total time=  27.4s\n",
      "[CV 3/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19217.64659034838\n",
      "[CV 3/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-19217.647 total time=  27.0s\n",
      "[CV 4/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "17189.304589955143\n",
      "[CV 4/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17189.305 total time=  27.1s\n",
      "[CV 5/5; 31/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "20247.7\n",
      "[CV 5/5; 31/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-20247.700 total time=  28.1s\n",
      "[CV 1/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "25273.33149042004\n",
      "[CV 1/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-25273.331 total time=   2.1s\n",
      "[CV 2/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "26078.341168944207\n",
      "[CV 2/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26078.341 total time=   2.2s\n",
      "[CV 3/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "31223.90659034838\n",
      "[CV 3/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-31223.907 total time=   2.4s\n",
      "[CV 4/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "27566.614589955145\n",
      "[CV 4/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-27566.615 total time=   2.3s\n",
      "[CV 5/5; 32/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "30918.46\n",
      "[CV 5/5; 32/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-30918.460 total time=   2.2s\n",
      "[CV 1/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 2/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.6s\n",
      "[CV 3/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 4/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.4s\n",
      "[CV 5/5; 33/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 33/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   3.0s\n",
      "[CV 1/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 34/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 34/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 35/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 35/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 36/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 36/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  24.0s\n",
      "[CV 2/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  24.9s\n",
      "[CV 3/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  26.8s\n",
      "[CV 4/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  24.5s\n",
      "[CV 5/5; 37/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 37/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.1s\n",
      "[CV 1/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.3s\n",
      "[CV 2/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.3s\n",
      "[CV 3/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.2s\n",
      "[CV 4/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.2s\n",
      "[CV 5/5; 38/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 38/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.8s\n",
      "[CV 1/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 39/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 39/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 40/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 40/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 41/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 41/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "37969.21378992973\n",
      "[CV 1/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-37969.214 total time=   2.1s\n",
      "[CV 2/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "37597.315354843326\n",
      "[CV 2/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-37597.315 total time=   2.1s\n",
      "[CV 3/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "45894.45659034838\n",
      "[CV 3/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-45894.457 total time=   2.1s\n",
      "[CV 4/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "41438.71833123021\n",
      "[CV 4/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-41438.718 total time=   1.8s\n",
      "[CV 5/5; 42/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "49225\n",
      "[CV 5/5; 42/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-49225.000 total time=   2.2s\n",
      "[CV 1/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "28744.213789929734\n",
      "[CV 1/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-28744.214 total time=  26.0s\n",
      "[CV 2/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "31272.315354843326\n",
      "[CV 2/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-31272.315 total time=  25.4s\n",
      "[CV 3/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "35127.356590348376\n",
      "[CV 3/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-35127.357 total time=  26.4s\n",
      "[CV 4/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "33423.05458995514\n",
      "[CV 4/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33423.055 total time=  25.7s\n",
      "[CV 5/5; 43/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "40415\n",
      "[CV 5/5; 43/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-40415.000 total time=  25.0s\n",
      "[CV 1/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "45417.33149042004\n",
      "[CV 1/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-45417.331 total time=   2.0s\n",
      "[CV 2/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "49156.09636456733\n",
      "[CV 2/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-49156.096 total time=   2.0s\n",
      "[CV 3/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "45278.61659034838\n",
      "[CV 3/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-45278.617 total time=   2.7s\n",
      "[CV 4/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "52991.24625872494\n",
      "[CV 4/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-52991.246 total time=   2.1s\n",
      "[CV 5/5; 44/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "49480\n",
      "[CV 5/5; 44/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-49480.000 total time=   3.1s\n",
      "[CV 1/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.4s\n",
      "[CV 2/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   2.6s\n",
      "[CV 3/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.5s\n",
      "[CV 4/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.7s\n",
      "[CV 5/5; 45/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 45/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   1.9s\n",
      "[CV 1/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 46/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 46/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 47/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 47/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 48/192] START logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 48/192] END logisticregression__C=0.0001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  22.8s\n",
      "[CV 2/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  23.4s\n",
      "[CV 3/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  23.7s\n",
      "[CV 4/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  22.2s\n",
      "[CV 5/5; 49/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 49/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  23.0s\n",
      "[CV 1/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.2s\n",
      "[CV 2/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.1s\n",
      "[CV 3/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.3s\n",
      "[CV 4/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.2s\n",
      "[CV 5/5; 50/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 50/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   2.9s\n",
      "[CV 1/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 51/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 51/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 52/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 52/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 53/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 53/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "13880.213789929732\n",
      "[CV 1/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13880.214 total time=   3.0s\n",
      "[CV 2/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "14682.285354843327\n",
      "[CV 2/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-14682.285 total time=   3.0s\n",
      "[CV 3/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "18721.69659034838\n",
      "[CV 3/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-18721.697 total time=   1.9s\n",
      "[CV 4/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "16451.644589955144\n",
      "[CV 4/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16451.645 total time=   2.6s\n",
      "[CV 5/5; 54/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "19287.7\n",
      "[CV 5/5; 54/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-19287.700 total time=   2.3s\n",
      "[CV 1/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "13400.213789929732\n",
      "[CV 1/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13400.214 total time=  24.9s\n",
      "[CV 2/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "13939.381719410661\n",
      "[CV 2/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13939.382 total time=  25.1s\n",
      "[CV 3/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "17656.69659034838\n",
      "[CV 3/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17656.697 total time=  25.9s\n",
      "[CV 4/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "15869.304589955143\n",
      "[CV 4/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-15869.305 total time=  25.6s\n",
      "[CV 5/5; 55/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "18832.7\n",
      "[CV 5/5; 55/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-18832.700 total time=  26.3s\n",
      "[CV 1/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "26418.33149042004\n",
      "[CV 1/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26418.331 total time=   2.1s\n",
      "[CV 2/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16519.38171941066\n",
      "[CV 2/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16519.382 total time=   3.5s\n",
      "[CV 3/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "32233.90659034838\n",
      "[CV 3/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32233.907 total time=   2.3s\n",
      "[CV 4/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "16681.644589955144\n",
      "[CV 4/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16681.645 total time=   3.4s\n",
      "[CV 5/5; 56/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "32297.7\n",
      "[CV 5/5; 56/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32297.700 total time=   2.2s\n",
      "[CV 1/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.4s\n",
      "[CV 2/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.4s\n",
      "[CV 3/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.4s\n",
      "[CV 4/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.2s\n",
      "[CV 5/5; 57/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 57/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.7s\n",
      "[CV 1/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 58/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 58/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 59/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 59/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 60/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 60/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  24.4s\n",
      "[CV 2/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  24.4s\n",
      "[CV 3/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  24.5s\n",
      "[CV 4/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  24.7s\n",
      "[CV 5/5; 61/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 61/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.9s\n",
      "[CV 1/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.2s\n",
      "[CV 2/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.2s\n",
      "[CV 3/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.4s\n",
      "[CV 4/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.3s\n",
      "[CV 5/5; 62/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 62/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.9s\n",
      "[CV 1/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 63/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 63/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 64/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 64/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 65/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 65/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "24155.213789929734\n",
      "[CV 1/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24155.214 total time=   2.8s\n",
      "[CV 2/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "29032.315354843326\n",
      "[CV 2/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-29032.315 total time=   2.2s\n",
      "[CV 3/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "30836.29659034838\n",
      "[CV 3/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-30836.297 total time=   3.1s\n",
      "[CV 4/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "28714.384589955145\n",
      "[CV 4/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-28714.385 total time=   4.8s\n",
      "[CV 5/5; 66/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "35350\n",
      "[CV 5/5; 66/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-35350.000 total time=   2.9s\n",
      "[CV 1/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "23765.213789929734\n",
      "[CV 1/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-23765.214 total time=  25.1s\n",
      "[CV 2/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "26747.295354843325\n",
      "[CV 2/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26747.295 total time=  26.4s\n",
      "[CV 3/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "31252.35659034838\n",
      "[CV 3/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-31252.357 total time=  25.1s\n",
      "[CV 4/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "29082.044589955145\n",
      "[CV 4/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-29082.045 total time=  25.7s\n",
      "[CV 5/5; 67/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "35275\n",
      "[CV 5/5; 67/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-35275.000 total time=  26.2s\n",
      "[CV 1/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "35789.61378992973\n",
      "[CV 1/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-35789.614 total time=   3.2s\n",
      "[CV 2/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46259.41171941066\n",
      "[CV 2/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46259.412 total time=   2.3s\n",
      "[CV 3/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53675.82659034838\n",
      "[CV 3/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53675.827 total time=   2.4s\n",
      "[CV 4/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 3\n",
      "35350.36458995514\n",
      "[CV 4/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-35350.365 total time=   3.5s\n",
      "[CV 5/5; 68/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 1\n",
      "59205.0\n",
      "[CV 5/5; 68/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-59205.000 total time=   2.5s\n",
      "[CV 1/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   3.1s\n",
      "[CV 2/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.5s\n",
      "[CV 3/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.9s\n",
      "[CV 4/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.0s\n",
      "[CV 5/5; 69/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 69/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.1s\n",
      "[CV 1/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 70/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 70/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 71/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 71/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 72/192] START logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 72/192] END logisticregression__C=0.001, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  25.1s\n",
      "[CV 2/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  26.4s\n",
      "[CV 3/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  27.0s\n",
      "[CV 4/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  25.2s\n",
      "[CV 5/5; 73/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 73/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  25.8s\n",
      "[CV 1/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.6s\n",
      "[CV 2/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.6s\n",
      "[CV 3/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.5s\n",
      "[CV 4/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.3s\n",
      "[CV 5/5; 74/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 74/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   3.1s\n",
      "[CV 1/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 75/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 75/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 76/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 76/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 5/5; 77/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 77/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 1/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "12510.213789929732\n",
      "[CV 1/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12510.214 total time=   5.0s\n",
      "[CV 2/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "13024.381719410661\n",
      "[CV 2/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13024.382 total time=   4.0s\n",
      "[CV 3/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16411.69659034838\n",
      "[CV 3/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16411.697 total time=  11.4s\n",
      "[CV 4/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "15876.644589955144\n",
      "[CV 4/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15876.645 total time=   2.4s\n",
      "[CV 5/5; 78/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "19697.7\n",
      "[CV 5/5; 78/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-19697.700 total time=   2.1s\n",
      "[CV 1/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "13075.213789929732\n",
      "[CV 1/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-13075.214 total time=  26.0s\n",
      "[CV 2/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12829.381719410661\n",
      "[CV 2/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12829.382 total time=  27.3s\n",
      "[CV 3/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16961.69659034838\n",
      "[CV 3/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16961.697 total time=  25.9s\n",
      "[CV 4/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15139.304589955143\n",
      "[CV 4/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-15139.305 total time=  25.0s\n",
      "[CV 5/5; 79/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "18352.7\n",
      "[CV 5/5; 79/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-18352.700 total time=  25.7s\n",
      "[CV 1/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "17120.213789929734\n",
      "[CV 1/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-17120.214 total time=   3.3s\n",
      "[CV 2/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "21769.40171941066\n",
      "[CV 2/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-21769.402 total time=   2.7s\n",
      "[CV 3/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32497.916590348377\n",
      "[CV 3/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32497.917 total time=   2.5s\n",
      "[CV 4/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29426.614589955145\n",
      "[CV 4/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29426.615 total time=   2.4s\n",
      "[CV 5/5; 80/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "20830\n",
      "[CV 5/5; 80/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-20830.000 total time=   3.4s\n",
      "[CV 1/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.9s\n",
      "[CV 2/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.7s\n",
      "[CV 3/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.6s\n",
      "[CV 4/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.4s\n",
      "[CV 5/5; 81/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 81/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   3.1s\n",
      "[CV 1/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 82/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 82/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 83/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 83/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 84/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 84/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  24.4s\n",
      "[CV 2/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  24.0s\n",
      "[CV 3/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  25.1s\n",
      "[CV 4/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  24.5s\n",
      "[CV 5/5; 85/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 85/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.8s\n",
      "[CV 1/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.3s\n",
      "[CV 2/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.2s\n",
      "[CV 3/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.3s\n",
      "[CV 4/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.4s\n",
      "[CV 5/5; 86/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 86/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   3.1s\n",
      "[CV 1/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 3/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 5/5; 87/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 87/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.4s\n",
      "[CV 2/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.4s\n",
      "[CV 3/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 88/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 88/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 89/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 89/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "21515.213789929734\n",
      "[CV 1/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21515.214 total time=   5.0s\n",
      "[CV 2/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "25197.295354843325\n",
      "[CV 2/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-25197.295 total time=   2.4s\n",
      "[CV 3/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "28996.29659034838\n",
      "[CV 3/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-28996.297 total time=   3.1s\n",
      "[CV 4/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "26944.304589955143\n",
      "[CV 4/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26944.305 total time=   3.7s\n",
      "[CV 5/5; 90/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "33160\n",
      "[CV 5/5; 90/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-33160.000 total time=   4.2s\n",
      "[CV 1/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21610.213789929734\n",
      "[CV 1/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21610.214 total time=  24.3s\n",
      "[CV 2/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24672.285354843327\n",
      "[CV 2/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-24672.285 total time=  23.8s\n",
      "[CV 3/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "29756.29659034838\n",
      "[CV 3/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-29756.297 total time=  24.3s\n",
      "[CV 4/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27572.044589955145\n",
      "[CV 4/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27572.045 total time=  23.6s\n",
      "[CV 5/5; 91/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33560\n",
      "[CV 5/5; 91/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33560.000 total time=  23.5s\n",
      "[CV 1/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42342.33149042004\n",
      "[CV 1/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42342.331 total time=   2.3s\n",
      "[CV 2/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46024.41171941066\n",
      "[CV 2/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46024.412 total time=   2.3s\n",
      "[CV 3/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53090.82659034838\n",
      "[CV 3/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53090.827 total time=   2.3s\n",
      "[CV 4/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34492.62458995514\n",
      "[CV 4/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34492.625 total time=   3.0s\n",
      "[CV 5/5; 92/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "51010\n",
      "[CV 5/5; 92/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-51010.000 total time=   3.0s\n",
      "[CV 1/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.9s\n",
      "[CV 2/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.2s\n",
      "[CV 3/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.2s\n",
      "[CV 4/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.3s\n",
      "[CV 5/5; 93/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 93/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.3s\n",
      "[CV 1/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 94/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 94/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 95/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 95/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 96/192] START logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 96/192] END logisticregression__C=0.01, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  24.8s\n",
      "[CV 2/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  24.6s\n",
      "[CV 3/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  25.3s\n",
      "[CV 4/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  24.8s\n",
      "[CV 5/5; 97/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 97/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  25.0s\n",
      "[CV 1/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.3s\n",
      "[CV 2/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.4s\n",
      "[CV 3/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.3s\n",
      "[CV 4/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.3s\n",
      "[CV 5/5; 98/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 98/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   3.0s\n",
      "[CV 1/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 99/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 99/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 100/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 100/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 101/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 101/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "12235.213789929732\n",
      "[CV 1/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12235.214 total time=   6.3s\n",
      "[CV 2/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "12739.381719410661\n",
      "[CV 2/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12739.382 total time=   6.3s\n",
      "[CV 3/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16451.69659034838\n",
      "[CV 3/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16451.697 total time=   5.6s\n",
      "[CV 4/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "15306.644589955144\n",
      "[CV 4/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15306.645 total time=   2.8s\n",
      "[CV 5/5; 102/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "17547.7\n",
      "[CV 5/5; 102/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17547.700 total time=   6.0s\n",
      "[CV 1/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12580.213789929732\n",
      "[CV 1/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12580.214 total time=  24.3s\n",
      "[CV 2/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12919.381719410661\n",
      "[CV 2/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12919.382 total time=  25.7s\n",
      "[CV 3/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16726.69659034838\n",
      "[CV 3/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16726.697 total time=  24.4s\n",
      "[CV 4/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "14724.304589955143\n",
      "[CV 4/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14724.305 total time=  24.7s\n",
      "[CV 5/5; 103/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17832.7\n",
      "[CV 5/5; 103/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17832.700 total time=  24.0s\n",
      "[CV 1/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "17470.213789929734\n",
      "[CV 1/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-17470.214 total time=   3.4s\n",
      "[CV 2/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.6s\n",
      "[CV 3/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32542.916590348377\n",
      "[CV 3/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32542.917 total time=   2.5s\n",
      "[CV 4/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.2s\n",
      "[CV 5/5; 104/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "26533.46\n",
      "[CV 5/5; 104/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26533.460 total time=   2.7s\n",
      "[CV 1/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 2/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.7s\n",
      "[CV 3/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.7s\n",
      "[CV 4/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.5s\n",
      "[CV 5/5; 105/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 105/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   3.0s\n",
      "[CV 1/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 106/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 106/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 107/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 107/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 108/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 108/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  23.4s\n",
      "[CV 2/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  23.5s\n",
      "[CV 3/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  23.3s\n",
      "[CV 4/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  23.3s\n",
      "[CV 5/5; 109/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 109/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.3s\n",
      "[CV 1/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.2s\n",
      "[CV 2/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.2s\n",
      "[CV 3/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.2s\n",
      "[CV 4/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.2s\n",
      "[CV 5/5; 110/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 110/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.7s\n",
      "[CV 1/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 111/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 111/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 112/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 112/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 113/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 113/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "21870.213789929734\n",
      "[CV 1/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21870.214 total time=   3.5s\n",
      "[CV 2/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 3\n",
      "27567.315354843326\n",
      "[CV 2/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27567.315 total time=   2.2s\n",
      "[CV 3/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "28261.29659034838\n",
      "[CV 3/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-28261.297 total time=   4.1s\n",
      "[CV 4/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "26014.304589955143\n",
      "[CV 4/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26014.305 total time=   4.7s\n",
      "[CV 5/5; 114/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "34015\n",
      "[CV 5/5; 114/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-34015.000 total time=   3.4s\n",
      "[CV 1/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21415.213789929734\n",
      "[CV 1/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21415.214 total time=  23.8s\n",
      "[CV 2/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "26642.295354843325\n",
      "[CV 2/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26642.295 total time=  23.9s\n",
      "[CV 3/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "27866.29659034838\n",
      "[CV 3/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27866.297 total time=  23.9s\n",
      "[CV 4/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "26694.304589955143\n",
      "[CV 4/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26694.305 total time=  23.9s\n",
      "[CV 5/5; 115/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "32925\n",
      "[CV 5/5; 115/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-32925.000 total time=  26.2s\n",
      "[CV 1/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42332.33149042004\n",
      "[CV 1/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42332.331 total time=   2.6s\n",
      "[CV 2/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46009.41171941066\n",
      "[CV 2/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46009.412 total time=   2.4s\n",
      "[CV 3/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53050.82659034838\n",
      "[CV 3/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53050.827 total time=   2.5s\n",
      "[CV 4/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34397.62458995514\n",
      "[CV 4/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34397.625 total time=   3.1s\n",
      "[CV 5/5; 116/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "50600\n",
      "[CV 5/5; 116/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-50600.000 total time=   3.1s\n",
      "[CV 1/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   3.0s\n",
      "[CV 2/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.2s\n",
      "[CV 3/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.1s\n",
      "[CV 4/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.2s\n",
      "[CV 5/5; 117/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 117/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.3s\n",
      "[CV 1/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 118/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 118/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 119/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 119/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 120/192] START logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 120/192] END logisticregression__C=0.1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  24.1s\n",
      "[CV 2/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  24.7s\n",
      "[CV 3/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  24.4s\n",
      "[CV 4/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  24.1s\n",
      "[CV 5/5; 121/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 121/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  24.5s\n",
      "[CV 1/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.3s\n",
      "[CV 2/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.2s\n",
      "[CV 3/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.4s\n",
      "[CV 4/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.3s\n",
      "[CV 5/5; 122/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 122/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   3.0s\n",
      "[CV 1/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 123/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 123/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 124/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 124/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 125/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 125/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "12565.213789929732\n",
      "[CV 1/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12565.214 total time=   3.7s\n",
      "[CV 2/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "12894.381719410661\n",
      "[CV 2/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12894.382 total time=   4.0s\n",
      "[CV 3/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "18641.69659034838\n",
      "[CV 3/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-18641.697 total time=   1.9s\n",
      "[CV 4/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "15496.644589955144\n",
      "[CV 4/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-15496.645 total time=   2.8s\n",
      "[CV 5/5; 126/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "18097.7\n",
      "[CV 5/5; 126/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-18097.700 total time=   3.5s\n",
      "[CV 1/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12520.213789929732\n",
      "[CV 1/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12520.214 total time=  24.1s\n",
      "[CV 2/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12869.381719410661\n",
      "[CV 2/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12869.382 total time=  24.3s\n",
      "[CV 3/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "17151.69659034838\n",
      "[CV 3/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17151.697 total time=  24.4s\n",
      "[CV 4/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "14684.304589955143\n",
      "[CV 4/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14684.305 total time=  24.5s\n",
      "[CV 5/5; 127/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17902.7\n",
      "[CV 5/5; 127/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17902.700 total time=  23.8s\n",
      "[CV 1/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "18538.11149042004\n",
      "[CV 1/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-18538.111 total time=   2.7s\n",
      "[CV 2/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16209.381719410661\n",
      "[CV 2/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16209.382 total time=   3.4s\n",
      "[CV 3/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32547.916590348377\n",
      "[CV 3/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32547.917 total time=   2.4s\n",
      "[CV 4/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.2s\n",
      "[CV 5/5; 128/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 128/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26543.460 total time=   2.8s\n",
      "[CV 1/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.8s\n",
      "[CV 2/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.8s\n",
      "[CV 3/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   3.0s\n",
      "[CV 4/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.6s\n",
      "[CV 5/5; 129/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 129/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   3.0s\n",
      "[CV 1/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 130/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 130/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 131/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 131/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 132/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 132/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  23.1s\n",
      "[CV 2/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  23.0s\n",
      "[CV 3/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  23.1s\n",
      "[CV 4/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  24.6s\n",
      "[CV 5/5; 133/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 133/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.0s\n",
      "[CV 1/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.2s\n",
      "[CV 2/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.2s\n",
      "[CV 3/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.2s\n",
      "[CV 4/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.2s\n",
      "[CV 5/5; 134/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 134/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.7s\n",
      "[CV 1/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 135/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 135/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 136/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 136/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 137/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 137/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "21645.213789929734\n",
      "[CV 1/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21645.214 total time=   4.1s\n",
      "[CV 2/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "23792.285354843327\n",
      "[CV 2/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-23792.285 total time=   6.4s\n",
      "[CV 3/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "28346.29659034838\n",
      "[CV 3/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-28346.297 total time=   4.0s\n",
      "[CV 4/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "27379.304589955143\n",
      "[CV 4/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27379.305 total time=   2.7s\n",
      "[CV 5/5; 138/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "32735\n",
      "[CV 5/5; 138/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-32735.000 total time=   4.6s\n",
      "[CV 1/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21535.213789929734\n",
      "[CV 1/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21535.214 total time=  23.3s\n",
      "[CV 2/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24692.285354843327\n",
      "[CV 2/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-24692.285 total time=  23.9s\n",
      "[CV 3/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28356.29659034838\n",
      "[CV 3/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-28356.297 total time=  23.5s\n",
      "[CV 4/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "26394.304589955143\n",
      "[CV 4/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26394.305 total time=  23.8s\n",
      "[CV 5/5; 139/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33910\n",
      "[CV 5/5; 139/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33910.000 total time=  24.1s\n",
      "[CV 1/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.2s\n",
      "[CV 2/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.2s\n",
      "[CV 3/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53050.82659034838\n",
      "[CV 3/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53050.827 total time=   2.2s\n",
      "[CV 4/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.0s\n",
      "[CV 5/5; 140/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "37390\n",
      "[CV 5/5; 140/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-37390.000 total time=   3.4s\n",
      "[CV 1/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.9s\n",
      "[CV 2/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.2s\n",
      "[CV 3/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.1s\n",
      "[CV 4/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.2s\n",
      "[CV 5/5; 141/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 141/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.3s\n",
      "[CV 1/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 142/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 142/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 143/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 143/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 144/192] START logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 144/192] END logisticregression__C=1, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  24.1s\n",
      "[CV 2/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  24.9s\n",
      "[CV 3/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  25.0s\n",
      "[CV 4/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  24.1s\n",
      "[CV 5/5; 145/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 145/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  26.1s\n",
      "[CV 1/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.6s\n",
      "[CV 2/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.2s\n",
      "[CV 3/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.4s\n",
      "[CV 4/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.2s\n",
      "[CV 5/5; 146/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 146/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   2.9s\n",
      "[CV 1/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 147/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 147/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 148/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 148/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 149/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 149/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "12390.213789929732\n",
      "[CV 1/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12390.214 total time=   4.4s\n",
      "[CV 2/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "13009.381719410661\n",
      "[CV 2/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13009.382 total time=   3.2s\n",
      "[CV 3/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16536.69659034838\n",
      "[CV 3/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16536.697 total time=   4.0s\n",
      "[CV 4/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "14766.644589955144\n",
      "[CV 4/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-14766.645 total time=   4.0s\n",
      "[CV 5/5; 150/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "18172.7\n",
      "[CV 5/5; 150/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-18172.700 total time=   2.9s\n",
      "[CV 1/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12300.213789929732\n",
      "[CV 1/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12300.214 total time=  25.6s\n",
      "[CV 2/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12484.381719410661\n",
      "[CV 2/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12484.382 total time=  25.0s\n",
      "[CV 3/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16531.69659034838\n",
      "[CV 3/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16531.697 total time=  23.9s\n",
      "[CV 4/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15174.304589955143\n",
      "[CV 4/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-15174.305 total time=  23.5s\n",
      "[CV 5/5; 151/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17727.7\n",
      "[CV 5/5; 151/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17727.700 total time=  24.6s\n",
      "[CV 1/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "18538.11149042004\n",
      "[CV 1/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-18538.111 total time=   2.8s\n",
      "[CV 2/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.3s\n",
      "[CV 3/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.4s\n",
      "[CV 4/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.4s\n",
      "[CV 5/5; 152/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 152/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26543.460 total time=   3.1s\n",
      "[CV 1/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   3.0s\n",
      "[CV 2/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   2.9s\n",
      "[CV 3/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   2.8s\n",
      "[CV 4/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   2.5s\n",
      "[CV 5/5; 153/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 153/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   3.0s\n",
      "[CV 1/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 154/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 154/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 155/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 155/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 156/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 156/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  23.2s\n",
      "[CV 2/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  23.2s\n",
      "[CV 3/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  24.3s\n",
      "[CV 4/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  25.5s\n",
      "[CV 5/5; 157/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 157/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  23.3s\n",
      "[CV 1/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.3s\n",
      "[CV 2/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.3s\n",
      "[CV 3/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.3s\n",
      "[CV 4/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.3s\n",
      "[CV 5/5; 158/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 158/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.7s\n",
      "[CV 1/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 159/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 159/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 160/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 160/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 161/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 161/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "20965.213789929734\n",
      "[CV 1/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-20965.214 total time=   5.2s\n",
      "[CV 2/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "24232.285354843327\n",
      "[CV 2/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24232.285 total time=   3.5s\n",
      "[CV 3/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 4\n",
      "28241.29659034838\n",
      "[CV 3/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-28241.297 total time=   4.5s\n",
      "[CV 4/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "26234.304589955143\n",
      "[CV 4/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-26234.305 total time=   3.1s\n",
      "[CV 5/5; 162/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "33015\n",
      "[CV 5/5; 162/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-33015.000 total time=   3.7s\n",
      "[CV 1/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "21950.213789929734\n",
      "[CV 1/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-21950.214 total time=  26.3s\n",
      "[CV 2/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "23492.285354843327\n",
      "[CV 2/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-23492.285 total time=  24.2s\n",
      "[CV 3/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28036.29659034838\n",
      "[CV 3/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-28036.297 total time=  24.8s\n",
      "[CV 4/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "26987.044589955145\n",
      "[CV 4/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-26987.045 total time=  23.6s\n",
      "[CV 5/5; 163/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33235\n",
      "[CV 5/5; 163/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33235.000 total time=  23.9s\n",
      "[CV 1/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42327.331 total time=   2.3s\n",
      "[CV 2/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46004.412 total time=   2.3s\n",
      "[CV 3/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53045.827 total time=   2.3s\n",
      "[CV 4/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34387.625 total time=   3.2s\n",
      "[CV 5/5; 164/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "50870\n",
      "[CV 5/5; 164/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-50870.000 total time=   2.9s\n",
      "[CV 1/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   3.0s\n",
      "[CV 2/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   3.1s\n",
      "[CV 3/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.1s\n",
      "[CV 4/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   3.2s\n",
      "[CV 5/5; 165/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 165/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   2.3s\n",
      "[CV 1/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 166/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 166/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 167/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 167/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 168/192] START logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 168/192] END logisticregression__C=10, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12440.213789929732\n",
      "[CV 1/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12440.214 total time=  23.8s\n",
      "[CV 2/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12784.381719410661\n",
      "[CV 2/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-12784.382 total time=  24.4s\n",
      "[CV 3/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16286.696590348378\n",
      "[CV 3/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-16286.697 total time=  24.7s\n",
      "[CV 4/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "15194.304589955143\n",
      "[CV 4/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-15194.305 total time=  23.6s\n",
      "[CV 5/5; 169/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17972.7\n",
      "[CV 5/5; 169/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-17972.700 total time=  24.3s\n",
      "[CV 1/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "19540.213789929734\n",
      "[CV 1/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-19540.214 total time=   3.3s\n",
      "[CV 2/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16369.381719410661\n",
      "[CV 2/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-16369.382 total time=   3.2s\n",
      "[CV 3/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-32552.917 total time=   2.3s\n",
      "[CV 4/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-29471.615 total time=   2.2s\n",
      "[CV 5/5; 170/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 170/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-26543.460 total time=   2.9s\n",
      "[CV 1/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 171/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 171/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 172/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 172/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 173/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 173/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "13185.213789929732\n",
      "[CV 1/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-13185.214 total time=   2.3s\n",
      "[CV 2/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "12904.381719410661\n",
      "[CV 2/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-12904.382 total time=   4.6s\n",
      "[CV 3/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "16476.69659034838\n",
      "[CV 3/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-16476.697 total time=   3.6s\n",
      "[CV 4/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "14281.644589955144\n",
      "[CV 4/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-14281.645 total time=   5.8s\n",
      "[CV 5/5; 174/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 2\n",
      "17877.7\n",
      "[CV 5/5; 174/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-17877.700 total time=   1.9s\n",
      "[CV 1/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "12745.213789929732\n",
      "[CV 1/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12745.214 total time=  17.4s\n",
      "[CV 2/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "12704.381719410661\n",
      "[CV 2/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-12704.382 total time=  18.5s\n",
      "[CV 3/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16386.69659034838\n",
      "[CV 3/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-16386.697 total time=  18.2s\n",
      "[CV 4/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "14494.304589955143\n",
      "[CV 4/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-14494.305 total time=  18.0s\n",
      "[CV 5/5; 175/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 2\n",
      "17917.7\n",
      "[CV 5/5; 175/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-17917.700 total time=  18.2s\n",
      "[CV 1/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "16734.213789929734\n",
      "[CV 1/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16734.214 total time=   2.5s\n",
      "[CV 2/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "16579.38171941066\n",
      "[CV 2/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-16579.382 total time=   2.7s\n",
      "[CV 3/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "32552.916590348377\n",
      "[CV 3/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-32552.917 total time=   1.8s\n",
      "[CV 4/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 5\n",
      "29471.614589955145\n",
      "[CV 4/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-29471.615 total time=   1.7s\n",
      "[CV 5/5; 176/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 2\n",
      "26543.46\n",
      "[CV 5/5; 176/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-26543.460 total time=   2.2s\n",
      "[CV 1/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 1/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.9s\n",
      "[CV 2/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226510\n",
      "[CV 2/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226510.000 total time=   1.8s\n",
      "[CV 3/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226495\n",
      "[CV 3/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226495.000 total time=   1.8s\n",
      "[CV 4/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227520\n",
      "[CV 4/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227520.000 total time=   1.6s\n",
      "[CV 5/5; 177/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227135\n",
      "[CV 5/5; 177/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227135.000 total time=   2.0s\n",
      "[CV 1/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 178/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 178/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 179/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 179/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 180/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 180/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 10.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22190.213789929734\n",
      "[CV 1/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-22190.214 total time=  17.3s\n",
      "[CV 2/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "24717.285354843327\n",
      "[CV 2/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-24717.285 total time=  17.2s\n",
      "[CV 3/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "28966.29659034838\n",
      "[CV 3/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-28966.297 total time=  17.4s\n",
      "[CV 4/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27617.044589955145\n",
      "[CV 4/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-27617.045 total time=  17.4s\n",
      "[CV 5/5; 181/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33455\n",
      "[CV 5/5; 181/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-33455.000 total time=  17.1s\n",
      "[CV 1/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-42327.331 total time=   1.7s\n",
      "[CV 2/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-46004.412 total time=   1.7s\n",
      "[CV 3/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-53045.827 total time=   1.7s\n",
      "[CV 4/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-34387.625 total time=   2.4s\n",
      "[CV 5/5; 182/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "49900\n",
      "[CV 5/5; 182/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-49900.000 total time=   2.0s\n",
      "[CV 1/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 183/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 183/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 184/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 184/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 185/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 185/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "21955.213789929734\n",
      "[CV 1/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-21955.214 total time=   1.8s\n",
      "[CV 2/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "24567.285354843327\n",
      "[CV 2/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-24567.285 total time=   1.7s\n",
      "[CV 3/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "31717.35659034838\n",
      "[CV 3/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-31717.357 total time=   1.3s\n",
      "[CV 4/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 5\n",
      "27699.304589955143\n",
      "[CV 4/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-27699.305 total time=   1.5s\n",
      "[CV 5/5; 186/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "32795\n",
      "[CV 5/5; 186/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-32795.000 total time=   2.3s\n",
      "[CV 1/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "22640.213789929734\n",
      "[CV 1/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-22640.214 total time=  17.5s\n",
      "[CV 2/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "23447.285354843327\n",
      "[CV 2/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-23447.285 total time=  18.3s\n",
      "[CV 3/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 5\n",
      "29992.35659034838\n",
      "[CV 3/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-29992.357 total time=  18.2s\n",
      "[CV 4/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 3\n",
      "27987.044589955145\n",
      "[CV 4/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-27987.045 total time=  18.2s\n",
      "[CV 5/5; 187/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 0\n",
      "33095\n",
      "[CV 5/5; 187/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-33095.000 total time=  18.3s\n",
      "[CV 1/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "42327.33149042004\n",
      "[CV 1/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-42327.331 total time=   1.8s\n",
      "[CV 2/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "46004.41171941066\n",
      "[CV 2/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-46004.412 total time=   1.7s\n",
      "[CV 3/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "53045.82659034838\n",
      "[CV 3/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-53045.827 total time=   1.8s\n",
      "[CV 4/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 4\n",
      "34387.62458995514\n",
      "[CV 4/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-34387.625 total time=   2.4s\n",
      "[CV 5/5; 188/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 0\n",
      "44760\n",
      "[CV 5/5; 188/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-44760.000 total time=   2.1s\n",
      "[CV 1/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227435\n",
      "[CV 1/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227435.000 total time=   2.0s\n",
      "[CV 2/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227080\n",
      "[CV 2/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227080.000 total time=   2.2s\n",
      "[CV 3/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 3/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.1s\n",
      "[CV 4/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "226920\n",
      "[CV 4/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-226920.000 total time=   2.2s\n",
      "[CV 5/5; 189/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 0\n",
      "227830\n",
      "[CV 5/5; 189/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-227830.000 total time=   1.6s\n",
      "[CV 1/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 190/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 190/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 191/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 191/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 192/192] START logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 192/192] END logisticregression__C=100, logisticregression__class_weight={0: 1.0, 1: 25.0}, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "480 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [ -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -56121.90685194  -20036.65333793  -27783.13287803\n",
      " -226832.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan -101738.09931807  -55175.55281327  -57799.49514702\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -24564.22333793  -17489.23006502  -28212.13076793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -42424.94081327  -33796.38806502  -48464.65814081\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -16604.70806502  -15939.65933793  -24830.19287803\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -29617.64206502  -29224.38206502  -46056.04333793\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -15504.12733793  -15271.65933793  -24328.82933793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -27162.62206502  -27434.16806502  -45392.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -14856.12733793  -14956.65933793  -24477.51733793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -27545.62606502  -27108.62206502  -45278.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -15539.12733793  -15025.65933793  -24662.09687803\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -26779.62006502  -26977.62006502  -42632.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -14975.12733793  -14843.65933793  -24695.09687803\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -26537.62006502  -26740.16806502  -45327.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -14945.12733793  -14849.65933793  -24376.31733793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -27746.83206502  -27432.38006502  -44105.03887803\n",
      " -227237.                      nan              nan              nan]\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_imba_wo_outliers = GridSearchCV(imba_pipeline, param_grid=new_params, cv=5, scoring=my_func_smt_wo_outliers,  verbose=10)\n",
    "grid_search_imba_wo_outliers = grid_imba_wo_outliers.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "177f8907-4731-4c74-8f3d-ea5f8249495d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [ -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -56121.90685194  -20036.65333793  -27783.13287803\n",
      " -226832.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan -101738.09931807  -55175.55281327  -57799.49514702\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -24564.22333793  -17489.23006502  -28212.13076793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -42424.94081327  -33796.38806502  -48464.65814081\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -16604.70806502  -15939.65933793  -24830.19287803\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -29617.64206502  -29224.38206502  -46056.04333793\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -15504.12733793  -15271.65933793  -24328.82933793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -27162.62206502  -27434.16806502  -45392.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -14856.12733793  -14956.65933793  -24477.51733793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -27545.62606502  -27108.62206502  -45278.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -15539.12733793  -15025.65933793  -24662.09687803\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -26779.62006502  -26977.62006502  -42632.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -14975.12733793  -14843.65933793  -24695.09687803\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -26537.62006502  -26740.16806502  -45327.03887803\n",
      " -227237.                      nan              nan              nan\n",
      "  -14935.65933793  -24895.51733793              nan              nan\n",
      "              nan  -14945.12733793  -14849.65933793  -24376.31733793\n",
      " -226831.                      nan              nan              nan\n",
      "  -27389.16806502  -45133.03887803              nan              nan\n",
      "              nan  -27746.83206502  -27432.38006502  -44105.03887803\n",
      " -227237.                      nan              nan              nan], using {'logisticregression__C': 10, 'logisticregression__class_weight': {0: 1.0, 1: 10.0}, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.239008</td>\n",
       "      <td>0.455604</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-12440.21379</td>\n",
       "      <td>-12784.381719</td>\n",
       "      <td>-16286.69659</td>\n",
       "      <td>-15194.30459</td>\n",
       "      <td>-17972.70</td>\n",
       "      <td>-14935.659338</td>\n",
       "      <td>2096.237529</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.371387</td>\n",
       "      <td>0.417453</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-19540.21379</td>\n",
       "      <td>-16369.381719</td>\n",
       "      <td>-32552.91659</td>\n",
       "      <td>-29471.61459</td>\n",
       "      <td>-26543.46</td>\n",
       "      <td>-24895.517338</td>\n",
       "      <td>6060.798777</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291005</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.292998</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{0: 1.0, 1: 10.0}</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2.036799</td>\n",
       "      <td>0.275182</td>\n",
       "      <td>0.020595</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-42327.33149</td>\n",
       "      <td>-46004.411719</td>\n",
       "      <td>-53045.82659</td>\n",
       "      <td>-34387.62459</td>\n",
       "      <td>-44760.00</td>\n",
       "      <td>-44105.038878</td>\n",
       "      <td>6025.988055</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2.105612</td>\n",
       "      <td>0.228460</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-227435.00000</td>\n",
       "      <td>-227080.000000</td>\n",
       "      <td>-226920.00000</td>\n",
       "      <td>-226920.00000</td>\n",
       "      <td>-227830.00</td>\n",
       "      <td>-227237.000000</td>\n",
       "      <td>351.135302</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.271193</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.269387</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1.0, 1: 25.0}</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        19.239008      0.455604         0.021799        0.000982   \n",
       "1         2.371387      0.417453         0.020821        0.000396   \n",
       "2         0.291005      0.007483         0.000000        0.000000   \n",
       "3         0.289000      0.010412         0.000000        0.000000   \n",
       "4         0.292998      0.009864         0.000000        0.000000   \n",
       "..             ...           ...              ...             ...   \n",
       "187       2.036799      0.275182         0.020595        0.000499   \n",
       "188       2.105612      0.228460         0.016600        0.000491   \n",
       "189       0.276800      0.002933         0.000000        0.000000   \n",
       "190       0.271193      0.002931         0.000000        0.000000   \n",
       "191       0.269387      0.004801         0.000000        0.000000   \n",
       "\n",
       "    param_logisticregression__C param_logisticregression__class_weight  \\\n",
       "0                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "1                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "2                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "3                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "4                       0.00001                      {0: 1.0, 1: 10.0}   \n",
       "..                          ...                                    ...   \n",
       "187                         100                      {0: 1.0, 1: 25.0}   \n",
       "188                         100                      {0: 1.0, 1: 25.0}   \n",
       "189                         100                      {0: 1.0, 1: 25.0}   \n",
       "190                         100                      {0: 1.0, 1: 25.0}   \n",
       "191                         100                      {0: 1.0, 1: 25.0}   \n",
       "\n",
       "    param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "0                                none                        newton-cg   \n",
       "1                                none                            lbfgs   \n",
       "2                                none                        liblinear   \n",
       "3                                  l1                        newton-cg   \n",
       "4                                  l1                            lbfgs   \n",
       "..                                ...                              ...   \n",
       "187                                l2                            lbfgs   \n",
       "188                                l2                        liblinear   \n",
       "189                        elasticnet                        newton-cg   \n",
       "190                        elasticnet                            lbfgs   \n",
       "191                        elasticnet                        liblinear   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'logisticregression__C': 1e-05, 'logisticregr...       -12440.21379   \n",
       "1    {'logisticregression__C': 1e-05, 'logisticregr...       -19540.21379   \n",
       "2    {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "3    {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "4    {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "..                                                 ...                ...   \n",
       "187  {'logisticregression__C': 100, 'logisticregres...       -42327.33149   \n",
       "188  {'logisticregression__C': 100, 'logisticregres...      -227435.00000   \n",
       "189  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "190  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "191  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0        -12784.381719       -16286.69659       -15194.30459   \n",
       "1        -16369.381719       -32552.91659       -29471.61459   \n",
       "2                  NaN                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                  NaN                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "187      -46004.411719       -53045.82659       -34387.62459   \n",
       "188     -227080.000000      -226920.00000      -226920.00000   \n",
       "189                NaN                NaN                NaN   \n",
       "190                NaN                NaN                NaN   \n",
       "191                NaN                NaN                NaN   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            -17972.70    -14935.659338     2096.237529                4  \n",
       "1            -26543.46    -24895.517338     6060.798777               30  \n",
       "2                  NaN              NaN             NaN              157  \n",
       "3                  NaN              NaN             NaN              156  \n",
       "4                  NaN              NaN             NaN              155  \n",
       "..                 ...              ...             ...              ...  \n",
       "187          -44760.00    -44105.038878     6025.988055               63  \n",
       "188         -227830.00   -227237.000000      351.135302               89  \n",
       "189                NaN              NaN             NaN              115  \n",
       "190                NaN              NaN             NaN              175  \n",
       "191                NaN              NaN             NaN              192  \n",
       "\n",
       "[192 rows x 17 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_search_imba_wo_outliers.cv_results_['mean_test_score'], grid_search_imba_wo_outliers.best_params_))\n",
    "results_df_imba_wo_outliers = pd.DataFrame(grid_search_imba_wo_outliers.cv_results_)\n",
    "results_df_imba_wo_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d119cca-d7fa-454e-a850-41583d22d618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
