{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72710333-acc9-4694-8904-3f40b391bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dcbbe3-3ee4-4382-85c2-f564f3feefdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "transactions = pd.read_csv(\"Data/creditcard.csv\")\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566e7f0c-6e96-4161-b7ca-660a83467677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "X = transactions.drop(['Class'], axis=1) # Features\n",
    "y = transactions.Class # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ae2d03-d8ca-49ef-beb3-7a681961ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "276f6f5c-1788-4026-abe8-a86e2914a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C': 100, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "model = LogisticRegression(solver='liblinear', C=100, penalty='l1', random_state=0)\n",
    "\n",
    "# Train\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f130107-6783-4cee-b788-1983c245935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Confusion matrix  \n",
    "cm= confusion_matrix(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fdaac1-1f85-4f94-b5c2-0a0f95dc4264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b824259e-fd96-4366-85e5-fcbc676c055e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sns.heatmap(cm/np.sum(cm), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef391705-d83e-4652-bd30-60c61155f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.00\n",
      "\n",
      "Micro Precision: 1.00\n",
      "Micro Recall: 1.00\n",
      "Micro F1-score: 1.00\n",
      "\n",
      "Macro Precision: 0.87\n",
      "Macro Recall: 0.78\n",
      "Macro F1-score: 0.82\n",
      "\n",
      "Weighted Precision: 1.00\n",
      "Weighted Recall: 1.00\n",
      "Weighted F1-score: 1.00\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56861\n",
      "           1       0.74      0.56      0.64       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.78      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f99400-399f-4f90-88f6-db5838d902c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FN, FP, TN = 0, 0, 0, 0\n",
    "\n",
    "def confusion_matrix_for(cls, cm):\n",
    "    TP = cm[cls, cls]\n",
    "    FN = cm[cls].sum() - TP\n",
    "    FP = cm[:, cls].sum() - TP\n",
    "    TN = cm.sum() - TP - FN - FP\n",
    "    return np.array([[TP, FN], [FP, TN]])\n",
    "\n",
    "def getTotalAmountFalseNegative(df):\n",
    "    df = df[df.case == 'false negative'] \n",
    "    totalAmount = 0\n",
    "    for index, row in df.iterrows():\n",
    "        totalAmount += row.Amount\n",
    "    return totalAmount\n",
    "\n",
    "def total_cost(cm, X_test, y_test, y_pred):\n",
    "    for cls in range(cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, cm).ravel()\n",
    "        #print(f'TP: {TP}, FN: {FN}, FP: {FP}, TN: {TN}')\n",
    "    \n",
    "    print(f'TP: {TP}, FN: {FN}, FP: {FP}, TN: {TN}')\n",
    "\n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "\n",
    "    X_test['case'] = labels[y_test * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegative(X_test) + (FP + TP) * Ca\n",
    "    print('Total cost: ' + str(TotalCost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "412ed753-f4b4-49d6-a182-833fccf0492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 57, FN: 44, FP: 20, TN: 56841\n",
      "Total cost: 8950.170000000002\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm, X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7e552-6833-404c-aa0b-316900633273",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0ed6f6-eb0b-4eb0-a97c-d5dfb213e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce76f819-9627-4040-b838-599ba6beb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=1) # Numerical value\n",
    "# rus = RandomUnderSampler(sampling_strategy=\"not minority\") # String\n",
    "X_train_us, y_train_us = rus.fit_resample(X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183689fa-5da2-4976-945f-f9ec9ac94e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# Train\n",
    "model_us = model.fit(X_train_us,y_train_us)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_us = model.predict(X_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c22ad7-6a3a-4625-988f-36fabd6acabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm_us = confusion_matrix(y_test_us, y_pred_us) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870c54e9-db5c-4a57-804d-5823add6d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_us, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e684183-2d31-496a-9316-b4221b9966b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_us/np.sum(cm_us), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c64f1c-2e29-423b-bc44-f7aa5066af48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 90, FN: 8, FP: 2047, TN: 54817\n",
      "Total cost: 11343.61\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm_us, X_test_us, y_test_us, y_pred_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa10484-fc6c-4fe5-90be-647f550113fe",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "581a7c00-37fc-4755-9ca4-ec649f75693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) # 80% training and 20% test\n",
    "\n",
    "smote_technique = SMOTE(sampling_strategy='minority')\n",
    "X_smt, y_smt = smote_technique.fit_resample(X_train_smt, y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d168c954-3f11-4d3b-817e-1a48d3953e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 'logisticregression__C': 1e-05, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'\n",
    "model_smt = LogisticRegression(C=1e-05, penalty='l2',solver='newton-cg')\n",
    "\n",
    "# Train\n",
    "model_smt = model_smt.fit(X_smt,y_smt)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_smt = model_smt.predict(X_test_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40005461-92c0-4c6d-be33-a402ccfaf5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm_smt = confusion_matrix(y_test_smt, y_pred_smt) \n",
    "\n",
    "sns.heatmap(cm_smt/np.sum(cm_smt), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1533d3b2-2f26-4a03-8f59-1f25c24aa1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 87, FN: 11, FP: 345, TN: 56519\n",
      "Total cost: 3986.5\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm_smt, X_test_smt, y_test_smt, y_pred_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da76817-f7ed-486b-96fb-057af668a08a",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c934ba22-0c69-44da-b000-76107423921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def get_x_elements_by_indices(x_train, indices):\n",
    "    new_df = pd.DataFrame()\n",
    "    for index in indices:\n",
    "        try:\n",
    "            new_df = new_df.append(x_train.iloc[index])\n",
    "        except:\n",
    "            print(str(index) + \" not found\")\n",
    "    return new_df\n",
    "\n",
    "def getTotalAmountFalseNegativeMyScorer(df, y_test, y_pred):\n",
    "    fn_indices = []\n",
    "    for ((index, row), i) in zip(y_test.items(), range(len(y_pred))):\n",
    "        if y_pred[i]==0 and row!=y_pred[i]:\n",
    "            fn_indices.append(index)\n",
    "    print(\"No of FN: \" + str(len(fn_indices)))\n",
    "    df = df.iloc[fn_indices]\n",
    "    totalAmount = 0\n",
    "    for index, row in df.iterrows():\n",
    "        totalAmount += row.Amount\n",
    "    return totalAmount\n",
    "\n",
    "def my_scorer(y_true, y_pred):\n",
    "    model_cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    for cls in range(model_cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, model_cm).ravel() \n",
    "        \n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "    X_test_score = X\n",
    "    # X_test_score = get_x_elements_by_indices(X_test_score, y_true.index)\n",
    "    #print(labels[y_true * 2 + y_pred])\n",
    "    #X_test_score['case'] = labels[y_true * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegativeMyScorer(X_test_score, y_true, y_pred) + (FP + TP) * Ca\n",
    "    print(TotalCost)\n",
    "    return TotalCost\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "my_func = make_scorer(my_scorer, greater_is_better=False)\n",
    "\n",
    "#my_scorer(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40af14e9-49b0-44eb-8693-7eef8b5ecc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# define search\n",
    "#search = GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504222c8-912c-47fd-9e7a-d5eef87aa32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search\n",
    "# search = GridSearchCV(model, space, cv=cv, scoring='f1', n_jobs=-1)\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring=my_func, cv=cv, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42fb557d-f9e5-403f-aa0a-795c63ac2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute search\n",
    "#result = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa0dddf3-d47a-4f36-9f40-3703b56ede21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9989554302261862\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09719699-678e-4706-8032-97b95aa6db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty  = ['none', 'l1', 'l2', 'elasticnet']\n",
    "C = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# Define parameters\n",
    "param_grid = dict(solver=solver, penalty=penalty, C=C)\n",
    "\n",
    "# Build the gridsearch\n",
    "lr = LogisticRegression()\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, scoring=my_func, cv = 5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5487de7a-da66-44a0-9212-ab6a35bb9948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START C=1e-05, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 1/96] END C=1e-05, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.7s\n",
      "[CV 2/5; 1/96] START C=1e-05, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 1/96] END C=1e-05, penalty=none, solver=newton-cg;, score=-7092.450 total time=  10.4s\n",
      "[CV 3/5; 1/96] START C=1e-05, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 1/96] END C=1e-05, penalty=none, solver=newton-cg;, score=-3285.260 total time=  10.4s\n",
      "[CV 4/5; 1/96] START C=1e-05, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 1/96] END C=1e-05, penalty=none, solver=newton-cg;, score=-4171.470 total time=  10.2s\n",
      "[CV 5/5; 1/96] START C=1e-05, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 1/96] END C=1e-05, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.5s\n",
      "[CV 1/5; 2/96] START C=1e-05, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 2/96] END C=1e-05, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.4s\n",
      "[CV 2/5; 2/96] START C=1e-05, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 2/96] END C=1e-05, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.4s\n",
      "[CV 3/5; 2/96] START C=1e-05, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 2/96] END C=1e-05, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.3s\n",
      "[CV 4/5; 2/96] START C=1e-05, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 2/96] END C=1e-05, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.5s\n",
      "[CV 5/5; 2/96] START C=1e-05, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 2/96] END C=1e-05, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.5s\n",
      "[CV 1/5; 3/96] START C=1e-05, penalty=none, solver=liblinear....................\n",
      "[CV 1/5; 3/96] END C=1e-05, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/96] START C=1e-05, penalty=none, solver=liblinear....................\n",
      "[CV 2/5; 3/96] END C=1e-05, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/96] START C=1e-05, penalty=none, solver=liblinear....................\n",
      "[CV 3/5; 3/96] END C=1e-05, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/96] START C=1e-05, penalty=none, solver=liblinear....................\n",
      "[CV 4/5; 3/96] END C=1e-05, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/96] START C=1e-05, penalty=none, solver=liblinear....................\n",
      "[CV 5/5; 3/96] END C=1e-05, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/96] START C=1e-05, penalty=l1, solver=newton-cg......................\n",
      "[CV 1/5; 4/96] END C=1e-05, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 4/96] START C=1e-05, penalty=l1, solver=newton-cg......................\n",
      "[CV 2/5; 4/96] END C=1e-05, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/96] START C=1e-05, penalty=l1, solver=newton-cg......................\n",
      "[CV 3/5; 4/96] END C=1e-05, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 4/96] START C=1e-05, penalty=l1, solver=newton-cg......................\n",
      "[CV 4/5; 4/96] END C=1e-05, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/96] START C=1e-05, penalty=l1, solver=newton-cg......................\n",
      "[CV 5/5; 4/96] END C=1e-05, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/96] START C=1e-05, penalty=l1, solver=lbfgs..........................\n",
      "[CV 1/5; 5/96] END C=1e-05, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 5/96] START C=1e-05, penalty=l1, solver=lbfgs..........................\n",
      "[CV 2/5; 5/96] END C=1e-05, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/96] START C=1e-05, penalty=l1, solver=lbfgs..........................\n",
      "[CV 3/5; 5/96] END C=1e-05, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/96] START C=1e-05, penalty=l1, solver=lbfgs..........................\n",
      "[CV 4/5; 5/96] END C=1e-05, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/96] START C=1e-05, penalty=l1, solver=lbfgs..........................\n",
      "[CV 5/5; 5/96] END C=1e-05, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/96] START C=1e-05, penalty=l1, solver=liblinear......................\n",
      "No of FN: 78\n",
      "7300.529999999998\n",
      "[CV 1/5; 6/96] END C=1e-05, penalty=l1, solver=liblinear;, score=-7300.530 total time=   0.2s\n",
      "[CV 2/5; 6/96] START C=1e-05, penalty=l1, solver=liblinear......................\n",
      "No of FN: 78\n",
      "10858.949999999997\n",
      "[CV 2/5; 6/96] END C=1e-05, penalty=l1, solver=liblinear;, score=-10858.950 total time=   0.3s\n",
      "[CV 3/5; 6/96] START C=1e-05, penalty=l1, solver=liblinear......................\n",
      "No of FN: 78\n",
      "6768.910000000001\n",
      "[CV 3/5; 6/96] END C=1e-05, penalty=l1, solver=liblinear;, score=-6768.910 total time=   0.2s\n",
      "[CV 4/5; 6/96] START C=1e-05, penalty=l1, solver=liblinear......................\n",
      "No of FN: 78\n",
      "7686.04\n",
      "[CV 4/5; 6/96] END C=1e-05, penalty=l1, solver=liblinear;, score=-7686.040 total time=   0.2s\n",
      "[CV 5/5; 6/96] START C=1e-05, penalty=l1, solver=liblinear......................\n",
      "No of FN: 79\n",
      "16510.07\n",
      "[CV 5/5; 6/96] END C=1e-05, penalty=l1, solver=liblinear;, score=-16510.070 total time=   0.3s\n",
      "[CV 1/5; 7/96] START C=1e-05, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "7300.529999999998\n",
      "[CV 1/5; 7/96] END C=1e-05, penalty=l2, solver=newton-cg;, score=-7300.530 total time=  10.3s\n",
      "[CV 2/5; 7/96] START C=1e-05, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "10858.949999999997\n",
      "[CV 2/5; 7/96] END C=1e-05, penalty=l2, solver=newton-cg;, score=-10858.950 total time=  10.2s\n",
      "[CV 3/5; 7/96] START C=1e-05, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "6768.910000000001\n",
      "[CV 3/5; 7/96] END C=1e-05, penalty=l2, solver=newton-cg;, score=-6768.910 total time=  10.2s\n",
      "[CV 4/5; 7/96] START C=1e-05, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "7686.04\n",
      "[CV 4/5; 7/96] END C=1e-05, penalty=l2, solver=newton-cg;, score=-7686.040 total time=   9.7s\n",
      "[CV 5/5; 7/96] START C=1e-05, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 79\n",
      "16510.07\n",
      "[CV 5/5; 7/96] END C=1e-05, penalty=l2, solver=newton-cg;, score=-16510.070 total time=  10.3s\n",
      "[CV 1/5; 8/96] START C=1e-05, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "7300.529999999998\n",
      "[CV 1/5; 8/96] END C=1e-05, penalty=l2, solver=lbfgs;, score=-7300.530 total time=   1.6s\n",
      "[CV 2/5; 8/96] START C=1e-05, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "10863.949999999997\n",
      "[CV 2/5; 8/96] END C=1e-05, penalty=l2, solver=lbfgs;, score=-10863.950 total time=   1.5s\n",
      "[CV 3/5; 8/96] START C=1e-05, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "6768.910000000001\n",
      "[CV 3/5; 8/96] END C=1e-05, penalty=l2, solver=lbfgs;, score=-6768.910 total time=   1.4s\n",
      "[CV 4/5; 8/96] START C=1e-05, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 78\n",
      "7686.04\n",
      "[CV 4/5; 8/96] END C=1e-05, penalty=l2, solver=lbfgs;, score=-7686.040 total time=   1.5s\n",
      "[CV 5/5; 8/96] START C=1e-05, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 79\n",
      "16520.07\n",
      "[CV 5/5; 8/96] END C=1e-05, penalty=l2, solver=lbfgs;, score=-16520.070 total time=   1.5s\n",
      "[CV 1/5; 9/96] START C=1e-05, penalty=l2, solver=liblinear......................\n",
      "No of FN: 75\n",
      "7317.529999999998\n",
      "[CV 1/5; 9/96] END C=1e-05, penalty=l2, solver=liblinear;, score=-7317.530 total time=   1.2s\n",
      "[CV 2/5; 9/96] START C=1e-05, penalty=l2, solver=liblinear......................\n",
      "No of FN: 77\n",
      "10872.949999999997\n",
      "[CV 2/5; 9/96] END C=1e-05, penalty=l2, solver=liblinear;, score=-10872.950 total time=   1.1s\n",
      "[CV 3/5; 9/96] START C=1e-05, penalty=l2, solver=liblinear......................\n",
      "No of FN: 74\n",
      "6795.910000000001\n",
      "[CV 3/5; 9/96] END C=1e-05, penalty=l2, solver=liblinear;, score=-6795.910 total time=   1.2s\n",
      "[CV 4/5; 9/96] START C=1e-05, penalty=l2, solver=liblinear......................\n",
      "No of FN: 74\n",
      "7711.940000000001\n",
      "[CV 4/5; 9/96] END C=1e-05, penalty=l2, solver=liblinear;, score=-7711.940 total time=   1.1s\n",
      "[CV 5/5; 9/96] START C=1e-05, penalty=l2, solver=liblinear......................\n",
      "No of FN: 76\n",
      "16522.07\n",
      "[CV 5/5; 9/96] END C=1e-05, penalty=l2, solver=liblinear;, score=-16522.070 total time=   0.9s\n",
      "[CV 1/5; 10/96] START C=1e-05, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 1/5; 10/96] END C=1e-05, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 10/96] START C=1e-05, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 2/5; 10/96] END C=1e-05, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 10/96] START C=1e-05, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 3/5; 10/96] END C=1e-05, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 10/96] START C=1e-05, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 4/5; 10/96] END C=1e-05, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 10/96] START C=1e-05, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 5/5; 10/96] END C=1e-05, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 11/96] START C=1e-05, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 1/5; 11/96] END C=1e-05, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 11/96] START C=1e-05, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 2/5; 11/96] END C=1e-05, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 11/96] START C=1e-05, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 3/5; 11/96] END C=1e-05, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 11/96] START C=1e-05, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 4/5; 11/96] END C=1e-05, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 11/96] START C=1e-05, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 5/5; 11/96] END C=1e-05, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 12/96] START C=1e-05, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 1/5; 12/96] END C=1e-05, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 12/96] START C=1e-05, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 2/5; 12/96] END C=1e-05, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 12/96] START C=1e-05, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 3/5; 12/96] END C=1e-05, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 12/96] START C=1e-05, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 4/5; 12/96] END C=1e-05, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 12/96] START C=1e-05, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 5/5; 12/96] END C=1e-05, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 13/96] START C=0.0001, penalty=none, solver=newton-cg..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 13/96] END C=0.0001, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.5s\n",
      "[CV 2/5; 13/96] START C=0.0001, penalty=none, solver=newton-cg..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 13/96] END C=0.0001, penalty=none, solver=newton-cg;, score=-7092.450 total time=  10.2s\n",
      "[CV 3/5; 13/96] START C=0.0001, penalty=none, solver=newton-cg..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 13/96] END C=0.0001, penalty=none, solver=newton-cg;, score=-3285.260 total time=  10.2s\n",
      "[CV 4/5; 13/96] START C=0.0001, penalty=none, solver=newton-cg..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 13/96] END C=0.0001, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.8s\n",
      "[CV 5/5; 13/96] START C=0.0001, penalty=none, solver=newton-cg..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 13/96] END C=0.0001, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.6s\n",
      "[CV 1/5; 14/96] START C=0.0001, penalty=none, solver=lbfgs......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 14/96] END C=0.0001, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.5s\n",
      "[CV 2/5; 14/96] START C=0.0001, penalty=none, solver=lbfgs......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 14/96] END C=0.0001, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.4s\n",
      "[CV 3/5; 14/96] START C=0.0001, penalty=none, solver=lbfgs......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 14/96] END C=0.0001, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.4s\n",
      "[CV 4/5; 14/96] START C=0.0001, penalty=none, solver=lbfgs......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 14/96] END C=0.0001, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.5s\n",
      "[CV 5/5; 14/96] START C=0.0001, penalty=none, solver=lbfgs......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 14/96] END C=0.0001, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.5s\n",
      "[CV 1/5; 15/96] START C=0.0001, penalty=none, solver=liblinear..................\n",
      "[CV 1/5; 15/96] END C=0.0001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 15/96] START C=0.0001, penalty=none, solver=liblinear..................\n",
      "[CV 2/5; 15/96] END C=0.0001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 15/96] START C=0.0001, penalty=none, solver=liblinear..................\n",
      "[CV 3/5; 15/96] END C=0.0001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 15/96] START C=0.0001, penalty=none, solver=liblinear..................\n",
      "[CV 4/5; 15/96] END C=0.0001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 15/96] START C=0.0001, penalty=none, solver=liblinear..................\n",
      "[CV 5/5; 15/96] END C=0.0001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 16/96] START C=0.0001, penalty=l1, solver=newton-cg....................\n",
      "[CV 1/5; 16/96] END C=0.0001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 16/96] START C=0.0001, penalty=l1, solver=newton-cg....................\n",
      "[CV 2/5; 16/96] END C=0.0001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 16/96] START C=0.0001, penalty=l1, solver=newton-cg....................\n",
      "[CV 3/5; 16/96] END C=0.0001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 16/96] START C=0.0001, penalty=l1, solver=newton-cg....................\n",
      "[CV 4/5; 16/96] END C=0.0001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 16/96] START C=0.0001, penalty=l1, solver=newton-cg....................\n",
      "[CV 5/5; 16/96] END C=0.0001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 17/96] START C=0.0001, penalty=l1, solver=lbfgs........................\n",
      "[CV 1/5; 17/96] END C=0.0001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 17/96] START C=0.0001, penalty=l1, solver=lbfgs........................\n",
      "[CV 2/5; 17/96] END C=0.0001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 17/96] START C=0.0001, penalty=l1, solver=lbfgs........................\n",
      "[CV 3/5; 17/96] END C=0.0001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 17/96] START C=0.0001, penalty=l1, solver=lbfgs........................\n",
      "[CV 4/5; 17/96] END C=0.0001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 17/96] START C=0.0001, penalty=l1, solver=lbfgs........................\n",
      "[CV 5/5; 17/96] END C=0.0001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 18/96] START C=0.0001, penalty=l1, solver=liblinear....................\n",
      "No of FN: 78\n",
      "7300.529999999998\n",
      "[CV 1/5; 18/96] END C=0.0001, penalty=l1, solver=liblinear;, score=-7300.530 total time=   0.3s\n",
      "[CV 2/5; 18/96] START C=0.0001, penalty=l1, solver=liblinear....................\n",
      "No of FN: 78\n",
      "10858.949999999997\n",
      "[CV 2/5; 18/96] END C=0.0001, penalty=l1, solver=liblinear;, score=-10858.950 total time=   0.3s\n",
      "[CV 3/5; 18/96] START C=0.0001, penalty=l1, solver=liblinear....................\n",
      "No of FN: 78\n",
      "6768.910000000001\n",
      "[CV 3/5; 18/96] END C=0.0001, penalty=l1, solver=liblinear;, score=-6768.910 total time=   0.3s\n",
      "[CV 4/5; 18/96] START C=0.0001, penalty=l1, solver=liblinear....................\n",
      "No of FN: 78\n",
      "7686.04\n",
      "[CV 4/5; 18/96] END C=0.0001, penalty=l1, solver=liblinear;, score=-7686.040 total time=   0.3s\n",
      "[CV 5/5; 18/96] START C=0.0001, penalty=l1, solver=liblinear....................\n",
      "No of FN: 79\n",
      "16510.07\n",
      "[CV 5/5; 18/96] END C=0.0001, penalty=l1, solver=liblinear;, score=-16510.070 total time=   0.3s\n",
      "[CV 1/5; 19/96] START C=0.0001, penalty=l2, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 62\n",
      "6740.539999999998\n",
      "[CV 1/5; 19/96] END C=0.0001, penalty=l2, solver=newton-cg;, score=-6740.540 total time=  11.2s\n",
      "[CV 2/5; 19/96] START C=0.0001, penalty=l2, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 60\n",
      "9106.639999999998\n",
      "[CV 2/5; 19/96] END C=0.0001, penalty=l2, solver=newton-cg;, score=-9106.640 total time=   9.7s\n",
      "[CV 3/5; 19/96] START C=0.0001, penalty=l2, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 59\n",
      "5445.950000000002\n",
      "[CV 3/5; 19/96] END C=0.0001, penalty=l2, solver=newton-cg;, score=-5445.950 total time=  10.0s\n",
      "[CV 4/5; 19/96] START C=0.0001, penalty=l2, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 59\n",
      "5883.81\n",
      "[CV 4/5; 19/96] END C=0.0001, penalty=l2, solver=newton-cg;, score=-5883.810 total time=  10.3s\n",
      "[CV 5/5; 19/96] START C=0.0001, penalty=l2, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 65\n",
      "14114.800000000001\n",
      "[CV 5/5; 19/96] END C=0.0001, penalty=l2, solver=newton-cg;, score=-14114.800 total time=  10.1s\n",
      "[CV 1/5; 20/96] START C=0.0001, penalty=l2, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 50\n",
      "6786.809999999999\n",
      "[CV 1/5; 20/96] END C=0.0001, penalty=l2, solver=lbfgs;, score=-6786.810 total time=   1.4s\n",
      "[CV 2/5; 20/96] START C=0.0001, penalty=l2, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 51\n",
      "9051.939999999999\n",
      "[CV 2/5; 20/96] END C=0.0001, penalty=l2, solver=lbfgs;, score=-9051.940 total time=   1.3s\n",
      "[CV 3/5; 20/96] START C=0.0001, penalty=l2, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 51\n",
      "5236.500000000002\n",
      "[CV 3/5; 20/96] END C=0.0001, penalty=l2, solver=lbfgs;, score=-5236.500 total time=   1.2s\n",
      "[CV 4/5; 20/96] START C=0.0001, penalty=l2, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 50\n",
      "5861.309999999999\n",
      "[CV 4/5; 20/96] END C=0.0001, penalty=l2, solver=lbfgs;, score=-5861.310 total time=   1.4s\n",
      "[CV 5/5; 20/96] START C=0.0001, penalty=l2, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 66\n",
      "16170.74\n",
      "[CV 5/5; 20/96] END C=0.0001, penalty=l2, solver=lbfgs;, score=-16170.740 total time=   1.3s\n",
      "[CV 1/5; 21/96] START C=0.0001, penalty=l2, solver=liblinear....................\n",
      "No of FN: 59\n",
      "6955.289999999999\n",
      "[CV 1/5; 21/96] END C=0.0001, penalty=l2, solver=liblinear;, score=-6955.290 total time=   1.4s\n",
      "[CV 2/5; 21/96] START C=0.0001, penalty=l2, solver=liblinear....................\n",
      "No of FN: 59\n",
      "10469.819999999996\n",
      "[CV 2/5; 21/96] END C=0.0001, penalty=l2, solver=liblinear;, score=-10469.820 total time=   1.3s\n",
      "[CV 3/5; 21/96] START C=0.0001, penalty=l2, solver=liblinear....................\n",
      "No of FN: 55\n",
      "5468.560000000001\n",
      "[CV 3/5; 21/96] END C=0.0001, penalty=l2, solver=liblinear;, score=-5468.560 total time=   1.4s\n",
      "[CV 4/5; 21/96] START C=0.0001, penalty=l2, solver=liblinear....................\n",
      "No of FN: 57\n",
      "6999.28\n",
      "[CV 4/5; 21/96] END C=0.0001, penalty=l2, solver=liblinear;, score=-6999.280 total time=   1.2s\n",
      "[CV 5/5; 21/96] START C=0.0001, penalty=l2, solver=liblinear....................\n",
      "No of FN: 63\n",
      "15816.78\n",
      "[CV 5/5; 21/96] END C=0.0001, penalty=l2, solver=liblinear;, score=-15816.780 total time=   1.0s\n",
      "[CV 1/5; 22/96] START C=0.0001, penalty=elasticnet, solver=newton-cg............\n",
      "[CV 1/5; 22/96] END C=0.0001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 22/96] START C=0.0001, penalty=elasticnet, solver=newton-cg............\n",
      "[CV 2/5; 22/96] END C=0.0001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 22/96] START C=0.0001, penalty=elasticnet, solver=newton-cg............\n",
      "[CV 3/5; 22/96] END C=0.0001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 22/96] START C=0.0001, penalty=elasticnet, solver=newton-cg............\n",
      "[CV 4/5; 22/96] END C=0.0001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 22/96] START C=0.0001, penalty=elasticnet, solver=newton-cg............\n",
      "[CV 5/5; 22/96] END C=0.0001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 23/96] START C=0.0001, penalty=elasticnet, solver=lbfgs................\n",
      "[CV 1/5; 23/96] END C=0.0001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 23/96] START C=0.0001, penalty=elasticnet, solver=lbfgs................\n",
      "[CV 2/5; 23/96] END C=0.0001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 23/96] START C=0.0001, penalty=elasticnet, solver=lbfgs................\n",
      "[CV 3/5; 23/96] END C=0.0001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 23/96] START C=0.0001, penalty=elasticnet, solver=lbfgs................\n",
      "[CV 4/5; 23/96] END C=0.0001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 23/96] START C=0.0001, penalty=elasticnet, solver=lbfgs................\n",
      "[CV 5/5; 23/96] END C=0.0001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 24/96] START C=0.0001, penalty=elasticnet, solver=liblinear............\n",
      "[CV 1/5; 24/96] END C=0.0001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 24/96] START C=0.0001, penalty=elasticnet, solver=liblinear............\n",
      "[CV 2/5; 24/96] END C=0.0001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 24/96] START C=0.0001, penalty=elasticnet, solver=liblinear............\n",
      "[CV 3/5; 24/96] END C=0.0001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 24/96] START C=0.0001, penalty=elasticnet, solver=liblinear............\n",
      "[CV 4/5; 24/96] END C=0.0001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 24/96] START C=0.0001, penalty=elasticnet, solver=liblinear............\n",
      "[CV 5/5; 24/96] END C=0.0001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 25/96] START C=0.001, penalty=none, solver=newton-cg...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 25/96] END C=0.001, penalty=none, solver=newton-cg;, score=-5397.220 total time=   9.9s\n",
      "[CV 2/5; 25/96] START C=0.001, penalty=none, solver=newton-cg...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 25/96] END C=0.001, penalty=none, solver=newton-cg;, score=-7092.450 total time=   9.7s\n",
      "[CV 3/5; 25/96] START C=0.001, penalty=none, solver=newton-cg...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 25/96] END C=0.001, penalty=none, solver=newton-cg;, score=-3285.260 total time=   9.7s\n",
      "[CV 4/5; 25/96] START C=0.001, penalty=none, solver=newton-cg...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 25/96] END C=0.001, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.4s\n",
      "[CV 5/5; 25/96] START C=0.001, penalty=none, solver=newton-cg...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 25/96] END C=0.001, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.2s\n",
      "[CV 1/5; 26/96] START C=0.001, penalty=none, solver=lbfgs.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 26/96] END C=0.001, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.3s\n",
      "[CV 2/5; 26/96] START C=0.001, penalty=none, solver=lbfgs.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 26/96] END C=0.001, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.3s\n",
      "[CV 3/5; 26/96] START C=0.001, penalty=none, solver=lbfgs.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 26/96] END C=0.001, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.3s\n",
      "[CV 4/5; 26/96] START C=0.001, penalty=none, solver=lbfgs.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 26/96] END C=0.001, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.5s\n",
      "[CV 5/5; 26/96] START C=0.001, penalty=none, solver=lbfgs.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 26/96] END C=0.001, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.5s\n",
      "[CV 1/5; 27/96] START C=0.001, penalty=none, solver=liblinear...................\n",
      "[CV 1/5; 27/96] END C=0.001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 27/96] START C=0.001, penalty=none, solver=liblinear...................\n",
      "[CV 2/5; 27/96] END C=0.001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 27/96] START C=0.001, penalty=none, solver=liblinear...................\n",
      "[CV 3/5; 27/96] END C=0.001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 27/96] START C=0.001, penalty=none, solver=liblinear...................\n",
      "[CV 4/5; 27/96] END C=0.001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 27/96] START C=0.001, penalty=none, solver=liblinear...................\n",
      "[CV 5/5; 27/96] END C=0.001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 28/96] START C=0.001, penalty=l1, solver=newton-cg.....................\n",
      "[CV 1/5; 28/96] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 28/96] START C=0.001, penalty=l1, solver=newton-cg.....................\n",
      "[CV 2/5; 28/96] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 28/96] START C=0.001, penalty=l1, solver=newton-cg.....................\n",
      "[CV 3/5; 28/96] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 28/96] START C=0.001, penalty=l1, solver=newton-cg.....................\n",
      "[CV 4/5; 28/96] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 28/96] START C=0.001, penalty=l1, solver=newton-cg.....................\n",
      "[CV 5/5; 28/96] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 29/96] START C=0.001, penalty=l1, solver=lbfgs.........................\n",
      "[CV 1/5; 29/96] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 29/96] START C=0.001, penalty=l1, solver=lbfgs.........................\n",
      "[CV 2/5; 29/96] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 29/96] START C=0.001, penalty=l1, solver=lbfgs.........................\n",
      "[CV 3/5; 29/96] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 29/96] START C=0.001, penalty=l1, solver=lbfgs.........................\n",
      "[CV 4/5; 29/96] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 29/96] START C=0.001, penalty=l1, solver=lbfgs.........................\n",
      "[CV 5/5; 29/96] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 30/96] START C=0.001, penalty=l1, solver=liblinear.....................\n",
      "No of FN: 53\n",
      "6742.549999999998\n",
      "[CV 1/5; 30/96] END C=0.001, penalty=l1, solver=liblinear;, score=-6742.550 total time=   0.4s\n",
      "[CV 2/5; 30/96] START C=0.001, penalty=l1, solver=liblinear.....................\n",
      "No of FN: 54\n",
      "9240.529999999997\n",
      "[CV 2/5; 30/96] END C=0.001, penalty=l1, solver=liblinear;, score=-9240.530 total time=   0.4s\n",
      "[CV 3/5; 30/96] START C=0.001, penalty=l1, solver=liblinear.....................\n",
      "No of FN: 54\n",
      "5437.960000000002\n",
      "[CV 3/5; 30/96] END C=0.001, penalty=l1, solver=liblinear;, score=-5437.960 total time=   0.4s\n",
      "[CV 4/5; 30/96] START C=0.001, penalty=l1, solver=liblinear.....................\n",
      "No of FN: 56\n",
      "6475.940000000001\n",
      "[CV 4/5; 30/96] END C=0.001, penalty=l1, solver=liblinear;, score=-6475.940 total time=   0.4s\n",
      "[CV 5/5; 30/96] START C=0.001, penalty=l1, solver=liblinear.....................\n",
      "No of FN: 60\n",
      "15286.720000000001\n",
      "[CV 5/5; 30/96] END C=0.001, penalty=l1, solver=liblinear;, score=-15286.720 total time=   0.4s\n",
      "[CV 1/5; 31/96] START C=0.001, penalty=l2, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "5640.53\n",
      "[CV 1/5; 31/96] END C=0.001, penalty=l2, solver=newton-cg;, score=-5640.530 total time=   9.6s\n",
      "[CV 2/5; 31/96] START C=0.001, penalty=l2, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 42\n",
      "8865.479999999998\n",
      "[CV 2/5; 31/96] END C=0.001, penalty=l2, solver=newton-cg;, score=-8865.480 total time=   9.5s\n",
      "[CV 3/5; 31/96] START C=0.001, penalty=l2, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "3594.96\n",
      "[CV 3/5; 31/96] END C=0.001, penalty=l2, solver=newton-cg;, score=-3594.960 total time=   9.7s\n",
      "[CV 4/5; 31/96] START C=0.001, penalty=l2, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 35\n",
      "4315.65\n",
      "[CV 4/5; 31/96] END C=0.001, penalty=l2, solver=newton-cg;, score=-4315.650 total time=   9.8s\n",
      "[CV 5/5; 31/96] START C=0.001, penalty=l2, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 48\n",
      "12442.04\n",
      "[CV 5/5; 31/96] END C=0.001, penalty=l2, solver=newton-cg;, score=-12442.040 total time=  10.0s\n",
      "[CV 1/5; 32/96] START C=0.001, penalty=l2, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "6022.91\n",
      "[CV 1/5; 32/96] END C=0.001, penalty=l2, solver=lbfgs;, score=-6022.910 total time=   1.3s\n",
      "[CV 2/5; 32/96] START C=0.001, penalty=l2, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 37\n",
      "8284.869999999999\n",
      "[CV 2/5; 32/96] END C=0.001, penalty=l2, solver=lbfgs;, score=-8284.870 total time=   1.3s\n",
      "[CV 3/5; 32/96] START C=0.001, penalty=l2, solver=lbfgs.........................\n",
      "No of FN: 33\n",
      "4084.5899999999997\n",
      "[CV 3/5; 32/96] END C=0.001, penalty=l2, solver=lbfgs;, score=-4084.590 total time=   0.8s\n",
      "[CV 4/5; 32/96] START C=0.001, penalty=l2, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 43\n",
      "5098.929999999999\n",
      "[CV 4/5; 32/96] END C=0.001, penalty=l2, solver=lbfgs;, score=-5098.930 total time=   1.3s\n",
      "[CV 5/5; 32/96] START C=0.001, penalty=l2, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 47\n",
      "12479.910000000002\n",
      "[CV 5/5; 32/96] END C=0.001, penalty=l2, solver=lbfgs;, score=-12479.910 total time=   1.5s\n",
      "[CV 1/5; 33/96] START C=0.001, penalty=l2, solver=liblinear.....................\n",
      "No of FN: 34\n",
      "5987.46\n",
      "[CV 1/5; 33/96] END C=0.001, penalty=l2, solver=liblinear;, score=-5987.460 total time=   1.6s\n",
      "[CV 2/5; 33/96] START C=0.001, penalty=l2, solver=liblinear.....................\n",
      "No of FN: 42\n",
      "8796.289999999997\n",
      "[CV 2/5; 33/96] END C=0.001, penalty=l2, solver=liblinear;, score=-8796.290 total time=   1.6s\n",
      "[CV 3/5; 33/96] START C=0.001, penalty=l2, solver=liblinear.....................\n",
      "No of FN: 38\n",
      "4406.5\n",
      "[CV 3/5; 33/96] END C=0.001, penalty=l2, solver=liblinear;, score=-4406.500 total time=   1.5s\n",
      "[CV 4/5; 33/96] START C=0.001, penalty=l2, solver=liblinear.....................\n",
      "No of FN: 40\n",
      "4380.389999999999\n",
      "[CV 4/5; 33/96] END C=0.001, penalty=l2, solver=liblinear;, score=-4380.390 total time=   1.4s\n",
      "[CV 5/5; 33/96] START C=0.001, penalty=l2, solver=liblinear.....................\n",
      "No of FN: 48\n",
      "13658.800000000001\n",
      "[CV 5/5; 33/96] END C=0.001, penalty=l2, solver=liblinear;, score=-13658.800 total time=   1.3s\n",
      "[CV 1/5; 34/96] START C=0.001, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 1/5; 34/96] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 34/96] START C=0.001, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 2/5; 34/96] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 34/96] START C=0.001, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 3/5; 34/96] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 34/96] START C=0.001, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 4/5; 34/96] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 34/96] START C=0.001, penalty=elasticnet, solver=newton-cg.............\n",
      "[CV 5/5; 34/96] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 35/96] START C=0.001, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 1/5; 35/96] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 35/96] START C=0.001, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 2/5; 35/96] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 35/96] START C=0.001, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 3/5; 35/96] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 35/96] START C=0.001, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 4/5; 35/96] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 35/96] START C=0.001, penalty=elasticnet, solver=lbfgs.................\n",
      "[CV 5/5; 35/96] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 36/96] START C=0.001, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 1/5; 36/96] END C=0.001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 36/96] START C=0.001, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 2/5; 36/96] END C=0.001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 36/96] START C=0.001, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 3/5; 36/96] END C=0.001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 36/96] START C=0.001, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 4/5; 36/96] END C=0.001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 36/96] START C=0.001, penalty=elasticnet, solver=liblinear.............\n",
      "[CV 5/5; 36/96] END C=0.001, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 37/96] START C=0.01, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 37/96] END C=0.01, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.0s\n",
      "[CV 2/5; 37/96] START C=0.01, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 37/96] END C=0.01, penalty=none, solver=newton-cg;, score=-7092.450 total time=   9.7s\n",
      "[CV 3/5; 37/96] START C=0.01, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 37/96] END C=0.01, penalty=none, solver=newton-cg;, score=-3285.260 total time=   9.7s\n",
      "[CV 4/5; 37/96] START C=0.01, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 37/96] END C=0.01, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.4s\n",
      "[CV 5/5; 37/96] START C=0.01, penalty=none, solver=newton-cg....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 37/96] END C=0.01, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.2s\n",
      "[CV 1/5; 38/96] START C=0.01, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 38/96] END C=0.01, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.3s\n",
      "[CV 2/5; 38/96] START C=0.01, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 38/96] END C=0.01, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.3s\n",
      "[CV 3/5; 38/96] START C=0.01, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 38/96] END C=0.01, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.4s\n",
      "[CV 4/5; 38/96] START C=0.01, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 38/96] END C=0.01, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.5s\n",
      "[CV 5/5; 38/96] START C=0.01, penalty=none, solver=lbfgs........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 38/96] END C=0.01, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.5s\n",
      "[CV 1/5; 39/96] START C=0.01, penalty=none, solver=liblinear....................\n",
      "[CV 1/5; 39/96] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/96] START C=0.01, penalty=none, solver=liblinear....................\n",
      "[CV 2/5; 39/96] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/96] START C=0.01, penalty=none, solver=liblinear....................\n",
      "[CV 3/5; 39/96] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/96] START C=0.01, penalty=none, solver=liblinear....................\n",
      "[CV 4/5; 39/96] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/96] START C=0.01, penalty=none, solver=liblinear....................\n",
      "[CV 5/5; 39/96] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/96] START C=0.01, penalty=l1, solver=newton-cg......................\n",
      "[CV 1/5; 40/96] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 40/96] START C=0.01, penalty=l1, solver=newton-cg......................\n",
      "[CV 2/5; 40/96] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 40/96] START C=0.01, penalty=l1, solver=newton-cg......................\n",
      "[CV 3/5; 40/96] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 40/96] START C=0.01, penalty=l1, solver=newton-cg......................\n",
      "[CV 4/5; 40/96] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 40/96] START C=0.01, penalty=l1, solver=newton-cg......................\n",
      "[CV 5/5; 40/96] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 41/96] START C=0.01, penalty=l1, solver=lbfgs..........................\n",
      "[CV 1/5; 41/96] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 41/96] START C=0.01, penalty=l1, solver=lbfgs..........................\n",
      "[CV 2/5; 41/96] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 41/96] START C=0.01, penalty=l1, solver=lbfgs..........................\n",
      "[CV 3/5; 41/96] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 41/96] START C=0.01, penalty=l1, solver=lbfgs..........................\n",
      "[CV 4/5; 41/96] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 41/96] START C=0.01, penalty=l1, solver=lbfgs..........................\n",
      "[CV 5/5; 41/96] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 42/96] START C=0.01, penalty=l1, solver=liblinear......................\n",
      "No of FN: 35\n",
      "5413.009999999999\n",
      "[CV 1/5; 42/96] END C=0.01, penalty=l1, solver=liblinear;, score=-5413.010 total time=   0.4s\n",
      "[CV 2/5; 42/96] START C=0.01, penalty=l1, solver=liblinear......................\n",
      "No of FN: 40\n",
      "8806.899999999998\n",
      "[CV 2/5; 42/96] END C=0.01, penalty=l1, solver=liblinear;, score=-8806.900 total time=   0.4s\n",
      "[CV 3/5; 42/96] START C=0.01, penalty=l1, solver=liblinear......................\n",
      "No of FN: 30\n",
      "3376.9800000000005\n",
      "[CV 3/5; 42/96] END C=0.01, penalty=l1, solver=liblinear;, score=-3376.980 total time=   0.5s\n",
      "[CV 4/5; 42/96] START C=0.01, penalty=l1, solver=liblinear......................\n",
      "No of FN: 33\n",
      "4145.98\n",
      "[CV 4/5; 42/96] END C=0.01, penalty=l1, solver=liblinear;, score=-4145.980 total time=   0.5s\n",
      "[CV 5/5; 42/96] START C=0.01, penalty=l1, solver=liblinear......................\n",
      "No of FN: 46\n",
      "11996.310000000001\n",
      "[CV 5/5; 42/96] END C=0.01, penalty=l1, solver=liblinear;, score=-11996.310 total time=   0.7s\n",
      "[CV 1/5; 43/96] START C=0.01, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 32\n",
      "5302.23\n",
      "[CV 1/5; 43/96] END C=0.01, penalty=l2, solver=newton-cg;, score=-5302.230 total time=  10.7s\n",
      "[CV 2/5; 43/96] START C=0.01, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 31\n",
      "7107.75\n",
      "[CV 2/5; 43/96] END C=0.01, penalty=l2, solver=newton-cg;, score=-7107.750 total time=   9.4s\n",
      "[CV 3/5; 43/96] START C=0.01, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3376.2799999999997\n",
      "[CV 3/5; 43/96] END C=0.01, penalty=l2, solver=newton-cg;, score=-3376.280 total time=   9.4s\n",
      "[CV 4/5; 43/96] START C=0.01, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 31\n",
      "4309.509999999999\n",
      "[CV 4/5; 43/96] END C=0.01, penalty=l2, solver=newton-cg;, score=-4309.510 total time=   9.4s\n",
      "[CV 5/5; 43/96] START C=0.01, penalty=l2, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "10698.690000000002\n",
      "[CV 5/5; 43/96] END C=0.01, penalty=l2, solver=newton-cg;, score=-10698.690 total time=  10.2s\n",
      "[CV 1/5; 44/96] START C=0.01, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4865.98\n",
      "[CV 1/5; 44/96] END C=0.01, penalty=l2, solver=lbfgs;, score=-4865.980 total time=   1.2s\n",
      "[CV 2/5; 44/96] START C=0.01, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7381.18\n",
      "[CV 2/5; 44/96] END C=0.01, penalty=l2, solver=lbfgs;, score=-7381.180 total time=   1.4s\n",
      "[CV 3/5; 44/96] START C=0.01, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4423.63\n",
      "[CV 3/5; 44/96] END C=0.01, penalty=l2, solver=lbfgs;, score=-4423.630 total time=   1.4s\n",
      "[CV 4/5; 44/96] START C=0.01, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4200.959999999999\n",
      "[CV 4/5; 44/96] END C=0.01, penalty=l2, solver=lbfgs;, score=-4200.960 total time=   1.5s\n",
      "[CV 5/5; 44/96] START C=0.01, penalty=l2, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 40\n",
      "11201.570000000002\n",
      "[CV 5/5; 44/96] END C=0.01, penalty=l2, solver=lbfgs;, score=-11201.570 total time=   1.5s\n",
      "[CV 1/5; 45/96] START C=0.01, penalty=l2, solver=liblinear......................\n",
      "No of FN: 25\n",
      "4968.799999999999\n",
      "[CV 1/5; 45/96] END C=0.01, penalty=l2, solver=liblinear;, score=-4968.800 total time=   1.5s\n",
      "[CV 2/5; 45/96] START C=0.01, penalty=l2, solver=liblinear......................\n",
      "No of FN: 37\n",
      "8483.41\n",
      "[CV 2/5; 45/96] END C=0.01, penalty=l2, solver=liblinear;, score=-8483.410 total time=   1.7s\n",
      "[CV 3/5; 45/96] START C=0.01, penalty=l2, solver=liblinear......................\n",
      "No of FN: 29\n",
      "4197.610000000001\n",
      "[CV 3/5; 45/96] END C=0.01, penalty=l2, solver=liblinear;, score=-4197.610 total time=   1.9s\n",
      "[CV 4/5; 45/96] START C=0.01, penalty=l2, solver=liblinear......................\n",
      "No of FN: 35\n",
      "4350.579999999999\n",
      "[CV 4/5; 45/96] END C=0.01, penalty=l2, solver=liblinear;, score=-4350.580 total time=   1.8s\n",
      "[CV 5/5; 45/96] START C=0.01, penalty=l2, solver=liblinear......................\n",
      "No of FN: 41\n",
      "11221.560000000001\n",
      "[CV 5/5; 45/96] END C=0.01, penalty=l2, solver=liblinear;, score=-11221.560 total time=   1.7s\n",
      "[CV 1/5; 46/96] START C=0.01, penalty=elasticnet, solver=newton-cg..............\n",
      "[CV 1/5; 46/96] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 46/96] START C=0.01, penalty=elasticnet, solver=newton-cg..............\n",
      "[CV 2/5; 46/96] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 46/96] START C=0.01, penalty=elasticnet, solver=newton-cg..............\n",
      "[CV 3/5; 46/96] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 46/96] START C=0.01, penalty=elasticnet, solver=newton-cg..............\n",
      "[CV 4/5; 46/96] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 46/96] START C=0.01, penalty=elasticnet, solver=newton-cg..............\n",
      "[CV 5/5; 46/96] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 47/96] START C=0.01, penalty=elasticnet, solver=lbfgs..................\n",
      "[CV 1/5; 47/96] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 47/96] START C=0.01, penalty=elasticnet, solver=lbfgs..................\n",
      "[CV 2/5; 47/96] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 47/96] START C=0.01, penalty=elasticnet, solver=lbfgs..................\n",
      "[CV 3/5; 47/96] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 47/96] START C=0.01, penalty=elasticnet, solver=lbfgs..................\n",
      "[CV 4/5; 47/96] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 47/96] START C=0.01, penalty=elasticnet, solver=lbfgs..................\n",
      "[CV 5/5; 47/96] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 48/96] START C=0.01, penalty=elasticnet, solver=liblinear..............\n",
      "[CV 1/5; 48/96] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 48/96] START C=0.01, penalty=elasticnet, solver=liblinear..............\n",
      "[CV 2/5; 48/96] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 48/96] START C=0.01, penalty=elasticnet, solver=liblinear..............\n",
      "[CV 3/5; 48/96] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 48/96] START C=0.01, penalty=elasticnet, solver=liblinear..............\n",
      "[CV 4/5; 48/96] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 48/96] START C=0.01, penalty=elasticnet, solver=liblinear..............\n",
      "[CV 5/5; 48/96] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 49/96] START C=0.1, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 49/96] END C=0.1, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.0s\n",
      "[CV 2/5; 49/96] START C=0.1, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 49/96] END C=0.1, penalty=none, solver=newton-cg;, score=-7092.450 total time=  10.0s\n",
      "[CV 3/5; 49/96] START C=0.1, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 49/96] END C=0.1, penalty=none, solver=newton-cg;, score=-3285.260 total time=  10.0s\n",
      "[CV 4/5; 49/96] START C=0.1, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 49/96] END C=0.1, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.3s\n",
      "[CV 5/5; 49/96] START C=0.1, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 49/96] END C=0.1, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.1s\n",
      "[CV 1/5; 50/96] START C=0.1, penalty=none, solver=lbfgs.........................\n",
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 50/96] END C=0.1, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.5s\n",
      "[CV 2/5; 50/96] START C=0.1, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 50/96] END C=0.1, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.4s\n",
      "[CV 3/5; 50/96] START C=0.1, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 50/96] END C=0.1, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.3s\n",
      "[CV 4/5; 50/96] START C=0.1, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 50/96] END C=0.1, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.4s\n",
      "[CV 5/5; 50/96] START C=0.1, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 50/96] END C=0.1, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.4s\n",
      "[CV 1/5; 51/96] START C=0.1, penalty=none, solver=liblinear.....................\n",
      "[CV 1/5; 51/96] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 51/96] START C=0.1, penalty=none, solver=liblinear.....................\n",
      "[CV 2/5; 51/96] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 51/96] START C=0.1, penalty=none, solver=liblinear.....................\n",
      "[CV 3/5; 51/96] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 51/96] START C=0.1, penalty=none, solver=liblinear.....................\n",
      "[CV 4/5; 51/96] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 51/96] START C=0.1, penalty=none, solver=liblinear.....................\n",
      "[CV 5/5; 51/96] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 52/96] START C=0.1, penalty=l1, solver=newton-cg.......................\n",
      "[CV 1/5; 52/96] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 52/96] START C=0.1, penalty=l1, solver=newton-cg.......................\n",
      "[CV 2/5; 52/96] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 52/96] START C=0.1, penalty=l1, solver=newton-cg.......................\n",
      "[CV 3/5; 52/96] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 52/96] START C=0.1, penalty=l1, solver=newton-cg.......................\n",
      "[CV 4/5; 52/96] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 52/96] START C=0.1, penalty=l1, solver=newton-cg.......................\n",
      "[CV 5/5; 52/96] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 53/96] START C=0.1, penalty=l1, solver=lbfgs...........................\n",
      "[CV 1/5; 53/96] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 53/96] START C=0.1, penalty=l1, solver=lbfgs...........................\n",
      "[CV 2/5; 53/96] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 53/96] START C=0.1, penalty=l1, solver=lbfgs...........................\n",
      "[CV 3/5; 53/96] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 53/96] START C=0.1, penalty=l1, solver=lbfgs...........................\n",
      "[CV 4/5; 53/96] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 53/96] START C=0.1, penalty=l1, solver=lbfgs...........................\n",
      "[CV 5/5; 53/96] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 54/96] START C=0.1, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 33\n",
      "5298.23\n",
      "[CV 1/5; 54/96] END C=0.1, penalty=l1, solver=liblinear;, score=-5298.230 total time=   1.4s\n",
      "[CV 2/5; 54/96] START C=0.1, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 31\n",
      "7107.75\n",
      "[CV 2/5; 54/96] END C=0.1, penalty=l1, solver=liblinear;, score=-7107.750 total time=   1.5s\n",
      "[CV 3/5; 54/96] START C=0.1, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 26\n",
      "2753.49\n",
      "[CV 3/5; 54/96] END C=0.1, penalty=l1, solver=liblinear;, score=-2753.490 total time=   1.8s\n",
      "[CV 4/5; 54/96] START C=0.1, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 32\n",
      "4305.269999999999\n",
      "[CV 4/5; 54/96] END C=0.1, penalty=l1, solver=liblinear;, score=-4305.270 total time=   1.0s\n",
      "[CV 5/5; 54/96] START C=0.1, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 38\n",
      "10259.520000000002\n",
      "[CV 5/5; 54/96] END C=0.1, penalty=l1, solver=liblinear;, score=-10259.520 total time=   1.2s\n",
      "[CV 1/5; 55/96] START C=0.1, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 55/96] END C=0.1, penalty=l2, solver=newton-cg;, score=-5397.220 total time=  10.4s\n",
      "[CV 2/5; 55/96] START C=0.1, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7097.449999999999\n",
      "[CV 2/5; 55/96] END C=0.1, penalty=l2, solver=newton-cg;, score=-7097.450 total time=   9.4s\n",
      "[CV 3/5; 55/96] START C=0.1, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 55/96] END C=0.1, penalty=l2, solver=newton-cg;, score=-3285.260 total time=   9.4s\n",
      "[CV 4/5; 55/96] START C=0.1, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 31\n",
      "4308.269999999999\n",
      "[CV 4/5; 55/96] END C=0.1, penalty=l2, solver=newton-cg;, score=-4308.270 total time=   9.9s\n",
      "[CV 5/5; 55/96] START C=0.1, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 37\n",
      "10245.560000000001\n",
      "[CV 5/5; 55/96] END C=0.1, penalty=l2, solver=newton-cg;, score=-10245.560 total time=   9.6s\n",
      "[CV 1/5; 56/96] START C=0.1, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 56/96] END C=0.1, penalty=l2, solver=lbfgs;, score=-5005.970 total time=   1.3s\n",
      "[CV 2/5; 56/96] START C=0.1, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "7206.81\n",
      "[CV 2/5; 56/96] END C=0.1, penalty=l2, solver=lbfgs;, score=-7206.810 total time=   1.3s\n",
      "[CV 3/5; 56/96] START C=0.1, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 23\n",
      "4030.0099999999993\n",
      "[CV 3/5; 56/96] END C=0.1, penalty=l2, solver=lbfgs;, score=-4030.010 total time=   1.3s\n",
      "[CV 4/5; 56/96] START C=0.1, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "3910.9599999999996\n",
      "[CV 4/5; 56/96] END C=0.1, penalty=l2, solver=lbfgs;, score=-3910.960 total time=   1.5s\n",
      "[CV 5/5; 56/96] START C=0.1, penalty=l2, solver=lbfgs...........................\n",
      "No of FN: 34\n",
      "10247.230000000001\n",
      "[CV 5/5; 56/96] END C=0.1, penalty=l2, solver=lbfgs;, score=-10247.230 total time=   1.2s\n",
      "[CV 1/5; 57/96] START C=0.1, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 31\n",
      "5555.88\n",
      "[CV 1/5; 57/96] END C=0.1, penalty=l2, solver=liblinear;, score=-5555.880 total time=   1.8s\n",
      "[CV 2/5; 57/96] START C=0.1, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 32\n",
      "7059.46\n",
      "[CV 2/5; 57/96] END C=0.1, penalty=l2, solver=liblinear;, score=-7059.460 total time=   1.9s\n",
      "[CV 3/5; 57/96] START C=0.1, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 24\n",
      "4088.66\n",
      "[CV 3/5; 57/96] END C=0.1, penalty=l2, solver=liblinear;, score=-4088.660 total time=   2.1s\n",
      "[CV 4/5; 57/96] START C=0.1, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 35\n",
      "4350.579999999999\n",
      "[CV 4/5; 57/96] END C=0.1, penalty=l2, solver=liblinear;, score=-4350.580 total time=   1.6s\n",
      "[CV 5/5; 57/96] START C=0.1, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 40\n",
      "11141.570000000002\n",
      "[CV 5/5; 57/96] END C=0.1, penalty=l2, solver=liblinear;, score=-11141.570 total time=   1.5s\n",
      "[CV 1/5; 58/96] START C=0.1, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 1/5; 58/96] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 58/96] START C=0.1, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 2/5; 58/96] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 58/96] START C=0.1, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 3/5; 58/96] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 58/96] START C=0.1, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 4/5; 58/96] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 58/96] START C=0.1, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 5/5; 58/96] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 59/96] START C=0.1, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 1/5; 59/96] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 59/96] START C=0.1, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 2/5; 59/96] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 59/96] START C=0.1, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 3/5; 59/96] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 59/96] START C=0.1, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 4/5; 59/96] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 59/96] START C=0.1, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 5/5; 59/96] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 60/96] START C=0.1, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 1/5; 60/96] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 60/96] START C=0.1, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 2/5; 60/96] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 60/96] START C=0.1, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 3/5; 60/96] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 60/96] START C=0.1, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 4/5; 60/96] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 60/96] START C=0.1, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 5/5; 60/96] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 61/96] START C=1, penalty=none, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 61/96] END C=1, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.0s\n",
      "[CV 2/5; 61/96] START C=1, penalty=none, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 61/96] END C=1, penalty=none, solver=newton-cg;, score=-7092.450 total time=   9.7s\n",
      "[CV 3/5; 61/96] START C=1, penalty=none, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 61/96] END C=1, penalty=none, solver=newton-cg;, score=-3285.260 total time=   9.7s\n",
      "[CV 4/5; 61/96] START C=1, penalty=none, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 61/96] END C=1, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.3s\n",
      "[CV 5/5; 61/96] START C=1, penalty=none, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 61/96] END C=1, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.1s\n",
      "[CV 1/5; 62/96] START C=1, penalty=none, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 62/96] END C=1, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.5s\n",
      "[CV 2/5; 62/96] START C=1, penalty=none, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 62/96] END C=1, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.4s\n",
      "[CV 3/5; 62/96] START C=1, penalty=none, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 62/96] END C=1, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.3s\n",
      "[CV 4/5; 62/96] START C=1, penalty=none, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 62/96] END C=1, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.4s\n",
      "[CV 5/5; 62/96] START C=1, penalty=none, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 62/96] END C=1, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.4s\n",
      "[CV 1/5; 63/96] START C=1, penalty=none, solver=liblinear.......................\n",
      "[CV 1/5; 63/96] END C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 63/96] START C=1, penalty=none, solver=liblinear.......................\n",
      "[CV 2/5; 63/96] END C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 63/96] START C=1, penalty=none, solver=liblinear.......................\n",
      "[CV 3/5; 63/96] END C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 63/96] START C=1, penalty=none, solver=liblinear.......................\n",
      "[CV 4/5; 63/96] END C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 63/96] START C=1, penalty=none, solver=liblinear.......................\n",
      "[CV 5/5; 63/96] END C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 64/96] START C=1, penalty=l1, solver=newton-cg.........................\n",
      "[CV 1/5; 64/96] END C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 64/96] START C=1, penalty=l1, solver=newton-cg.........................\n",
      "[CV 2/5; 64/96] END C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 64/96] START C=1, penalty=l1, solver=newton-cg.........................\n",
      "[CV 3/5; 64/96] END C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 64/96] START C=1, penalty=l1, solver=newton-cg.........................\n",
      "[CV 4/5; 64/96] END C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 64/96] START C=1, penalty=l1, solver=newton-cg.........................\n",
      "[CV 5/5; 64/96] END C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 65/96] START C=1, penalty=l1, solver=lbfgs.............................\n",
      "[CV 1/5; 65/96] END C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 65/96] START C=1, penalty=l1, solver=lbfgs.............................\n",
      "[CV 2/5; 65/96] END C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 65/96] START C=1, penalty=l1, solver=lbfgs.............................\n",
      "[CV 3/5; 65/96] END C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 65/96] START C=1, penalty=l1, solver=lbfgs.............................\n",
      "[CV 4/5; 65/96] END C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 65/96] START C=1, penalty=l1, solver=lbfgs.............................\n",
      "[CV 5/5; 65/96] END C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 66/96] START C=1, penalty=l1, solver=liblinear.........................\n",
      "No of FN: 35\n",
      "5389.969999999999\n",
      "[CV 1/5; 66/96] END C=1, penalty=l1, solver=liblinear;, score=-5389.970 total time=   2.6s\n",
      "[CV 2/5; 66/96] START C=1, penalty=l1, solver=liblinear.........................\n",
      "No of FN: 31\n",
      "7112.75\n",
      "[CV 2/5; 66/96] END C=1, penalty=l1, solver=liblinear;, score=-7112.750 total time=   1.8s\n",
      "[CV 3/5; 66/96] START C=1, penalty=l1, solver=liblinear.........................\n",
      "No of FN: 24\n",
      "2624.96\n",
      "[CV 3/5; 66/96] END C=1, penalty=l1, solver=liblinear;, score=-2624.960 total time=   2.1s\n",
      "[CV 4/5; 66/96] START C=1, penalty=l1, solver=liblinear.........................\n",
      "No of FN: 28\n",
      "3727.609999999999\n",
      "[CV 4/5; 66/96] END C=1, penalty=l1, solver=liblinear;, score=-3727.610 total time=   1.8s\n",
      "[CV 5/5; 66/96] START C=1, penalty=l1, solver=liblinear.........................\n",
      "No of FN: 36\n",
      "8788.130000000001\n",
      "[CV 5/5; 66/96] END C=1, penalty=l1, solver=liblinear;, score=-8788.130 total time=   2.1s\n",
      "[CV 1/5; 67/96] START C=1, penalty=l2, solver=newton-cg.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 67/96] END C=1, penalty=l2, solver=newton-cg;, score=-5397.220 total time=   9.8s\n",
      "[CV 2/5; 67/96] START C=1, penalty=l2, solver=newton-cg.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 67/96] END C=1, penalty=l2, solver=newton-cg;, score=-7092.450 total time=   9.4s\n",
      "[CV 3/5; 67/96] START C=1, penalty=l2, solver=newton-cg.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 67/96] END C=1, penalty=l2, solver=newton-cg;, score=-3285.260 total time=   9.4s\n",
      "[CV 4/5; 67/96] START C=1, penalty=l2, solver=newton-cg.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 31\n",
      "4308.269999999999\n",
      "[CV 4/5; 67/96] END C=1, penalty=l2, solver=newton-cg;, score=-4308.270 total time=   9.7s\n",
      "[CV 5/5; 67/96] START C=1, penalty=l2, solver=newton-cg.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10249.79\n",
      "[CV 5/5; 67/96] END C=1, penalty=l2, solver=newton-cg;, score=-10249.790 total time=   9.6s\n",
      "[CV 1/5; 68/96] START C=1, penalty=l2, solver=lbfgs.............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5010.969999999999\n",
      "[CV 1/5; 68/96] END C=1, penalty=l2, solver=lbfgs;, score=-5010.970 total time=   1.3s\n",
      "[CV 2/5; 68/96] START C=1, penalty=l2, solver=lbfgs.............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "7201.780000000001\n",
      "[CV 2/5; 68/96] END C=1, penalty=l2, solver=lbfgs;, score=-7201.780 total time=   1.5s\n",
      "[CV 3/5; 68/96] START C=1, penalty=l2, solver=lbfgs.............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 22\n",
      "3013.9900000000002\n",
      "[CV 3/5; 68/96] END C=1, penalty=l2, solver=lbfgs;, score=-3013.990 total time=   1.3s\n",
      "[CV 4/5; 68/96] START C=1, penalty=l2, solver=lbfgs.............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "3885.45\n",
      "[CV 4/5; 68/96] END C=1, penalty=l2, solver=lbfgs;, score=-3885.450 total time=   1.5s\n",
      "[CV 5/5; 68/96] START C=1, penalty=l2, solver=lbfgs.............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 68/96] END C=1, penalty=l2, solver=lbfgs;, score=-11250.080 total time=   1.5s\n",
      "[CV 1/5; 69/96] START C=1, penalty=l2, solver=liblinear.........................\n",
      "No of FN: 30\n",
      "5560.88\n",
      "[CV 1/5; 69/96] END C=1, penalty=l2, solver=liblinear;, score=-5560.880 total time=   1.7s\n",
      "[CV 2/5; 69/96] START C=1, penalty=l2, solver=liblinear.........................\n",
      "No of FN: 32\n",
      "7059.46\n",
      "[CV 2/5; 69/96] END C=1, penalty=l2, solver=liblinear;, score=-7059.460 total time=   1.9s\n",
      "[CV 3/5; 69/96] START C=1, penalty=l2, solver=liblinear.........................\n",
      "No of FN: 28\n",
      "3469.4000000000005\n",
      "[CV 3/5; 69/96] END C=1, penalty=l2, solver=liblinear;, score=-3469.400 total time=   2.5s\n",
      "[CV 4/5; 69/96] START C=1, penalty=l2, solver=liblinear.........................\n",
      "No of FN: 35\n",
      "4350.579999999999\n",
      "[CV 4/5; 69/96] END C=1, penalty=l2, solver=liblinear;, score=-4350.580 total time=   1.7s\n",
      "[CV 5/5; 69/96] START C=1, penalty=l2, solver=liblinear.........................\n",
      "No of FN: 40\n",
      "11141.570000000002\n",
      "[CV 5/5; 69/96] END C=1, penalty=l2, solver=liblinear;, score=-11141.570 total time=   1.5s\n",
      "[CV 1/5; 70/96] START C=1, penalty=elasticnet, solver=newton-cg.................\n",
      "[CV 1/5; 70/96] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 70/96] START C=1, penalty=elasticnet, solver=newton-cg.................\n",
      "[CV 2/5; 70/96] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 70/96] START C=1, penalty=elasticnet, solver=newton-cg.................\n",
      "[CV 3/5; 70/96] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 70/96] START C=1, penalty=elasticnet, solver=newton-cg.................\n",
      "[CV 4/5; 70/96] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 70/96] START C=1, penalty=elasticnet, solver=newton-cg.................\n",
      "[CV 5/5; 70/96] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 71/96] START C=1, penalty=elasticnet, solver=lbfgs.....................\n",
      "[CV 1/5; 71/96] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 71/96] START C=1, penalty=elasticnet, solver=lbfgs.....................\n",
      "[CV 2/5; 71/96] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 71/96] START C=1, penalty=elasticnet, solver=lbfgs.....................\n",
      "[CV 3/5; 71/96] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 71/96] START C=1, penalty=elasticnet, solver=lbfgs.....................\n",
      "[CV 4/5; 71/96] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 71/96] START C=1, penalty=elasticnet, solver=lbfgs.....................\n",
      "[CV 5/5; 71/96] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 72/96] START C=1, penalty=elasticnet, solver=liblinear.................\n",
      "[CV 1/5; 72/96] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 72/96] START C=1, penalty=elasticnet, solver=liblinear.................\n",
      "[CV 2/5; 72/96] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 72/96] START C=1, penalty=elasticnet, solver=liblinear.................\n",
      "[CV 3/5; 72/96] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 72/96] START C=1, penalty=elasticnet, solver=liblinear.................\n",
      "[CV 4/5; 72/96] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 72/96] START C=1, penalty=elasticnet, solver=liblinear.................\n",
      "[CV 5/5; 72/96] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 73/96] START C=10, penalty=none, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 73/96] END C=10, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.1s\n",
      "[CV 2/5; 73/96] START C=10, penalty=none, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 73/96] END C=10, penalty=none, solver=newton-cg;, score=-7092.450 total time=   9.8s\n",
      "[CV 3/5; 73/96] START C=10, penalty=none, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 73/96] END C=10, penalty=none, solver=newton-cg;, score=-3285.260 total time=   9.7s\n",
      "[CV 4/5; 73/96] START C=10, penalty=none, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 73/96] END C=10, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.4s\n",
      "[CV 5/5; 73/96] START C=10, penalty=none, solver=newton-cg......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 73/96] END C=10, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.3s\n",
      "[CV 1/5; 74/96] START C=10, penalty=none, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 74/96] END C=10, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.5s\n",
      "[CV 2/5; 74/96] START C=10, penalty=none, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 74/96] END C=10, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.3s\n",
      "[CV 3/5; 74/96] START C=10, penalty=none, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 74/96] END C=10, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.3s\n",
      "[CV 4/5; 74/96] START C=10, penalty=none, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 74/96] END C=10, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.4s\n",
      "[CV 5/5; 74/96] START C=10, penalty=none, solver=lbfgs..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 74/96] END C=10, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.4s\n",
      "[CV 1/5; 75/96] START C=10, penalty=none, solver=liblinear......................\n",
      "[CV 1/5; 75/96] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 75/96] START C=10, penalty=none, solver=liblinear......................\n",
      "[CV 2/5; 75/96] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 75/96] START C=10, penalty=none, solver=liblinear......................\n",
      "[CV 3/5; 75/96] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 75/96] START C=10, penalty=none, solver=liblinear......................\n",
      "[CV 4/5; 75/96] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 75/96] START C=10, penalty=none, solver=liblinear......................\n",
      "[CV 5/5; 75/96] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 76/96] START C=10, penalty=l1, solver=newton-cg........................\n",
      "[CV 1/5; 76/96] END C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 76/96] START C=10, penalty=l1, solver=newton-cg........................\n",
      "[CV 2/5; 76/96] END C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 76/96] START C=10, penalty=l1, solver=newton-cg........................\n",
      "[CV 3/5; 76/96] END C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 76/96] START C=10, penalty=l1, solver=newton-cg........................\n",
      "[CV 4/5; 76/96] END C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 76/96] START C=10, penalty=l1, solver=newton-cg........................\n",
      "[CV 5/5; 76/96] END C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 77/96] START C=10, penalty=l1, solver=lbfgs............................\n",
      "[CV 1/5; 77/96] END C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 77/96] START C=10, penalty=l1, solver=lbfgs............................\n",
      "[CV 2/5; 77/96] END C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 77/96] START C=10, penalty=l1, solver=lbfgs............................\n",
      "[CV 3/5; 77/96] END C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 77/96] START C=10, penalty=l1, solver=lbfgs............................\n",
      "[CV 4/5; 77/96] END C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 77/96] START C=10, penalty=l1, solver=lbfgs............................\n",
      "[CV 5/5; 77/96] END C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 78/96] START C=10, penalty=l1, solver=liblinear........................\n",
      "No of FN: 35\n",
      "5389.969999999999\n",
      "[CV 1/5; 78/96] END C=10, penalty=l1, solver=liblinear;, score=-5389.970 total time=   2.4s\n",
      "[CV 2/5; 78/96] START C=10, penalty=l1, solver=liblinear........................\n",
      "No of FN: 31\n",
      "7107.75\n",
      "[CV 2/5; 78/96] END C=10, penalty=l1, solver=liblinear;, score=-7107.750 total time=   2.3s\n",
      "[CV 3/5; 78/96] START C=10, penalty=l1, solver=liblinear........................\n",
      "No of FN: 23\n",
      "2629.96\n",
      "[CV 3/5; 78/96] END C=10, penalty=l1, solver=liblinear;, score=-2629.960 total time=   2.2s\n",
      "[CV 4/5; 78/96] START C=10, penalty=l1, solver=liblinear........................\n",
      "No of FN: 27\n",
      "3587.8099999999995\n",
      "[CV 4/5; 78/96] END C=10, penalty=l1, solver=liblinear;, score=-3587.810 total time=   2.2s\n",
      "[CV 5/5; 78/96] START C=10, penalty=l1, solver=liblinear........................\n",
      "No of FN: 35\n",
      "7293.200000000001\n",
      "[CV 5/5; 78/96] END C=10, penalty=l1, solver=liblinear;, score=-7293.200 total time=   2.9s\n",
      "[CV 1/5; 79/96] START C=10, penalty=l2, solver=newton-cg........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 79/96] END C=10, penalty=l2, solver=newton-cg;, score=-5397.220 total time=   9.7s\n",
      "[CV 2/5; 79/96] START C=10, penalty=l2, solver=newton-cg........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 31\n",
      "7117.75\n",
      "[CV 2/5; 79/96] END C=10, penalty=l2, solver=newton-cg;, score=-7117.750 total time=  10.1s\n",
      "[CV 3/5; 79/96] START C=10, penalty=l2, solver=newton-cg........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "3289.26\n",
      "[CV 3/5; 79/96] END C=10, penalty=l2, solver=newton-cg;, score=-3289.260 total time=   9.7s\n",
      "[CV 4/5; 79/96] START C=10, penalty=l2, solver=newton-cg........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "4168.469999999999\n",
      "[CV 4/5; 79/96] END C=10, penalty=l2, solver=newton-cg;, score=-4168.470 total time=   9.3s\n",
      "[CV 5/5; 79/96] START C=10, penalty=l2, solver=newton-cg........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10249.79\n",
      "[CV 5/5; 79/96] END C=10, penalty=l2, solver=newton-cg;, score=-10249.790 total time=   9.8s\n",
      "[CV 1/5; 80/96] START C=10, penalty=l2, solver=lbfgs............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 18\n",
      "3051.2999999999993\n",
      "[CV 1/5; 80/96] END C=10, penalty=l2, solver=lbfgs;, score=-3051.300 total time=   1.5s\n",
      "[CV 2/5; 80/96] START C=10, penalty=l2, solver=lbfgs............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 24\n",
      "5227.4000000000015\n",
      "[CV 2/5; 80/96] END C=10, penalty=l2, solver=lbfgs;, score=-5227.400 total time=   1.5s\n",
      "[CV 3/5; 80/96] START C=10, penalty=l2, solver=lbfgs............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 23\n",
      "3317.5599999999995\n",
      "[CV 3/5; 80/96] END C=10, penalty=l2, solver=lbfgs;, score=-3317.560 total time=   1.2s\n",
      "[CV 4/5; 80/96] START C=10, penalty=l2, solver=lbfgs............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 80/96] END C=10, penalty=l2, solver=lbfgs;, score=-3790.460 total time=   1.3s\n",
      "[CV 5/5; 80/96] START C=10, penalty=l2, solver=lbfgs............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 38\n",
      "10459.230000000001\n",
      "[CV 5/5; 80/96] END C=10, penalty=l2, solver=lbfgs;, score=-10459.230 total time=   1.3s\n",
      "[CV 1/5; 81/96] START C=10, penalty=l2, solver=liblinear........................\n",
      "No of FN: 30\n",
      "5560.88\n",
      "[CV 1/5; 81/96] END C=10, penalty=l2, solver=liblinear;, score=-5560.880 total time=   1.9s\n",
      "[CV 2/5; 81/96] START C=10, penalty=l2, solver=liblinear........................\n",
      "No of FN: 32\n",
      "7059.46\n",
      "[CV 2/5; 81/96] END C=10, penalty=l2, solver=liblinear;, score=-7059.460 total time=   2.2s\n",
      "[CV 3/5; 81/96] START C=10, penalty=l2, solver=liblinear........................\n",
      "No of FN: 31\n",
      "4565.78\n",
      "[CV 3/5; 81/96] END C=10, penalty=l2, solver=liblinear;, score=-4565.780 total time=   2.2s\n",
      "[CV 4/5; 81/96] START C=10, penalty=l2, solver=liblinear........................\n",
      "No of FN: 35\n",
      "4350.579999999999\n",
      "[CV 4/5; 81/96] END C=10, penalty=l2, solver=liblinear;, score=-4350.580 total time=   1.4s\n",
      "[CV 5/5; 81/96] START C=10, penalty=l2, solver=liblinear........................\n",
      "No of FN: 40\n",
      "11141.570000000002\n",
      "[CV 5/5; 81/96] END C=10, penalty=l2, solver=liblinear;, score=-11141.570 total time=   1.3s\n",
      "[CV 1/5; 82/96] START C=10, penalty=elasticnet, solver=newton-cg................\n",
      "[CV 1/5; 82/96] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 82/96] START C=10, penalty=elasticnet, solver=newton-cg................\n",
      "[CV 2/5; 82/96] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 82/96] START C=10, penalty=elasticnet, solver=newton-cg................\n",
      "[CV 3/5; 82/96] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 82/96] START C=10, penalty=elasticnet, solver=newton-cg................\n",
      "[CV 4/5; 82/96] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 82/96] START C=10, penalty=elasticnet, solver=newton-cg................\n",
      "[CV 5/5; 82/96] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 83/96] START C=10, penalty=elasticnet, solver=lbfgs....................\n",
      "[CV 1/5; 83/96] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 83/96] START C=10, penalty=elasticnet, solver=lbfgs....................\n",
      "[CV 2/5; 83/96] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 83/96] START C=10, penalty=elasticnet, solver=lbfgs....................\n",
      "[CV 3/5; 83/96] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 83/96] START C=10, penalty=elasticnet, solver=lbfgs....................\n",
      "[CV 4/5; 83/96] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 83/96] START C=10, penalty=elasticnet, solver=lbfgs....................\n",
      "[CV 5/5; 83/96] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 84/96] START C=10, penalty=elasticnet, solver=liblinear................\n",
      "[CV 1/5; 84/96] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 84/96] START C=10, penalty=elasticnet, solver=liblinear................\n",
      "[CV 2/5; 84/96] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 84/96] START C=10, penalty=elasticnet, solver=liblinear................\n",
      "[CV 3/5; 84/96] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 84/96] START C=10, penalty=elasticnet, solver=liblinear................\n",
      "[CV 4/5; 84/96] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 84/96] START C=10, penalty=elasticnet, solver=liblinear................\n",
      "[CV 5/5; 84/96] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 85/96] START C=100, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 85/96] END C=100, penalty=none, solver=newton-cg;, score=-5397.220 total time=  10.2s\n",
      "[CV 2/5; 85/96] START C=100, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7092.449999999999\n",
      "[CV 2/5; 85/96] END C=100, penalty=none, solver=newton-cg;, score=-7092.450 total time=   9.7s\n",
      "[CV 3/5; 85/96] START C=100, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 28\n",
      "3285.26\n",
      "[CV 3/5; 85/96] END C=100, penalty=none, solver=newton-cg;, score=-3285.260 total time=   9.8s\n",
      "[CV 4/5; 85/96] START C=100, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "4171.469999999999\n",
      "[CV 4/5; 85/96] END C=100, penalty=none, solver=newton-cg;, score=-4171.470 total time=   9.4s\n",
      "[CV 5/5; 85/96] START C=100, penalty=none, solver=newton-cg.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 85/96] END C=100, penalty=none, solver=newton-cg;, score=-10254.790 total time=   9.4s\n",
      "[CV 1/5; 86/96] START C=100, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 21\n",
      "5005.969999999999\n",
      "[CV 1/5; 86/96] END C=100, penalty=none, solver=lbfgs;, score=-5005.970 total time=   1.3s\n",
      "[CV 2/5; 86/96] START C=100, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 29\n",
      "7263.7300000000005\n",
      "[CV 2/5; 86/96] END C=100, penalty=none, solver=lbfgs;, score=-7263.730 total time=   1.4s\n",
      "[CV 3/5; 86/96] START C=100, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "4114.3\n",
      "[CV 3/5; 86/96] END C=100, penalty=none, solver=lbfgs;, score=-4114.300 total time=   1.4s\n",
      "[CV 4/5; 86/96] START C=100, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 26\n",
      "3790.4599999999996\n",
      "[CV 4/5; 86/96] END C=100, penalty=none, solver=lbfgs;, score=-3790.460 total time=   1.6s\n",
      "[CV 5/5; 86/96] START C=100, penalty=none, solver=lbfgs.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 39\n",
      "11250.080000000002\n",
      "[CV 5/5; 86/96] END C=100, penalty=none, solver=lbfgs;, score=-11250.080 total time=   1.5s\n",
      "[CV 1/5; 87/96] START C=100, penalty=none, solver=liblinear.....................\n",
      "[CV 1/5; 87/96] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 87/96] START C=100, penalty=none, solver=liblinear.....................\n",
      "[CV 2/5; 87/96] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 87/96] START C=100, penalty=none, solver=liblinear.....................\n",
      "[CV 3/5; 87/96] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 87/96] START C=100, penalty=none, solver=liblinear.....................\n",
      "[CV 4/5; 87/96] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 87/96] START C=100, penalty=none, solver=liblinear.....................\n",
      "[CV 5/5; 87/96] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5; 88/96] START C=100, penalty=l1, solver=newton-cg.......................\n",
      "[CV 1/5; 88/96] END C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 88/96] START C=100, penalty=l1, solver=newton-cg.......................\n",
      "[CV 2/5; 88/96] END C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 88/96] START C=100, penalty=l1, solver=newton-cg.......................\n",
      "[CV 3/5; 88/96] END C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 88/96] START C=100, penalty=l1, solver=newton-cg.......................\n",
      "[CV 4/5; 88/96] END C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 88/96] START C=100, penalty=l1, solver=newton-cg.......................\n",
      "[CV 5/5; 88/96] END C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 89/96] START C=100, penalty=l1, solver=lbfgs...........................\n",
      "[CV 1/5; 89/96] END C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 89/96] START C=100, penalty=l1, solver=lbfgs...........................\n",
      "[CV 2/5; 89/96] END C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 89/96] START C=100, penalty=l1, solver=lbfgs...........................\n",
      "[CV 3/5; 89/96] END C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 89/96] START C=100, penalty=l1, solver=lbfgs...........................\n",
      "[CV 4/5; 89/96] END C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 89/96] START C=100, penalty=l1, solver=lbfgs...........................\n",
      "[CV 5/5; 89/96] END C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 90/96] START C=100, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 34\n",
      "5394.959999999999\n",
      "[CV 1/5; 90/96] END C=100, penalty=l1, solver=liblinear;, score=-5394.960 total time=   2.1s\n",
      "[CV 2/5; 90/96] START C=100, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 31\n",
      "7107.75\n",
      "[CV 2/5; 90/96] END C=100, penalty=l1, solver=liblinear;, score=-7107.750 total time=   1.4s\n",
      "[CV 3/5; 90/96] START C=100, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 23\n",
      "2629.96\n",
      "[CV 3/5; 90/96] END C=100, penalty=l1, solver=liblinear;, score=-2629.960 total time=   2.6s\n",
      "[CV 4/5; 90/96] START C=100, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 27\n",
      "3587.8099999999995\n",
      "[CV 4/5; 90/96] END C=100, penalty=l1, solver=liblinear;, score=-3587.810 total time=   2.2s\n",
      "[CV 5/5; 90/96] START C=100, penalty=l1, solver=liblinear.......................\n",
      "No of FN: 35\n",
      "7293.200000000001\n",
      "[CV 5/5; 90/96] END C=100, penalty=l1, solver=liblinear;, score=-7293.200 total time=   1.8s\n",
      "[CV 1/5; 91/96] START C=100, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 33\n",
      "5397.219999999999\n",
      "[CV 1/5; 91/96] END C=100, penalty=l2, solver=newton-cg;, score=-5397.220 total time=   9.7s\n",
      "[CV 2/5; 91/96] START C=100, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 30\n",
      "7097.449999999999\n",
      "[CV 2/5; 91/96] END C=100, penalty=l2, solver=newton-cg;, score=-7097.450 total time=   9.7s\n",
      "[CV 3/5; 91/96] START C=100, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "3294.26\n",
      "[CV 3/5; 91/96] END C=100, penalty=l2, solver=newton-cg;, score=-3294.260 total time=   9.2s\n",
      "[CV 4/5; 91/96] START C=100, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 31\n",
      "4308.269999999999\n",
      "[CV 4/5; 91/96] END C=100, penalty=l2, solver=newton-cg;, score=-4308.270 total time=   9.5s\n",
      "[CV 5/5; 91/96] START C=100, penalty=l2, solver=newton-cg.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 36\n",
      "10254.79\n",
      "[CV 5/5; 91/96] END C=100, penalty=l2, solver=newton-cg;, score=-10254.790 total time=   8.8s\n",
      "[CV 1/5; 92/96] START C=100, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 19\n",
      "4900.98\n",
      "[CV 1/5; 92/96] END C=100, penalty=l2, solver=lbfgs;, score=-4900.980 total time=   1.5s\n",
      "[CV 2/5; 92/96] START C=100, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 24\n",
      "5202.4000000000015\n",
      "[CV 2/5; 92/96] END C=100, penalty=l2, solver=lbfgs;, score=-5202.400 total time=   1.4s\n",
      "[CV 3/5; 92/96] START C=100, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 23\n",
      "3317.5599999999995\n",
      "[CV 3/5; 92/96] END C=100, penalty=l2, solver=lbfgs;, score=-3317.560 total time=   1.2s\n",
      "[CV 4/5; 92/96] START C=100, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 27\n",
      "3885.45\n",
      "[CV 4/5; 92/96] END C=100, penalty=l2, solver=lbfgs;, score=-3885.450 total time=   1.3s\n",
      "[CV 5/5; 92/96] START C=100, penalty=l2, solver=lbfgs...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 41\n",
      "12015.660000000002\n",
      "[CV 5/5; 92/96] END C=100, penalty=l2, solver=lbfgs;, score=-12015.660 total time=   1.3s\n",
      "[CV 1/5; 93/96] START C=100, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 30\n",
      "5560.88\n",
      "[CV 1/5; 93/96] END C=100, penalty=l2, solver=liblinear;, score=-5560.880 total time=   2.0s\n",
      "[CV 2/5; 93/96] START C=100, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 32\n",
      "7059.46\n",
      "[CV 2/5; 93/96] END C=100, penalty=l2, solver=liblinear;, score=-7059.460 total time=   2.2s\n",
      "[CV 3/5; 93/96] START C=100, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 31\n",
      "4565.78\n",
      "[CV 3/5; 93/96] END C=100, penalty=l2, solver=liblinear;, score=-4565.780 total time=   2.1s\n",
      "[CV 4/5; 93/96] START C=100, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 35\n",
      "4350.579999999999\n",
      "[CV 4/5; 93/96] END C=100, penalty=l2, solver=liblinear;, score=-4350.580 total time=   1.5s\n",
      "[CV 5/5; 93/96] START C=100, penalty=l2, solver=liblinear.......................\n",
      "No of FN: 40\n",
      "11141.570000000002\n",
      "[CV 5/5; 93/96] END C=100, penalty=l2, solver=liblinear;, score=-11141.570 total time=   1.3s\n",
      "[CV 1/5; 94/96] START C=100, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 1/5; 94/96] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5; 94/96] START C=100, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 2/5; 94/96] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5; 94/96] START C=100, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 3/5; 94/96] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5; 94/96] START C=100, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 4/5; 94/96] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5; 94/96] START C=100, penalty=elasticnet, solver=newton-cg...............\n",
      "[CV 5/5; 94/96] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5; 95/96] START C=100, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 1/5; 95/96] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5; 95/96] START C=100, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 2/5; 95/96] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5; 95/96] START C=100, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 3/5; 95/96] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5; 95/96] START C=100, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 4/5; 95/96] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5; 95/96] START C=100, penalty=elasticnet, solver=lbfgs...................\n",
      "[CV 5/5; 95/96] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5; 96/96] START C=100, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 1/5; 96/96] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5; 96/96] START C=100, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 2/5; 96/96] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5; 96/96] START C=100, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 3/5; 96/96] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5; 96/96] START C=100, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 4/5; 96/96] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5; 96/96] START C=100, penalty=elasticnet, solver=liblinear...............\n",
      "[CV 5/5; 96/96] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-6040.238 -6284.908       nan       nan       nan -9824.9   -9824.9\n",
      " -9827.9   -9844.08        nan       nan       nan -6040.238 -6284.908\n",
      "       nan       nan       nan -9824.9   -8258.348 -8621.46  -9141.946\n",
      "       nan       nan       nan -6040.238 -6284.908       nan       nan\n",
      "       nan -8636.74  -6971.732 -7194.242 -7445.888       nan       nan\n",
      "       nan -6040.238 -6284.908       nan       nan       nan -6747.836\n",
      " -6158.892 -6414.664 -6644.392       nan       nan       nan -6040.238\n",
      " -6284.908       nan       nan       nan -5944.852 -6066.752 -6080.196\n",
      " -6439.23        nan       nan       nan -6040.238 -6284.908       nan\n",
      "       nan       nan -5528.684 -6066.598 -6072.454 -6316.378       nan\n",
      "       nan       nan -6040.238 -6284.908       nan       nan       nan\n",
      " -5201.738 -6044.498 -5169.19  -6535.654       nan       nan       nan\n",
      " -6040.238 -6284.908       nan       nan       nan -5202.736 -6070.398\n",
      " -5864.41  -6535.654       nan       nan       nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [-6040.238 -6284.908       nan       nan       nan -9824.9   -9824.9\n",
      " -9827.9   -9844.08        nan       nan       nan -6040.238 -6284.908\n",
      "       nan       nan       nan -9824.9   -8258.348 -8621.46  -9141.946\n",
      "       nan       nan       nan -6040.238 -6284.908       nan       nan\n",
      "       nan -8636.74  -6971.732 -7194.242 -7445.888       nan       nan\n",
      "       nan -6040.238 -6284.908       nan       nan       nan -6747.836\n",
      " -6158.892 -6414.664 -6644.392       nan       nan       nan -6040.238\n",
      " -6284.908       nan       nan       nan -5944.852 -6066.752 -6080.196\n",
      " -6439.23        nan       nan       nan -6040.238 -6284.908       nan\n",
      "       nan       nan -5528.684 -6066.598 -6072.454 -6316.378       nan\n",
      "       nan       nan -6040.238 -6284.908       nan       nan       nan\n",
      " -5201.738 -6044.498 -5169.19  -6535.654       nan       nan       nan\n",
      " -6040.238 -6284.908       nan       nan       nan -5202.736 -6070.398\n",
      " -5864.41  -6535.654       nan       nan       nan], using {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.313076</td>\n",
       "      <td>0.377507</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'none', 'solver': 'new...</td>\n",
       "      <td>-5397.22</td>\n",
       "      <td>-7092.45</td>\n",
       "      <td>-3285.26</td>\n",
       "      <td>-4171.47</td>\n",
       "      <td>-10254.79</td>\n",
       "      <td>-6040.238</td>\n",
       "      <td>2464.356647</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.510200</td>\n",
       "      <td>0.063019</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'none', 'solver': 'lbf...</td>\n",
       "      <td>-5005.97</td>\n",
       "      <td>-7263.73</td>\n",
       "      <td>-4114.30</td>\n",
       "      <td>-3790.46</td>\n",
       "      <td>-11250.08</td>\n",
       "      <td>-6284.908</td>\n",
       "      <td>2763.350062</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'none', 'solver': 'lib...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018997</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1', 'solver': 'newto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017599</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.415807</td>\n",
       "      <td>0.076935</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>-4900.98</td>\n",
       "      <td>-5202.40</td>\n",
       "      <td>-3317.56</td>\n",
       "      <td>-3885.45</td>\n",
       "      <td>-12015.66</td>\n",
       "      <td>-5864.410</td>\n",
       "      <td>3149.827258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.888787</td>\n",
       "      <td>0.356815</td>\n",
       "      <td>0.022411</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>-5560.88</td>\n",
       "      <td>-7059.46</td>\n",
       "      <td>-4565.78</td>\n",
       "      <td>-4350.58</td>\n",
       "      <td>-11141.57</td>\n",
       "      <td>-6535.654</td>\n",
       "      <td>2493.751040</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.018993</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100, 'penalty': 'elasticnet', 'solver': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'penalty': 'elasticnet', 'solver': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'penalty': 'elasticnet', 'solver': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0       10.313076      0.377507         0.023599        0.001624  0.00001   \n",
       "1        1.510200      0.063019         0.022399        0.000800  0.00001   \n",
       "2        0.018198      0.000981         0.000000        0.000000  0.00001   \n",
       "3        0.018997      0.002186         0.000000        0.000000  0.00001   \n",
       "4        0.017599      0.000800         0.000000        0.000000  0.00001   \n",
       "..            ...           ...              ...             ...      ...   \n",
       "91       1.415807      0.076935         0.022193        0.000986      100   \n",
       "92       1.888787      0.356815         0.022411        0.000488      100   \n",
       "93       0.018993      0.001780         0.000000        0.000000      100   \n",
       "94       0.015806      0.000418         0.000000        0.000000      100   \n",
       "95       0.015412      0.000791         0.000000        0.000000      100   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "0           none    newton-cg   \n",
       "1           none        lbfgs   \n",
       "2           none    liblinear   \n",
       "3             l1    newton-cg   \n",
       "4             l1        lbfgs   \n",
       "..           ...          ...   \n",
       "91            l2        lbfgs   \n",
       "92            l2    liblinear   \n",
       "93    elasticnet    newton-cg   \n",
       "94    elasticnet        lbfgs   \n",
       "95    elasticnet    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 1e-05, 'penalty': 'none', 'solver': 'new...           -5397.22   \n",
       "1   {'C': 1e-05, 'penalty': 'none', 'solver': 'lbf...           -5005.97   \n",
       "2   {'C': 1e-05, 'penalty': 'none', 'solver': 'lib...                NaN   \n",
       "3   {'C': 1e-05, 'penalty': 'l1', 'solver': 'newto...                NaN   \n",
       "4    {'C': 1e-05, 'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "..                                                ...                ...   \n",
       "91     {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}           -4900.98   \n",
       "92  {'C': 100, 'penalty': 'l2', 'solver': 'libline...           -5560.88   \n",
       "93  {'C': 100, 'penalty': 'elasticnet', 'solver': ...                NaN   \n",
       "94  {'C': 100, 'penalty': 'elasticnet', 'solver': ...                NaN   \n",
       "95  {'C': 100, 'penalty': 'elasticnet', 'solver': ...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            -7092.45           -3285.26           -4171.47   \n",
       "1            -7263.73           -4114.30           -3790.46   \n",
       "2                 NaN                NaN                NaN   \n",
       "3                 NaN                NaN                NaN   \n",
       "4                 NaN                NaN                NaN   \n",
       "..                ...                ...                ...   \n",
       "91           -5202.40           -3317.56           -3885.45   \n",
       "92           -7059.46           -4565.78           -4350.58   \n",
       "93                NaN                NaN                NaN   \n",
       "94                NaN                NaN                NaN   \n",
       "95                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -10254.79        -6040.238     2464.356647                7  \n",
       "1           -11250.08        -6284.908     2763.350062               22  \n",
       "2                 NaN              NaN             NaN               66  \n",
       "3                 NaN              NaN             NaN               67  \n",
       "4                 NaN              NaN             NaN               68  \n",
       "..                ...              ...             ...              ...  \n",
       "91          -12015.66        -5864.410     3149.827258                5  \n",
       "92          -11141.57        -6535.654     2493.751040               33  \n",
       "93                NaN              NaN             NaN               50  \n",
       "94                NaN              NaN             NaN               89  \n",
       "95                NaN              NaN             NaN               96  \n",
       "\n",
       "[96 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ebc8ebb-2531-410d-9396-3e43ce7ca049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def my_scorer_smt(y_true, y_pred):\n",
    "    model_cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    for cls in range(model_cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, model_cm).ravel() \n",
    "        \n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "    X_test_score = X_smt\n",
    "    # X_test_score = get_x_elements_by_indices(X_test_score, y_true.index)\n",
    "    #print(labels[y_true * 2 + y_pred])\n",
    "    #X_test_score['case'] = labels[y_true * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegativeMyScorer(X_test_score, y_true, y_pred) + (FP + TP) * Ca\n",
    "    print(TotalCost)\n",
    "    return TotalCost\n",
    "\n",
    "my_func_smt = make_scorer(my_scorer_smt, greater_is_better=False)\n",
    "\n",
    "#my_scorer(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98be83f0-64eb-444c-bbeb-11f0ff2c59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "# DecisionTreeClassifier\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state=42), \n",
    "                              LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0edb9d07-cdc3-4b38-b226-c19dc4eee01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  24.2s\n",
      "[CV 2/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  22.7s\n",
      "[CV 3/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  24.0s\n",
      "[CV 4/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  23.7s\n",
      "[CV 5/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  25.5s\n",
      "[CV 1/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.3s\n",
      "[CV 2/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.3s\n",
      "[CV 3/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.4s\n",
      "[CV 4/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.7s\n",
      "[CV 5/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   2.0s\n",
      "[CV 1/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 15\n",
      "6354.840197613744\n",
      "[CV 1/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-6354.840 total time=   1.1s\n",
      "[CV 2/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 17\n",
      "5737.959170225919\n",
      "[CV 2/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5737.959 total time=   1.2s\n",
      "[CV 3/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "5343.74\n",
      "[CV 3/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5343.740 total time=   1.1s\n",
      "[CV 4/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5603.02394223854\n",
      "[CV 4/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5603.024 total time=   1.0s\n",
      "[CV 5/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 13\n",
      "7534.9821468185255\n",
      "[CV 5/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-7534.982 total time=   1.0s\n",
      "[CV 1/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2582.9550973669657\n",
      "[CV 1/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2582.955 total time=  24.7s\n",
      "[CV 2/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2327.5447223717524\n",
      "[CV 2/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2327.545 total time=  24.5s\n",
      "[CV 3/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "1848.67\n",
      "[CV 3/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-1848.670 total time=  23.3s\n",
      "[CV 4/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2141.80394223854\n",
      "[CV 4/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2141.804 total time=  23.9s\n",
      "[CV 5/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3918.042276488321\n",
      "[CV 5/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3918.042 total time=  24.6s\n",
      "[CV 1/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 14\n",
      "5068.060197613744\n",
      "[CV 1/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5068.060 total time=   1.4s\n",
      "[CV 2/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 18\n",
      "5646.154722371752\n",
      "[CV 2/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5646.155 total time=   1.3s\n",
      "[CV 3/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "3665.63\n",
      "[CV 3/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-3665.630 total time=   2.3s\n",
      "[CV 4/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "4097.02394223854\n",
      "[CV 4/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4097.024 total time=   2.0s\n",
      "[CV 5/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 13\n",
      "6683.342276488322\n",
      "[CV 5/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6683.342 total time=   1.3s\n",
      "[CV 1/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 14\n",
      "3978.060197613744\n",
      "[CV 1/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3978.060 total time=   3.6s\n",
      "[CV 2/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 12\n",
      "4128.094722371752\n",
      "[CV 2/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4128.095 total time=   3.6s\n",
      "[CV 3/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3430.63\n",
      "[CV 3/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3430.630 total time=   3.9s\n",
      "[CV 4/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "3711.80394223854\n",
      "[CV 4/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3711.804 total time=   3.1s\n",
      "[CV 5/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5767.792276488321\n",
      "[CV 5/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5767.792 total time=   3.1s\n",
      "[CV 1/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  26.0s\n",
      "[CV 2/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  23.8s\n",
      "[CV 3/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  24.9s\n",
      "[CV 4/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  25.4s\n",
      "[CV 5/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  27.3s\n",
      "[CV 1/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.3s\n",
      "[CV 2/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.3s\n",
      "[CV 3/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.5s\n",
      "[CV 4/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.9s\n",
      "[CV 5/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   2.1s\n",
      "[CV 1/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.4s\n",
      "[CV 1/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "6038.5696118827345\n",
      "[CV 1/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-6038.570 total time=   1.7s\n",
      "[CV 2/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "5348.317530575388\n",
      "[CV 2/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5348.318 total time=   1.5s\n",
      "[CV 3/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "6015.7\n",
      "[CV 3/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-6015.700 total time=   1.8s\n",
      "[CV 4/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "5774.01394223854\n",
      "[CV 4/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5774.014 total time=   1.8s\n",
      "[CV 5/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "8154.199999999999\n",
      "[CV 5/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-8154.200 total time=   1.4s\n",
      "[CV 1/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "3013.844511635956\n",
      "[CV 1/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3013.845 total time=  26.3s\n",
      "[CV 2/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3006.4475305753886\n",
      "[CV 2/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3006.448 total time=  25.6s\n",
      "[CV 3/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2924.92\n",
      "[CV 3/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2924.920 total time=  25.0s\n",
      "[CV 4/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3092.0239422385403\n",
      "[CV 4/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3092.024 total time=  25.0s\n",
      "[CV 5/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "5432.4\n",
      "[CV 5/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5432.400 total time=  24.7s\n",
      "[CV 1/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5103.5696118827345\n",
      "[CV 1/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5103.570 total time=   1.9s\n",
      "[CV 2/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 15\n",
      "6718.824722371752\n",
      "[CV 2/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6718.825 total time=   1.3s\n",
      "[CV 3/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "4935.7\n",
      "[CV 3/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4935.700 total time=   2.2s\n",
      "[CV 4/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "4898.90394223854\n",
      "[CV 4/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4898.904 total time=   2.0s\n",
      "[CV 5/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "6742.539999999999\n",
      "[CV 5/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6742.540 total time=   2.9s\n",
      "[CV 1/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "3728.844511635956\n",
      "[CV 1/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3728.845 total time=   3.4s\n",
      "[CV 2/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4299.814722371752\n",
      "[CV 2/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4299.815 total time=   3.0s\n",
      "[CV 3/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3960.63\n",
      "[CV 3/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3960.630 total time=   4.0s\n",
      "[CV 4/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4638.02394223854\n",
      "[CV 4/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4638.024 total time=   3.2s\n",
      "[CV 5/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5897.792276488321\n",
      "[CV 5/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5897.792 total time=   2.6s\n",
      "[CV 1/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  24.0s\n",
      "[CV 2/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  22.6s\n",
      "[CV 3/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  25.3s\n",
      "[CV 4/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  25.4s\n",
      "[CV 5/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  26.5s\n",
      "[CV 1/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.3s\n",
      "[CV 2/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.7s\n",
      "[CV 3/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.5s\n",
      "[CV 4/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   3.0s\n",
      "[CV 5/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   2.0s\n",
      "[CV 1/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.4s\n",
      "[CV 4/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "3133.844511635956\n",
      "[CV 1/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3133.845 total time=   3.5s\n",
      "[CV 2/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3106.5175305753887\n",
      "[CV 2/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3106.518 total time=   4.1s\n",
      "[CV 3/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3115.63\n",
      "[CV 3/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3115.630 total time=   3.7s\n",
      "[CV 4/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3357.0239422385403\n",
      "[CV 4/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3357.024 total time=   1.7s\n",
      "[CV 5/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "5609.199999999999\n",
      "[CV 5/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5609.200 total time=   2.3s\n",
      "[CV 1/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "3093.844511635956\n",
      "[CV 1/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3093.845 total time=  26.6s\n",
      "[CV 2/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2901.5175305753887\n",
      "[CV 2/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2901.518 total time=  26.1s\n",
      "[CV 3/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3034.92\n",
      "[CV 3/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3034.920 total time=  27.1s\n",
      "[CV 4/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2967.0239422385403\n",
      "[CV 4/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2967.024 total time=  24.3s\n",
      "[CV 5/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5361.629999999999\n",
      "[CV 5/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5361.630 total time=  25.0s\n",
      "[CV 1/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5553.5696118827345\n",
      "[CV 1/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5553.570 total time=   2.5s\n",
      "[CV 2/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5346.517530575388\n",
      "[CV 2/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5346.518 total time=   2.6s\n",
      "[CV 3/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8081.582434600649\n",
      "[CV 3/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8081.582 total time=   1.4s\n",
      "[CV 4/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "5288.90394223854\n",
      "[CV 4/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5288.904 total time=   2.1s\n",
      "[CV 5/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "6962.539999999999\n",
      "[CV 5/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6962.540 total time=   2.7s\n",
      "[CV 1/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4353.844511635956\n",
      "[CV 1/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4353.845 total time=   3.6s\n",
      "[CV 2/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "4843.814722371752\n",
      "[CV 2/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4843.815 total time=   3.2s\n",
      "[CV 3/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4485.7\n",
      "[CV 3/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4485.700 total time=   3.4s\n",
      "[CV 4/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4753.02394223854\n",
      "[CV 4/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4753.024 total time=   3.6s\n",
      "[CV 5/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5907.792276488321\n",
      "[CV 5/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5907.792 total time=   3.1s\n",
      "[CV 1/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.4s\n",
      "[CV 5/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  23.9s\n",
      "[CV 2/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  23.3s\n",
      "[CV 3/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  25.4s\n",
      "[CV 4/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  24.1s\n",
      "[CV 5/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  25.3s\n",
      "[CV 1/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.2s\n",
      "[CV 2/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.2s\n",
      "[CV 3/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.3s\n",
      "[CV 4/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.6s\n",
      "[CV 5/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.9s\n",
      "[CV 1/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2747.9745116359563\n",
      "[CV 1/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2747.975 total time=   4.4s\n",
      "[CV 2/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2846.5175305753887\n",
      "[CV 2/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2846.518 total time=   1.5s\n",
      "[CV 3/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2939.99\n",
      "[CV 3/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2939.990 total time=   4.3s\n",
      "[CV 4/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3082.0239422385403\n",
      "[CV 4/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3082.024 total time=   1.7s\n",
      "[CV 5/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "5149.969999999999\n",
      "[CV 5/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5149.970 total time=   5.1s\n",
      "[CV 1/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2767.9745116359563\n",
      "[CV 1/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2767.975 total time=  23.8s\n",
      "[CV 2/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2886.5175305753887\n",
      "[CV 2/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2886.518 total time=  23.5s\n",
      "[CV 3/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2984.99\n",
      "[CV 3/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2984.990 total time=  22.9s\n",
      "[CV 4/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3052.0239422385403\n",
      "[CV 4/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3052.024 total time=  23.0s\n",
      "[CV 5/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5139.969999999999\n",
      "[CV 5/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5139.970 total time=  25.4s\n",
      "[CV 1/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "4611.258406585697\n",
      "[CV 1/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4611.258 total time=   2.8s\n",
      "[CV 2/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "5263.814722371752\n",
      "[CV 2/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5263.815 total time=   2.7s\n",
      "[CV 3/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8506.582434600648\n",
      "[CV 3/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8506.582 total time=   1.3s\n",
      "[CV 4/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "4898.02394223854\n",
      "[CV 4/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4898.024 total time=   2.9s\n",
      "[CV 5/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "6927.539999999999\n",
      "[CV 5/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6927.540 total time=   2.6s\n",
      "[CV 1/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4403.844511635956\n",
      "[CV 1/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4403.845 total time=   3.8s\n",
      "[CV 2/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4221.517530575388\n",
      "[CV 2/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4221.518 total time=   3.4s\n",
      "[CV 3/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4645.7\n",
      "[CV 3/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4645.700 total time=   3.8s\n",
      "[CV 4/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4878.02394223854\n",
      "[CV 4/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4878.024 total time=   3.3s\n",
      "[CV 5/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5902.792276488321\n",
      "[CV 5/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5902.792 total time=   2.8s\n",
      "[CV 1/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 2/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 3/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 4/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  25.5s\n",
      "[CV 2/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  23.5s\n",
      "[CV 3/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  24.4s\n",
      "[CV 4/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  24.2s\n",
      "[CV 5/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  26.7s\n",
      "[CV 1/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.4s\n",
      "[CV 2/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.3s\n",
      "[CV 3/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.4s\n",
      "[CV 4/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.7s\n",
      "[CV 5/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.9s\n",
      "[CV 1/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2727.9745116359563\n",
      "[CV 1/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2727.975 total time=   7.8s\n",
      "[CV 2/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2831.5175305753887\n",
      "[CV 2/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2831.518 total time=   4.7s\n",
      "[CV 3/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2939.99\n",
      "[CV 3/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2939.990 total time=  17.7s\n",
      "[CV 4/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3012.0239422385403\n",
      "[CV 4/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3012.024 total time=   5.6s\n",
      "[CV 5/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "5094.969999999999\n",
      "[CV 5/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5094.970 total time=   9.6s\n",
      "[CV 1/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2702.9745116359563\n",
      "[CV 1/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2702.975 total time=  24.4s\n",
      "[CV 2/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2841.5175305753887\n",
      "[CV 2/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2841.518 total time=  22.7s\n",
      "[CV 3/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2954.99\n",
      "[CV 3/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2954.990 total time=  22.4s\n",
      "[CV 4/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3002.0239422385403\n",
      "[CV 4/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3002.024 total time=  22.1s\n",
      "[CV 5/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5054.970 total time=  23.9s\n",
      "[CV 1/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.0s\n",
      "[CV 2/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "4576.517530575388\n",
      "[CV 2/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4576.518 total time=   2.5s\n",
      "[CV 3/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.2s\n",
      "[CV 4/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "5578.90394223854\n",
      "[CV 4/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5578.904 total time=   2.0s\n",
      "[CV 5/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "6937.539999999999\n",
      "[CV 5/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6937.540 total time=   2.5s\n",
      "[CV 1/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4413.844511635956\n",
      "[CV 1/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4413.845 total time=   3.0s\n",
      "[CV 2/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4221.517530575388\n",
      "[CV 2/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4221.518 total time=   2.8s\n",
      "[CV 3/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4650.7\n",
      "[CV 3/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4650.700 total time=   2.9s\n",
      "[CV 4/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4888.02394223854\n",
      "[CV 4/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4888.024 total time=   2.7s\n",
      "[CV 5/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5907.792276488321\n",
      "[CV 5/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5907.792 total time=   2.3s\n",
      "[CV 1/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  22.6s\n",
      "[CV 2/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  21.2s\n",
      "[CV 3/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  22.1s\n",
      "[CV 4/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  22.0s\n",
      "[CV 5/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  23.7s\n",
      "[CV 1/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.1s\n",
      "[CV 2/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.1s\n",
      "[CV 3/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.3s\n",
      "[CV 4/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.5s\n",
      "[CV 5/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.9s\n",
      "[CV 1/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2697.975 total time=   7.8s\n",
      "[CV 2/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2841.5175305753887\n",
      "[CV 2/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2841.518 total time=   3.3s\n",
      "[CV 3/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2999.99\n",
      "[CV 3/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2999.990 total time=   2.9s\n",
      "[CV 4/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3022.0239422385403\n",
      "[CV 4/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3022.024 total time=  18.7s\n",
      "[CV 5/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "5099.969999999999\n",
      "[CV 5/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5099.970 total time=   3.0s\n",
      "[CV 1/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2692.9745116359563\n",
      "[CV 1/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2692.975 total time=  21.4s\n",
      "[CV 2/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2819.5075305753885\n",
      "[CV 2/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2819.508 total time=  21.6s\n",
      "[CV 3/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2909.99\n",
      "[CV 3/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2909.990 total time=  22.2s\n",
      "[CV 4/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3037.024 total time=  22.0s\n",
      "[CV 5/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5069.969999999999\n",
      "[CV 5/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5069.970 total time=  22.6s\n",
      "[CV 1/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "4655.388406585696\n",
      "[CV 1/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4655.388 total time=   2.6s\n",
      "[CV 2/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5366.517530575388\n",
      "[CV 2/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5366.518 total time=   2.5s\n",
      "[CV 3/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.2s\n",
      "[CV 4/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "4788.02394223854\n",
      "[CV 4/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4788.024 total time=   2.6s\n",
      "[CV 5/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.8s\n",
      "[CV 1/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4413.844511635956\n",
      "[CV 1/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4413.845 total time=   2.9s\n",
      "[CV 2/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4231.517530575388\n",
      "[CV 2/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4231.518 total time=   2.8s\n",
      "[CV 3/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4655.7\n",
      "[CV 3/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4655.700 total time=   2.9s\n",
      "[CV 4/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4888.02394223854\n",
      "[CV 4/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4888.024 total time=   2.8s\n",
      "[CV 5/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5907.792276488321\n",
      "[CV 5/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5907.792 total time=   2.4s\n",
      "[CV 1/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  22.4s\n",
      "[CV 2/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  21.0s\n",
      "[CV 3/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  21.9s\n",
      "[CV 4/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  22.0s\n",
      "[CV 5/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  23.7s\n",
      "[CV 1/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.1s\n",
      "[CV 2/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.1s\n",
      "[CV 3/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.2s\n",
      "[CV 4/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.4s\n",
      "[CV 5/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.9s\n",
      "[CV 1/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2697.975 total time=   8.2s\n",
      "[CV 2/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2806.5175305753887\n",
      "[CV 2/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2806.518 total time=  12.4s\n",
      "[CV 3/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2939.99\n",
      "[CV 3/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2939.990 total time=  12.3s\n",
      "[CV 4/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2992.0239422385403\n",
      "[CV 4/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2992.024 total time=   7.4s\n",
      "[CV 5/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "5074.969999999999\n",
      "[CV 5/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5074.970 total time=  10.8s\n",
      "[CV 1/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2672.9745116359563\n",
      "[CV 1/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2672.975 total time=  22.5s\n",
      "[CV 2/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2806.5175305753887\n",
      "[CV 2/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2806.518 total time=  22.1s\n",
      "[CV 3/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2909.99\n",
      "[CV 3/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2909.990 total time=  21.9s\n",
      "[CV 4/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3032.0239422385403\n",
      "[CV 4/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3032.024 total time=  21.6s\n",
      "[CV 5/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5044.969999999999\n",
      "[CV 5/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5044.970 total time=  22.6s\n",
      "[CV 1/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.1s\n",
      "[CV 2/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.1s\n",
      "[CV 3/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.3s\n",
      "[CV 4/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5518.90394223854\n",
      "[CV 4/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5518.904 total time=   2.5s\n",
      "[CV 5/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "6942.539999999999\n",
      "[CV 5/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6942.540 total time=   2.5s\n",
      "[CV 1/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4413.844511635956\n",
      "[CV 1/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4413.845 total time=   2.9s\n",
      "[CV 2/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4231.517530575388\n",
      "[CV 2/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4231.518 total time=   2.9s\n",
      "[CV 3/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4655.7\n",
      "[CV 3/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4655.700 total time=   2.9s\n",
      "[CV 4/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4888.02394223854\n",
      "[CV 4/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4888.024 total time=   2.8s\n",
      "[CV 5/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5907.792276488321\n",
      "[CV 5/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5907.792 total time=   2.3s\n",
      "[CV 1/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2697.9745116359563\n",
      "[CV 1/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2697.975 total time=  22.4s\n",
      "[CV 2/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2826.518 total time=  21.1s\n",
      "[CV 3/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2884.99\n",
      "[CV 3/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2884.990 total time=  22.0s\n",
      "[CV 4/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3037.024 total time=  22.0s\n",
      "[CV 5/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5054.969999999999\n",
      "[CV 5/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-5054.970 total time=  23.6s\n",
      "[CV 1/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.1s\n",
      "[CV 2/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5291.517530575388\n",
      "[CV 2/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5291.518 total time=   2.1s\n",
      "[CV 3/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.2s\n",
      "[CV 4/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.4s\n",
      "[CV 5/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.9s\n",
      "[CV 1/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2702.9745116359563\n",
      "[CV 1/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2702.975 total time=  13.3s\n",
      "[CV 2/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2826.5175305753887\n",
      "[CV 2/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2826.518 total time=   3.3s\n",
      "[CV 3/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3014.99\n",
      "[CV 3/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3014.990 total time=   2.6s\n",
      "[CV 4/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3022.0239422385403\n",
      "[CV 4/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3022.024 total time=  36.8s\n",
      "[CV 5/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "5099.969999999999\n",
      "[CV 5/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5099.970 total time=   2.9s\n",
      "[CV 1/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2707.9745116359563\n",
      "[CV 1/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2707.975 total time=  20.5s\n",
      "[CV 2/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2811.5175305753887\n",
      "[CV 2/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2811.518 total time=  21.5s\n",
      "[CV 3/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2904.99\n",
      "[CV 3/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2904.990 total time=  22.3s\n",
      "[CV 4/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3037.0239422385403\n",
      "[CV 4/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3037.024 total time=  21.3s\n",
      "[CV 5/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5089.969999999999\n",
      "[CV 5/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-5089.970 total time=  22.2s\n",
      "[CV 1/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5783.5696118827345\n",
      "[CV 1/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5783.570 total time=   2.1s\n",
      "[CV 2/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "4551.517530575388\n",
      "[CV 2/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4551.518 total time=   2.5s\n",
      "[CV 3/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8536.582434600648\n",
      "[CV 3/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8536.582 total time=   1.2s\n",
      "[CV 4/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5538.90394223854\n",
      "[CV 4/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5538.904 total time=   2.5s\n",
      "[CV 5/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "8147.539999999999\n",
      "[CV 5/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8147.540 total time=   1.8s\n",
      "[CV 1/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4413.844511635956\n",
      "[CV 1/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4413.845 total time=   3.0s\n",
      "[CV 2/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4231.517530575388\n",
      "[CV 2/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4231.518 total time=   2.8s\n",
      "[CV 3/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4655.7\n",
      "[CV 3/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4655.700 total time=   2.9s\n",
      "[CV 4/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4888.02394223854\n",
      "[CV 4/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4888.024 total time=   2.8s\n",
      "[CV 5/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "5907.792276488321\n",
      "[CV 5/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5907.792 total time=   2.3s\n",
      "[CV 1/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -6114.90909138 -2563.80320769 -5032.04222774\n",
      " -4203.27622774            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -6266.16021694 -3493.92719689 -5679.9076553\n",
      " -4505.02109055            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3664.44319689 -3471.78719689 -6246.62270386\n",
      " -4868.83509055            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3353.29519689 -3366.29519689 -6041.44390116\n",
      " -4810.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3321.29519689 -3311.29519689 -6282.62270386\n",
      " -4816.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3332.29519689 -3305.89319689 -6298.8104628\n",
      " -4819.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3302.29519689 -3293.29519689 -6414.62270386\n",
      " -4819.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3333.29519689 -3310.29519689 -6511.62270386\n",
      " -4819.37565219            nan            nan            nan]\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "# grid_smt = GridSearchCV(estimator=dtc, param_grid=param_grid, scoring=my_func_smt, cv = 5, verbose=10)\n",
    "new_params = {'logisticregression__' + key: param_grid[key] for key in param_grid}\n",
    "# grid_c = GridSearchCV(estimator=dfrst_c, param_grid=param_grid_criterion, scoring=my_func, cv = 5, verbose=10)return_train_score=True,\n",
    "grid_imba = GridSearchCV(imba_pipeline, param_grid=new_params, cv=5, scoring=my_func_smt,  verbose=10)\n",
    "grid_search_imba = grid_imba.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dafea1c-b41f-4918-b949-780d0bd3b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [-3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -6114.90909138 -2563.80320769 -5032.04222774\n",
      " -4203.27622774            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -6266.16021694 -3493.92719689 -5679.9076553\n",
      " -4505.02109055            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3664.44319689 -3471.78719689 -6246.62270386\n",
      " -4868.83509055            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3353.29519689 -3366.29519689 -6041.44390116\n",
      " -4810.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3321.29519689 -3311.29519689 -6282.62270386\n",
      " -4816.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3332.29519689 -3305.89319689 -6298.8104628\n",
      " -4819.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3302.29519689 -3293.29519689 -6414.62270386\n",
      " -4819.37565219            nan            nan            nan\n",
      " -3300.29519689 -6659.62270386            nan            nan\n",
      "            nan -3333.29519689 -3310.29519689 -6511.62270386\n",
      " -4819.37565219            nan            nan            nan], using {'logisticregression__C': 1e-05, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.083000</td>\n",
       "      <td>0.919213</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-2697.974512</td>\n",
       "      <td>-2826.517531</td>\n",
       "      <td>-2884.990000</td>\n",
       "      <td>-3037.023942</td>\n",
       "      <td>-5054.970000</td>\n",
       "      <td>-3300.295197</td>\n",
       "      <td>884.073448</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.200200</td>\n",
       "      <td>0.413407</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-5783.569612</td>\n",
       "      <td>-5291.517531</td>\n",
       "      <td>-8536.582435</td>\n",
       "      <td>-5538.903942</td>\n",
       "      <td>-8147.540000</td>\n",
       "      <td>-6659.622704</td>\n",
       "      <td>1387.952956</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.295600</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.295190</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329001</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2.097793</td>\n",
       "      <td>0.462749</td>\n",
       "      <td>0.020606</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-5783.569612</td>\n",
       "      <td>-4551.517531</td>\n",
       "      <td>-8536.582435</td>\n",
       "      <td>-5538.903942</td>\n",
       "      <td>-8147.540000</td>\n",
       "      <td>-6511.622704</td>\n",
       "      <td>1555.309789</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2.835199</td>\n",
       "      <td>0.234582</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-4413.844512</td>\n",
       "      <td>-4231.517531</td>\n",
       "      <td>-4655.700000</td>\n",
       "      <td>-4888.023942</td>\n",
       "      <td>-5907.792276</td>\n",
       "      <td>-4819.375652</td>\n",
       "      <td>587.568844</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.275399</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.282608</td>\n",
       "      <td>0.014722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       24.083000      0.919213         0.021800        0.000400   \n",
       "1        2.200200      0.413407         0.021200        0.000401   \n",
       "2        0.295600      0.005422         0.000000        0.000000   \n",
       "3        0.295190      0.005647         0.000000        0.000000   \n",
       "4        0.329001      0.023100         0.000000        0.000000   \n",
       "..            ...           ...              ...             ...   \n",
       "91       2.097793      0.462749         0.020606        0.000496   \n",
       "92       2.835199      0.234582         0.020806        0.000403   \n",
       "93       0.276800      0.008699         0.000000        0.000000   \n",
       "94       0.275399      0.006854         0.000000        0.000000   \n",
       "95       0.282608      0.014722         0.000000        0.000000   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__penalty  \\\n",
       "0                      0.00001                              none   \n",
       "1                      0.00001                              none   \n",
       "2                      0.00001                              none   \n",
       "3                      0.00001                                l1   \n",
       "4                      0.00001                                l1   \n",
       "..                         ...                               ...   \n",
       "91                         100                                l2   \n",
       "92                         100                                l2   \n",
       "93                         100                        elasticnet   \n",
       "94                         100                        elasticnet   \n",
       "95                         100                        elasticnet   \n",
       "\n",
       "   param_logisticregression__solver  \\\n",
       "0                         newton-cg   \n",
       "1                             lbfgs   \n",
       "2                         liblinear   \n",
       "3                         newton-cg   \n",
       "4                             lbfgs   \n",
       "..                              ...   \n",
       "91                            lbfgs   \n",
       "92                        liblinear   \n",
       "93                        newton-cg   \n",
       "94                            lbfgs   \n",
       "95                        liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'logisticregression__C': 1e-05, 'logisticregr...       -2697.974512   \n",
       "1   {'logisticregression__C': 1e-05, 'logisticregr...       -5783.569612   \n",
       "2   {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "3   {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "4   {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "..                                                ...                ...   \n",
       "91  {'logisticregression__C': 100, 'logisticregres...       -5783.569612   \n",
       "92  {'logisticregression__C': 100, 'logisticregres...       -4413.844512   \n",
       "93  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "94  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "95  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0        -2826.517531       -2884.990000       -3037.023942   \n",
       "1        -5291.517531       -8536.582435       -5538.903942   \n",
       "2                 NaN                NaN                NaN   \n",
       "3                 NaN                NaN                NaN   \n",
       "4                 NaN                NaN                NaN   \n",
       "..                ...                ...                ...   \n",
       "91       -4551.517531       -8536.582435       -5538.903942   \n",
       "92       -4231.517531       -4655.700000       -4888.023942   \n",
       "93                NaN                NaN                NaN   \n",
       "94                NaN                NaN                NaN   \n",
       "95                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0        -5054.970000     -3300.295197      884.073448                3  \n",
       "1        -8147.540000     -6659.622704     1387.952956               41  \n",
       "2                 NaN              NaN             NaN               66  \n",
       "3                 NaN              NaN             NaN               67  \n",
       "4                 NaN              NaN             NaN               68  \n",
       "..                ...              ...             ...              ...  \n",
       "91       -8147.540000     -6511.622704     1555.309789               40  \n",
       "92       -5907.792276     -4819.375652      587.568844               27  \n",
       "93                NaN              NaN             NaN               49  \n",
       "94                NaN              NaN             NaN               89  \n",
       "95                NaN              NaN             NaN               96  \n",
       "\n",
       "[96 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_search_imba.cv_results_['mean_test_score'], grid_search_imba.best_params_))\n",
    "results_df_smt = pd.DataFrame(grid_search_imba.cv_results_)\n",
    "results_df_smt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59df01e-5af4-4e92-b9da-f1f69ecbce20",
   "metadata": {},
   "source": [
    "# Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d074b3d-abbd-4421-8303-caba4bd908be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.1, random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "anomaly_inputs = []\n",
    "for name in transactions.columns[1:29]:\n",
    "    anomaly_inputs.append(name)\n",
    "anomaly_inputs.append('Class')\n",
    "\n",
    "model_IF = IsolationForest(contamination=float(0.1),random_state=42)\n",
    "\n",
    "anomaly_df = transactions\n",
    "model_IF.fit(anomaly_df[anomaly_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc406d3c-3c71-4f2e-ac56-43e36d1484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df['anomaly_scores'] = model_IF.decision_function(anomaly_df[anomaly_inputs])\n",
    "anomaly_df['anomaly'] = model_IF.predict(anomaly_df[anomaly_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52a82db8-7697-4335-a090-c210aab824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_o = anomaly_df[(anomaly_df[\"anomaly\"]==1) | ((anomaly_df[\"Class\"]==1) & (anomaly_df[\"anomaly\"]==-1))]\n",
    "df_wo_o = df_wo_o.drop(\"anomaly\", axis='columns')\n",
    "df_wo_o = df_wo_o.drop(\"anomaly_scores\", axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77c8d47b-a061-4f32-aaa3-bbb59344b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#split dataset in features and target variable\n",
    "X_wo_outliers = df_wo_o.drop(['Class'], axis=1) # Features\n",
    "y_wo_outliers = df_wo_o.Class # Target variable\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train_smt_wo_outliers, X_test_smt_wo_outliers, y_train_smt_wo_outliers, y_test_smt_wo_outliers = train_test_split(X_wo_outliers, y_wo_outliers, test_size=0.2, stratify=y_wo_outliers, random_state=42) # 80% training and 20% test\n",
    "\n",
    "smote_technique = SMOTE(sampling_strategy='minority')\n",
    "X_smt_wo_outliers, y_smt_wo_outliers = smote_technique.fit_resample(X_train_smt_wo_outliers, y_train_smt_wo_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16adfce0-2efb-4942-b3ca-f49632a01613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_smt_wo_outliers = LogisticRegression(C=1e-05, penalty='l2',solver='newton-cg')\n",
    "\n",
    "# Train\n",
    "model_smt_wo_outliers = model_smt_wo_outliers.fit(X_smt_wo_outliers,y_smt_wo_outliers)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_smt_wo_outliers = model_smt_wo_outliers.predict(X_test_smt_wo_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea4846ce-d92e-427d-b611-e3ef6c817aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_smt_wo_outliers = confusion_matrix(y_test_smt_wo_outliers, y_pred_smt_wo_outliers) \n",
    "\n",
    "sns.heatmap(cm_smt_wo_outliers/np.sum(cm_smt_wo_outliers), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91c13d6f-7bad-4809-903e-4e493db0c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 87, FN: 11, FP: 78, TN: 51179\n",
      "Total cost: 2038.6899999999998\n"
     ]
    }
   ],
   "source": [
    "total_cost(cm_smt_wo_outliers, X_test_smt_wo_outliers, y_test_smt_wo_outliers, y_pred_smt_wo_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8719f70-a84c-4310-b591-626b3d92ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def my_scorer_smt_wo_outliers(y_true, y_pred):\n",
    "    model_cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    for cls in range(model_cm.shape[0]):\n",
    "        #print(f'[Class {cls} vs others]')\n",
    "        TP, FN, FP, TN = confusion_matrix_for(cls, model_cm).ravel() \n",
    "        \n",
    "    labels = np.array(['true negative',   # y_test, y_pred = 0,0\n",
    "                   'false positive',  # y_test, y_pred = 0,1\n",
    "                   'false negative',  # y_test, y_pred = 1,0\n",
    "                   'true positive'    # y_test, y_pred = 1,1\n",
    "                  ])\n",
    "    X_test_score = X_smt_wo_outliers\n",
    "    # X_test_score = get_x_elements_by_indices(X_test_score, y_true.index)\n",
    "    #print(labels[y_true * 2 + y_pred])\n",
    "    #X_test_score['case'] = labels[y_true * 2 + y_pred]\n",
    "    Ca = 5\n",
    "    TotalCost = getTotalAmountFalseNegativeMyScorer(X_test_score, y_true, y_pred) + (FP + TP) * Ca\n",
    "    print(TotalCost)\n",
    "    return TotalCost\n",
    "\n",
    "my_func_smt_wo_outliers = make_scorer(my_scorer_smt_wo_outliers, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b6cb9f6-c1b0-4b76-a9ed-641d64aae734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  24.0s\n",
      "[CV 2/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  23.4s\n",
      "[CV 3/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  23.9s\n",
      "[CV 4/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  23.7s\n",
      "[CV 5/5; 1/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 1/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  25.8s\n",
      "[CV 1/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.3s\n",
      "[CV 2/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.3s\n",
      "[CV 3/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.4s\n",
      "[CV 4/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.7s\n",
      "[CV 5/5; 2/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 2/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   2.0s\n",
      "[CV 1/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 5/5; 3/96] START logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 3/96] END logisticregression__C=1e-05, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 5/5; 4/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 4/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 5/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 5/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 15\n",
      "6601.602867403903\n",
      "[CV 1/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-6601.603 total time=   1.1s\n",
      "[CV 2/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 17\n",
      "5732.54193721458\n",
      "[CV 2/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5732.542 total time=   1.1s\n",
      "[CV 3/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "5978.237663936143\n",
      "[CV 3/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5978.238 total time=   0.8s\n",
      "[CV 4/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5376.1720654316605\n",
      "[CV 4/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5376.172 total time=   1.0s\n",
      "[CV 5/5; 6/96] START logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 13\n",
      "4770.4700094102345\n",
      "[CV 5/5; 6/96] END logisticregression__C=1e-05, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-4770.470 total time=   1.0s\n",
      "[CV 1/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 13\n",
      "2640.2625325024505\n",
      "[CV 1/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2640.263 total time=  25.5s\n",
      "[CV 2/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 14\n",
      "2051.9972334026434\n",
      "[CV 2/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2051.997 total time=  24.7s\n",
      "[CV 3/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "2390.217663936143\n",
      "[CV 3/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2390.218 total time=  24.2s\n",
      "[CV 4/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "1653.2320654316602\n",
      "[CV 4/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-1653.232 total time=  24.8s\n",
      "[CV 5/5; 7/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "1827.2379646253937\n",
      "[CV 5/5; 7/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-1827.238 total time=  24.8s\n",
      "[CV 1/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 14\n",
      "5217.682867403903\n",
      "[CV 1/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5217.683 total time=   1.4s\n",
      "[CV 2/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 18\n",
      "4900.24292833283\n",
      "[CV 2/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4900.243 total time=   1.3s\n",
      "[CV 3/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "4191.217663936142\n",
      "[CV 3/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4191.218 total time=   2.2s\n",
      "[CV 4/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "3811.1220654316603\n",
      "[CV 4/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-3811.122 total time=   2.0s\n",
      "[CV 5/5; 8/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 13\n",
      "4371.576616552209\n",
      "[CV 5/5; 8/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4371.577 total time=   1.3s\n",
      "[CV 1/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 14\n",
      "4127.682867403903\n",
      "[CV 1/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4127.683 total time=   2.8s\n",
      "[CV 2/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 12\n",
      "4371.08292833283\n",
      "[CV 2/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4371.083 total time=   2.7s\n",
      "[CV 3/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3956.217663936143\n",
      "[CV 3/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3956.218 total time=   3.2s\n",
      "[CV 4/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "3575.1220654316603\n",
      "[CV 4/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3575.122 total time=   2.6s\n",
      "[CV 5/5; 9/96] START logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3468.4679646253935\n",
      "[CV 5/5; 9/96] END logisticregression__C=1e-05, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3468.468 total time=   2.7s\n",
      "[CV 1/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 10/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 10/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 1/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 11/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 11/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 12/96] START logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 12/96] END logisticregression__C=1e-05, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  23.9s\n",
      "[CV 2/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  23.0s\n",
      "[CV 3/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  24.9s\n",
      "[CV 4/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  26.1s\n",
      "[CV 5/5; 13/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 13/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  27.2s\n",
      "[CV 1/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.3s\n",
      "[CV 2/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.2s\n",
      "[CV 3/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.5s\n",
      "[CV 4/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.6s\n",
      "[CV 5/5; 14/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 14/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   2.1s\n",
      "[CV 1/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 15/96] START logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 15/96] END logisticregression__C=0.0001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 3/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 16/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 16/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 17/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 17/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "6336.692867403903\n",
      "[CV 1/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-6336.693 total time=   1.3s\n",
      "[CV 2/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "5542.942993177581\n",
      "[CV 2/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5542.943 total time=   1.3s\n",
      "[CV 3/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "6659.237663936143\n",
      "[CV 3/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-6659.238 total time=   1.3s\n",
      "[CV 4/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "5411.1720654316605\n",
      "[CV 4/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5411.172 total time=   1.3s\n",
      "[CV 5/5; 18/96] START logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "5860.84\n",
      "[CV 5/5; 18/96] END logisticregression__C=0.0001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-5860.840 total time=   1.3s\n",
      "[CV 1/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "3264.2625325024505\n",
      "[CV 1/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3264.263 total time=  23.7s\n",
      "[CV 2/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3157.4429931775812\n",
      "[CV 2/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3157.443 total time=  24.0s\n",
      "[CV 3/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3500.217663936143\n",
      "[CV 3/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3500.218 total time=  24.0s\n",
      "[CV 4/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2806.1220654316603\n",
      "[CV 4/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2806.122 total time=  24.0s\n",
      "[CV 5/5; 19/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "3136.84\n",
      "[CV 5/5; 19/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3136.840 total time=  25.1s\n",
      "[CV 1/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5401.692867403903\n",
      "[CV 1/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5401.693 total time=   2.0s\n",
      "[CV 2/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 15\n",
      "6927.972928332831\n",
      "[CV 2/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6927.973 total time=   1.4s\n",
      "[CV 3/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 8\n",
      "5579.237663936143\n",
      "[CV 3/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5579.238 total time=   2.1s\n",
      "[CV 4/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "4668.34206543166\n",
      "[CV 4/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4668.342 total time=   2.0s\n",
      "[CV 5/5; 20/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "4540.84\n",
      "[CV 5/5; 20/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4540.840 total time=   2.7s\n",
      "[CV 1/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "3979.2625325024505\n",
      "[CV 1/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3979.263 total time=   3.4s\n",
      "[CV 2/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4111.607233402644\n",
      "[CV 2/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4111.607 total time=   3.2s\n",
      "[CV 3/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4486.217663936142\n",
      "[CV 3/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4486.218 total time=   3.4s\n",
      "[CV 4/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4416.1720654316605\n",
      "[CV 4/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4416.172 total time=   3.2s\n",
      "[CV 5/5; 21/96] START logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3598.4679646253935\n",
      "[CV 5/5; 21/96] END logisticregression__C=0.0001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3598.468 total time=   2.7s\n",
      "[CV 1/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 22/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 22/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 23/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 23/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 24/96] START logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 24/96] END logisticregression__C=0.0001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  24.3s\n",
      "[CV 2/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  22.9s\n",
      "[CV 3/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  23.4s\n",
      "[CV 4/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  23.6s\n",
      "[CV 5/5; 25/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 25/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  25.4s\n",
      "[CV 1/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.2s\n",
      "[CV 2/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.2s\n",
      "[CV 3/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.6s\n",
      "[CV 5/5; 26/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 26/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   2.0s\n",
      "[CV 1/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 27/96] START logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 27/96] END logisticregression__C=0.001, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 2/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 28/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 28/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 29/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 29/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "3384.2625325024505\n",
      "[CV 1/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3384.263 total time=   1.6s\n",
      "[CV 2/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3362.9429931775812\n",
      "[CV 2/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3362.943 total time=   1.3s\n",
      "[CV 3/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3641.217663936143\n",
      "[CV 3/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3641.218 total time=   2.4s\n",
      "[CV 4/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3071.1220654316603\n",
      "[CV 4/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3071.122 total time=   1.5s\n",
      "[CV 5/5; 30/96] START logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 7\n",
      "3315.84\n",
      "[CV 5/5; 30/96] END logisticregression__C=0.001, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3315.840 total time=   2.8s\n",
      "[CV 1/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "3344.2625325024505\n",
      "[CV 1/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3344.263 total time=  23.8s\n",
      "[CV 2/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3122.9429931775812\n",
      "[CV 2/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3122.943 total time=  23.6s\n",
      "[CV 3/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3610.217663936143\n",
      "[CV 3/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3610.218 total time=  23.4s\n",
      "[CV 4/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2681.1220654316603\n",
      "[CV 4/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2681.122 total time=  22.8s\n",
      "[CV 5/5; 31/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "3044.44\n",
      "[CV 5/5; 31/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3044.440 total time=  23.3s\n",
      "[CV 1/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "5851.692867403903\n",
      "[CV 1/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5851.693 total time=   2.5s\n",
      "[CV 2/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5567.942993177581\n",
      "[CV 2/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5567.943 total time=   2.5s\n",
      "[CV 3/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "8690.88777682016\n",
      "[CV 3/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-8690.888 total time=   1.4s\n",
      "[CV 4/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "5058.34206543166\n",
      "[CV 4/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5058.342 total time=   2.1s\n",
      "[CV 5/5; 32/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "4760.84\n",
      "[CV 5/5; 32/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4760.840 total time=   2.6s\n",
      "[CV 1/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4604.262532502451\n",
      "[CV 1/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4604.263 total time=   3.4s\n",
      "[CV 2/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "4423.457233402643\n",
      "[CV 2/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4423.457 total time=   3.1s\n",
      "[CV 3/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5129.237663936143\n",
      "[CV 3/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5129.238 total time=   3.2s\n",
      "[CV 4/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4531.1720654316605\n",
      "[CV 4/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4531.172 total time=   3.1s\n",
      "[CV 5/5; 33/96] START logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3608.4679646253935\n",
      "[CV 5/5; 33/96] END logisticregression__C=0.001, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3608.468 total time=   2.5s\n",
      "[CV 1/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 34/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 34/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 35/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 35/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 36/96] START logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 36/96] END logisticregression__C=0.001, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  23.5s\n",
      "[CV 2/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  22.5s\n",
      "[CV 3/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  23.8s\n",
      "[CV 4/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  23.7s\n",
      "[CV 5/5; 37/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 37/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  25.4s\n",
      "[CV 1/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.2s\n",
      "[CV 2/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.2s\n",
      "[CV 3/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.6s\n",
      "[CV 5/5; 38/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 38/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   2.0s\n",
      "[CV 1/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 3/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 39/96] START logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 39/96] END logisticregression__C=0.01, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 40/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 40/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 41/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 41/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2988.7008200038385\n",
      "[CV 1/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2988.701 total time=   1.7s\n",
      "[CV 2/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3082.9429931775812\n",
      "[CV 2/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3082.943 total time=   3.3s\n",
      "[CV 3/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3623.237663936143\n",
      "[CV 3/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3623.238 total time=   4.0s\n",
      "[CV 4/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2756.1220654316603\n",
      "[CV 4/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2756.122 total time=   2.9s\n",
      "[CV 5/5; 42/96] START logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "2964.44\n",
      "[CV 5/5; 42/96] END logisticregression__C=0.01, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2964.440 total time=   1.4s\n",
      "[CV 1/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2978.7008200038385\n",
      "[CV 1/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2978.701 total time=  22.0s\n",
      "[CV 2/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3107.9429931775812\n",
      "[CV 2/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3107.943 total time=  22.3s\n",
      "[CV 3/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3678.237663936143\n",
      "[CV 3/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3678.238 total time=  21.8s\n",
      "[CV 4/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2766.1220654316603\n",
      "[CV 4/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2766.122 total time=  21.5s\n",
      "[CV 5/5; 43/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2914.44\n",
      "[CV 5/5; 43/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2914.440 total time=  23.3s\n",
      "[CV 1/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "4893.498931012973\n",
      "[CV 1/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4893.499 total time=   2.7s\n",
      "[CV 2/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "4843.457233402643\n",
      "[CV 2/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4843.457 total time=   2.7s\n",
      "[CV 3/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "9115.88777682016\n",
      "[CV 3/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-9115.888 total time=   1.3s\n",
      "[CV 4/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "4676.1720654316605\n",
      "[CV 4/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4676.172 total time=   2.8s\n",
      "[CV 5/5; 44/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "4725.84\n",
      "[CV 5/5; 44/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4725.840 total time=   2.7s\n",
      "[CV 1/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4654.262532502451\n",
      "[CV 1/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4654.263 total time=   3.4s\n",
      "[CV 2/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4442.942993177581\n",
      "[CV 2/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4442.943 total time=   3.2s\n",
      "[CV 3/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5289.237663936143\n",
      "[CV 3/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5289.238 total time=   3.3s\n",
      "[CV 4/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4656.1720654316605\n",
      "[CV 4/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4656.172 total time=   3.1s\n",
      "[CV 5/5; 45/96] START logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3603.4679646253935\n",
      "[CV 5/5; 45/96] END logisticregression__C=0.01, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3603.468 total time=   2.6s\n",
      "[CV 1/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.3s\n",
      "[CV 4/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 46/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 46/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 47/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 47/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 2/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 48/96] START logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 48/96] END logisticregression__C=0.01, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  24.2s\n",
      "[CV 2/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  22.8s\n",
      "[CV 3/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  23.3s\n",
      "[CV 4/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  23.3s\n",
      "[CV 5/5; 49/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 49/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  25.6s\n",
      "[CV 1/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.2s\n",
      "[CV 2/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.2s\n",
      "[CV 3/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.6s\n",
      "[CV 5/5; 50/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 50/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   2.0s\n",
      "[CV 1/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 51/96] START logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 51/96] END logisticregression__C=0.1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.3s\n",
      "[CV 1/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 52/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 52/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 53/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 53/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 1/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2953.7008200038385\n",
      "[CV 1/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2953.701 total time=   3.9s\n",
      "[CV 2/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3052.9429931775812\n",
      "[CV 2/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3052.943 total time=   3.6s\n",
      "[CV 3/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3688.237663936143\n",
      "[CV 3/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3688.238 total time=   4.2s\n",
      "[CV 4/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2736.1220654316603\n",
      "[CV 4/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2736.122 total time=   4.8s\n",
      "[CV 5/5; 54/96] START logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "2849.44\n",
      "[CV 5/5; 54/96] END logisticregression__C=0.1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2849.440 total time=  10.7s\n",
      "[CV 1/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2913.7008200038385\n",
      "[CV 1/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2913.701 total time=  23.1s\n",
      "[CV 2/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3062.9429931775812\n",
      "[CV 2/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3062.943 total time=  22.8s\n",
      "[CV 3/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3648.237663936143\n",
      "[CV 3/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3648.238 total time=  22.2s\n",
      "[CV 4/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2716.1220654316603\n",
      "[CV 4/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2716.122 total time=  22.5s\n",
      "[CV 5/5; 55/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 55/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2829.440 total time=  25.4s\n",
      "[CV 1/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.1s\n",
      "[CV 2/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "4797.942993177581\n",
      "[CV 2/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4797.943 total time=   2.6s\n",
      "[CV 3/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 7\n",
      "5348.34206543166\n",
      "[CV 4/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5348.342 total time=   2.0s\n",
      "[CV 5/5; 56/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "4735.84\n",
      "[CV 5/5; 56/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4735.840 total time=   2.6s\n",
      "[CV 1/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4664.262532502451\n",
      "[CV 1/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4664.263 total time=   3.1s\n",
      "[CV 2/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4442.942993177581\n",
      "[CV 2/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4442.943 total time=   2.9s\n",
      "[CV 3/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5294.237663936143\n",
      "[CV 3/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5294.238 total time=   3.1s\n",
      "[CV 4/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4666.1720654316605\n",
      "[CV 4/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4666.172 total time=   2.8s\n",
      "[CV 5/5; 57/96] START logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3608.4679646253935\n",
      "[CV 5/5; 57/96] END logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3608.468 total time=   2.4s\n",
      "[CV 1/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 58/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 58/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 59/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 59/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 60/96] START logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 60/96] END logisticregression__C=0.1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  23.1s\n",
      "[CV 2/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  22.4s\n",
      "[CV 3/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  23.4s\n",
      "[CV 4/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  22.8s\n",
      "[CV 5/5; 61/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 61/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  25.3s\n",
      "[CV 1/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.1s\n",
      "[CV 2/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.1s\n",
      "[CV 3/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.6s\n",
      "[CV 5/5; 62/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 62/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   1.9s\n",
      "[CV 1/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 63/96] START logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 63/96] END logisticregression__C=1, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 64/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 64/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 4/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.3s\n",
      "[CV 5/5; 65/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 65/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.4s\n",
      "[CV 1/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2908.701 total time=  13.2s\n",
      "[CV 2/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3042.9429931775812\n",
      "[CV 2/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3042.943 total time=   7.9s\n",
      "[CV 3/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3673.237663936143\n",
      "[CV 3/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3673.238 total time=   4.4s\n",
      "[CV 4/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2736.1220654316603\n",
      "[CV 4/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2736.122 total time=   4.1s\n",
      "[CV 5/5; 66/96] START logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "2899.44\n",
      "[CV 5/5; 66/96] END logisticregression__C=1, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2899.440 total time=   2.3s\n",
      "[CV 1/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2903.7008200038385\n",
      "[CV 1/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2903.701 total time=  21.6s\n",
      "[CV 2/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "3025.2929931775816\n",
      "[CV 2/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3025.293 total time=  23.1s\n",
      "[CV 3/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3603.237663936143\n",
      "[CV 3/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3603.238 total time=  24.4s\n",
      "[CV 4/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2751.122 total time=  23.0s\n",
      "[CV 5/5; 67/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2844.44\n",
      "[CV 5/5; 67/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2844.440 total time=  23.5s\n",
      "[CV 1/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "4897.937218514361\n",
      "[CV 1/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4897.937 total time=   2.6s\n",
      "[CV 2/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5587.942993177581\n",
      "[CV 2/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5587.943 total time=   2.5s\n",
      "[CV 3/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 8\n",
      "4566.1720654316605\n",
      "[CV 4/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4566.172 total time=   2.7s\n",
      "[CV 5/5; 68/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 68/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5945.840 total time=   1.9s\n",
      "[CV 1/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4664.262532502451\n",
      "[CV 1/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4664.263 total time=   3.2s\n",
      "[CV 2/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4452.942993177581\n",
      "[CV 2/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4452.943 total time=   2.9s\n",
      "[CV 3/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5299.237663936143\n",
      "[CV 3/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5299.238 total time=   3.1s\n",
      "[CV 4/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4666.1720654316605\n",
      "[CV 4/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4666.172 total time=   2.9s\n",
      "[CV 5/5; 69/96] START logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3608.4679646253935\n",
      "[CV 5/5; 69/96] END logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3608.468 total time=   2.5s\n",
      "[CV 1/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 70/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 70/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 71/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 71/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 72/96] START logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 72/96] END logisticregression__C=1, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  23.7s\n",
      "[CV 2/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  22.1s\n",
      "[CV 3/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  24.1s\n",
      "[CV 4/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  22.7s\n",
      "[CV 5/5; 73/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 73/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  24.8s\n",
      "[CV 1/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.3s\n",
      "[CV 2/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.2s\n",
      "[CV 3/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.6s\n",
      "[CV 5/5; 74/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 74/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   1.9s\n",
      "[CV 1/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 75/96] START logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 75/96] END logisticregression__C=10, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 76/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 76/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 77/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 77/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2948.7008200038385\n",
      "[CV 1/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2948.701 total time=   4.1s\n",
      "[CV 2/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3037.9429931775812\n",
      "[CV 2/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3037.943 total time=   3.2s\n",
      "[CV 3/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3638.237663936143\n",
      "[CV 3/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3638.238 total time=  11.4s\n",
      "[CV 4/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2731.1220654316603\n",
      "[CV 4/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2731.122 total time=   4.5s\n",
      "[CV 5/5; 78/96] START logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "2839.44\n",
      "[CV 5/5; 78/96] END logisticregression__C=10, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2839.440 total time=  16.2s\n",
      "[CV 1/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2883.7008200038385\n",
      "[CV 1/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2883.701 total time=  22.6s\n",
      "[CV 2/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3027.9429931775812\n",
      "[CV 2/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3027.943 total time=  22.2s\n",
      "[CV 3/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3603.237663936143\n",
      "[CV 3/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3603.238 total time=  22.1s\n",
      "[CV 4/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2746.1220654316603\n",
      "[CV 4/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2746.122 total time=  21.8s\n",
      "[CV 5/5; 79/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2819.44\n",
      "[CV 5/5; 79/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2819.440 total time=  22.9s\n",
      "[CV 1/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.1s\n",
      "[CV 2/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.1s\n",
      "[CV 3/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.2s\n",
      "[CV 4/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5288.34206543166\n",
      "[CV 4/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5288.342 total time=   2.5s\n",
      "[CV 5/5; 80/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "4740.84\n",
      "[CV 5/5; 80/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4740.840 total time=   2.5s\n",
      "[CV 1/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4664.262532502451\n",
      "[CV 1/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4664.263 total time=   3.0s\n",
      "[CV 2/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4452.942993177581\n",
      "[CV 2/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4452.943 total time=   2.8s\n",
      "[CV 3/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5299.237663936143\n",
      "[CV 3/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5299.238 total time=   2.9s\n",
      "[CV 4/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4666.1720654316605\n",
      "[CV 4/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4666.172 total time=   2.7s\n",
      "[CV 5/5; 81/96] START logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3608.4679646253935\n",
      "[CV 5/5; 81/96] END logisticregression__C=10, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3608.468 total time=   2.3s\n",
      "[CV 1/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 82/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 82/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 83/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 83/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 84/96] START logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 84/96] END logisticregression__C=10, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2908.7008200038385\n",
      "[CV 1/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2908.701 total time=  22.7s\n",
      "[CV 2/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3047.9429931775812\n",
      "[CV 2/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3047.943 total time=  21.4s\n",
      "[CV 3/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3578.237663936143\n",
      "[CV 3/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-3578.238 total time=  22.2s\n",
      "[CV 4/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2751.122 total time=  22.2s\n",
      "[CV 5/5; 85/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2829.44\n",
      "[CV 5/5; 85/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=newton-cg;, score=-2829.440 total time=  24.0s\n",
      "[CV 1/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.1s\n",
      "[CV 2/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "5512.942993177581\n",
      "[CV 2/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5512.943 total time=   2.1s\n",
      "[CV 3/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.3s\n",
      "[CV 4/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.5s\n",
      "[CV 5/5; 86/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 86/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=lbfgs;, score=-5945.840 total time=   1.9s\n",
      "[CV 1/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 1/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 2/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 3/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 4/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 87/96] START logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear\n",
      "[CV 5/5; 87/96] END logisticregression__C=100, logisticregression__penalty=none, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 1/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 88/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 88/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 89/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 89/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 10\n",
      "2953.7008200038385\n",
      "[CV 1/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2953.701 total time=   2.5s\n",
      "[CV 2/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3042.9429931775812\n",
      "[CV 2/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3042.943 total time=   3.4s\n",
      "[CV 3/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3688.237663936143\n",
      "[CV 3/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-3688.238 total time=   3.4s\n",
      "[CV 4/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "2721.1220654316603\n",
      "[CV 4/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2721.122 total time=   5.7s\n",
      "[CV 5/5; 90/96] START logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear\n",
      "No of FN: 6\n",
      "2859.44\n",
      "[CV 5/5; 90/96] END logisticregression__C=100, logisticregression__penalty=l1, logisticregression__solver=liblinear;, score=-2859.440 total time=   4.0s\n",
      "[CV 1/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 10\n",
      "2918.7008200038385\n",
      "[CV 1/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2918.701 total time=  20.6s\n",
      "[CV 2/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3032.9429931775812\n",
      "[CV 2/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3032.943 total time=  21.7s\n",
      "[CV 3/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "3598.237663936143\n",
      "[CV 3/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-3598.238 total time=  22.4s\n",
      "[CV 4/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "2751.1220654316603\n",
      "[CV 4/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2751.122 total time=  21.4s\n",
      "[CV 5/5; 91/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 6\n",
      "2864.44\n",
      "[CV 5/5; 91/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=-2864.440 total time=  22.1s\n",
      "[CV 1/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 11\n",
      "6081.692867403903\n",
      "[CV 1/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-6081.693 total time=   2.1s\n",
      "[CV 2/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 9\n",
      "4772.942993177581\n",
      "[CV 2/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-4772.943 total time=   2.5s\n",
      "[CV 3/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 10\n",
      "9145.88777682016\n",
      "[CV 3/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-9145.888 total time=   1.2s\n",
      "[CV 4/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of FN: 7\n",
      "5308.34206543166\n",
      "[CV 4/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5308.342 total time=   2.5s\n",
      "[CV 5/5; 92/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs\n",
      "No of FN: 6\n",
      "5945.84\n",
      "[CV 5/5; 92/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=-5945.840 total time=   1.9s\n",
      "[CV 1/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 11\n",
      "4664.262532502451\n",
      "[CV 1/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4664.263 total time=   3.0s\n",
      "[CV 2/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "4452.942993177581\n",
      "[CV 2/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4452.943 total time=   2.8s\n",
      "[CV 3/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "5299.237663936143\n",
      "[CV 3/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-5299.238 total time=   2.9s\n",
      "[CV 4/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 8\n",
      "4666.1720654316605\n",
      "[CV 4/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-4666.172 total time=   2.7s\n",
      "[CV 5/5; 93/96] START logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear\n",
      "No of FN: 9\n",
      "3608.4679646253935\n",
      "[CV 5/5; 93/96] END logisticregression__C=100, logisticregression__penalty=l2, logisticregression__solver=liblinear;, score=-3608.468 total time=   2.3s\n",
      "[CV 1/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 1/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 2/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 2/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 3/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 3/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 4/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 4/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 5/5; 94/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg\n",
      "[CV 5/5; 94/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   0.2s\n",
      "[CV 1/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 1/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 2/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 3/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 3/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 4/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 4/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 5/5; 95/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs\n",
      "[CV 5/5; 95/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 1/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 1/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 2/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 2/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 3/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 3/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 4/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 4/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n",
      "[CV 5/5; 96/96] START logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear\n",
      "[CV 5/5; 96/96] END logisticregression__C=100, logisticregression__penalty=elasticnet, logisticregression__solver=liblinear;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -5691.80490868 -2112.58949198 -4498.36842833\n",
      " -3899.71469795            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -5962.17711799 -3172.97705101 -5423.61710502\n",
      " -4118.34549198            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3355.07705101 -3160.59705101 -5985.94114057\n",
      " -4459.31949198            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3083.08870851 -3089.08870851 -5650.97120133\n",
      " -4529.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3056.08870851 -3034.08870851 -6021.94114057\n",
      " -4535.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3052.08870851 -3025.55870851 -6028.75601079\n",
      " -4538.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3039.08870851 -3016.08870851 -6153.94114057\n",
      " -4538.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3053.08870851 -3033.08870851 -6250.94114057\n",
      " -4538.21664393            nan            nan            nan]\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "grid_imba_wo_outliers = GridSearchCV(imba_pipeline, param_grid=new_params, cv=5, scoring=my_func_smt_wo_outliers,  verbose=10)\n",
    "grid_search_imba_wo_outliers = grid_imba_wo_outliers.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "177f8907-4731-4c74-8f3d-ea5f8249495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [-3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -5691.80490868 -2112.58949198 -4498.36842833\n",
      " -3899.71469795            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -5962.17711799 -3172.97705101 -5423.61710502\n",
      " -4118.34549198            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3355.07705101 -3160.59705101 -5985.94114057\n",
      " -4459.31949198            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3083.08870851 -3089.08870851 -5650.97120133\n",
      " -4529.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3056.08870851 -3034.08870851 -6021.94114057\n",
      " -4535.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3052.08870851 -3025.55870851 -6028.75601079\n",
      " -4538.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3039.08870851 -3016.08870851 -6153.94114057\n",
      " -4538.21664393            nan            nan            nan\n",
      " -3023.08870851 -6398.94114057            nan            nan\n",
      "            nan -3053.08870851 -3033.08870851 -6250.94114057\n",
      " -4538.21664393            nan            nan            nan], using {'logisticregression__C': 1e-05, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.236193</td>\n",
       "      <td>0.828255</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-2908.700820</td>\n",
       "      <td>-3047.942993</td>\n",
       "      <td>-3578.237664</td>\n",
       "      <td>-2751.122065</td>\n",
       "      <td>-2829.440000</td>\n",
       "      <td>-3023.088709</td>\n",
       "      <td>294.400531</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.206000</td>\n",
       "      <td>0.431422</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>-6081.692867</td>\n",
       "      <td>-5512.942993</td>\n",
       "      <td>-9145.887777</td>\n",
       "      <td>-5308.342065</td>\n",
       "      <td>-5945.840000</td>\n",
       "      <td>-6398.941141</td>\n",
       "      <td>1401.860335</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325007</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342604</td>\n",
       "      <td>0.039450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322399</td>\n",
       "      <td>0.021422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 1e-05, 'logisticregr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2.116007</td>\n",
       "      <td>0.464997</td>\n",
       "      <td>0.021199</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-6081.692867</td>\n",
       "      <td>-4772.942993</td>\n",
       "      <td>-9145.887777</td>\n",
       "      <td>-5308.342065</td>\n",
       "      <td>-5945.840000</td>\n",
       "      <td>-6250.941141</td>\n",
       "      <td>1521.539960</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2.837188</td>\n",
       "      <td>0.243794</td>\n",
       "      <td>0.021206</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>-4664.262533</td>\n",
       "      <td>-4452.942993</td>\n",
       "      <td>-5299.237664</td>\n",
       "      <td>-4666.172065</td>\n",
       "      <td>-3608.467965</td>\n",
       "      <td>-4538.216644</td>\n",
       "      <td>544.631499</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.284205</td>\n",
       "      <td>0.016276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.272799</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.293603</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       24.236193      0.828255         0.025000        0.002191   \n",
       "1        2.206000      0.431422         0.022001        0.000632   \n",
       "2        0.325007      0.029175         0.000000        0.000000   \n",
       "3        0.342604      0.039450         0.000000        0.000000   \n",
       "4        0.322399      0.021422         0.000000        0.000000   \n",
       "..            ...           ...              ...             ...   \n",
       "91       2.116007      0.464997         0.021199        0.000398   \n",
       "92       2.837188      0.243794         0.021206        0.000740   \n",
       "93       0.284205      0.016276         0.000000        0.000000   \n",
       "94       0.272799      0.016971         0.000000        0.000000   \n",
       "95       0.293603      0.024384         0.000000        0.000000   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__penalty  \\\n",
       "0                      0.00001                              none   \n",
       "1                      0.00001                              none   \n",
       "2                      0.00001                              none   \n",
       "3                      0.00001                                l1   \n",
       "4                      0.00001                                l1   \n",
       "..                         ...                               ...   \n",
       "91                         100                                l2   \n",
       "92                         100                                l2   \n",
       "93                         100                        elasticnet   \n",
       "94                         100                        elasticnet   \n",
       "95                         100                        elasticnet   \n",
       "\n",
       "   param_logisticregression__solver  \\\n",
       "0                         newton-cg   \n",
       "1                             lbfgs   \n",
       "2                         liblinear   \n",
       "3                         newton-cg   \n",
       "4                             lbfgs   \n",
       "..                              ...   \n",
       "91                            lbfgs   \n",
       "92                        liblinear   \n",
       "93                        newton-cg   \n",
       "94                            lbfgs   \n",
       "95                        liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'logisticregression__C': 1e-05, 'logisticregr...       -2908.700820   \n",
       "1   {'logisticregression__C': 1e-05, 'logisticregr...       -6081.692867   \n",
       "2   {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "3   {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "4   {'logisticregression__C': 1e-05, 'logisticregr...                NaN   \n",
       "..                                                ...                ...   \n",
       "91  {'logisticregression__C': 100, 'logisticregres...       -6081.692867   \n",
       "92  {'logisticregression__C': 100, 'logisticregres...       -4664.262533   \n",
       "93  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "94  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "95  {'logisticregression__C': 100, 'logisticregres...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0        -3047.942993       -3578.237664       -2751.122065   \n",
       "1        -5512.942993       -9145.887777       -5308.342065   \n",
       "2                 NaN                NaN                NaN   \n",
       "3                 NaN                NaN                NaN   \n",
       "4                 NaN                NaN                NaN   \n",
       "..                ...                ...                ...   \n",
       "91       -4772.942993       -9145.887777       -5308.342065   \n",
       "92       -4452.942993       -5299.237664       -4666.172065   \n",
       "93                NaN                NaN                NaN   \n",
       "94                NaN                NaN                NaN   \n",
       "95                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0        -2829.440000     -3023.088709      294.400531                3  \n",
       "1        -5945.840000     -6398.941141     1401.860335               41  \n",
       "2                 NaN              NaN             NaN               66  \n",
       "3                 NaN              NaN             NaN               67  \n",
       "4                 NaN              NaN             NaN               68  \n",
       "..                ...              ...             ...              ...  \n",
       "91       -5945.840000     -6250.941141     1521.539960               40  \n",
       "92       -3608.467965     -4538.216644      544.631499               29  \n",
       "93                NaN              NaN             NaN               51  \n",
       "94                NaN              NaN             NaN               89  \n",
       "95                NaN              NaN             NaN               96  \n",
       "\n",
       "[96 rows x 16 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_search_imba_wo_outliers.cv_results_['mean_test_score'], grid_search_imba_wo_outliers.best_params_))\n",
    "results_df_imba_wo_outliers = pd.DataFrame(grid_search_imba_wo_outliers.cv_results_)\n",
    "results_df_imba_wo_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d119cca-d7fa-454e-a850-41583d22d618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
